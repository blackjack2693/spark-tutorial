2022.02.10 18:18:21 INFO  tracing is disabled for protocol LSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/lsp.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/lsp.trace.json
2022.02.10 18:18:22 INFO  logging to file /Users/Johann/Documents/GitHub/spark-tutorial/.metals/metals.log
2022.02.10 18:18:22 INFO  Started: Metals version 0.11.1 in workspace '/Users/Johann/Documents/GitHub/spark-tutorial' for client Visual Studio Code 1.64.0.
2022.02.10 18:18:22 INFO  Parse release: 11.0.1
2022.02.10 18:18:25 INFO  time: initialize in 3.5s
2022.02.10 18:18:26 WARN  Build server is not auto-connectable.
2022.02.10 18:18:27 WARN  no build target for: /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:18:36 INFO  no build target found for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala. Using presentation compiler with project's scala-library version: 3.1.0
2022.02.10 18:18:54 INFO  running '/Library/Java/JavaVirtualMachines/jdk-11.0.1.jdk/Contents/Home/bin/java -Djline.terminal=jline.UnsupportedTerminal -Dsbt.log.noformat=true -Dfile.encoding=UTF-8 -jar /var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/metals5927924205624153876/sbt-launch.jar -Dbloop.export-jar-classifiers=sources bloopInstall'
2022.02.10 18:18:54 WARN  no build target for: /Users/Johann/Documents/GitHub/spark-tutorial/project/metals.sbt
2022.02.10 18:18:54 WARN  no build target for: /Users/Johann/Documents/GitHub/spark-tutorial/project/project/metals.sbt
2022.02.10 18:18:54 INFO  skipping build import with status 'Started'
2022.02.10 18:18:54 WARN  no build target for: /Users/Johann/Documents/GitHub/spark-tutorial/project/metals.sbt
2022.02.10 18:18:54 WARN  no build target for: /Users/Johann/Documents/GitHub/spark-tutorial/project/project/metals.sbt
2022.02.10 18:18:54 INFO  skipping build import with status 'Started'
2022.02.10 18:18:58 INFO  [info] welcome to sbt 1.3.12 (Oracle Corporation Java 11.0.1)
2022.02.10 18:19:01 INFO  [info] loading settings for project spark-tutorial-build-build-build from metals.sbt ...
2022.02.10 18:19:03 INFO  [info] loading project definition from /Users/Johann/Documents/GitHub/spark-tutorial/project/project/project
2022.02.10 18:19:07 INFO  [warn] There may be incompatibilities among your library dependencies; run 'evicted' to see detailed eviction warnings.
2022.02.10 18:19:09 INFO  [info] loading settings for project spark-tutorial-build-build from metals.sbt ...
2022.02.10 18:19:09 INFO  [info] loading project definition from /Users/Johann/Documents/GitHub/spark-tutorial/project/project
2022.02.10 18:19:10 INFO  [warn] There may be incompatibilities among your library dependencies; run 'evicted' to see detailed eviction warnings.
2022.02.10 18:19:12 INFO  [warn] There may be incompatibilities among your library dependencies; run 'evicted' to see detailed eviction warnings.
2022.02.10 18:19:13 INFO  [success] Generated .bloop/spark-tutorial-build-build.json
2022.02.10 18:19:13 INFO  [success] Total time: 3 s, completed 10.02.2022, 18:19:13
2022.02.10 18:19:14 INFO  [info] loading settings for project spark-tutorial-build from plugins.sbt,metals.sbt ...
2022.02.10 18:19:14 INFO  [info] loading project definition from /Users/Johann/Documents/GitHub/spark-tutorial/project
2022.02.10 18:19:16 INFO  [warn] There may be incompatibilities among your library dependencies; run 'evicted' to see detailed eviction warnings.
2022.02.10 18:19:18 INFO  [warn] There may be incompatibilities among your library dependencies; run 'evicted' to see detailed eviction warnings.
2022.02.10 18:19:18 INFO  [success] Generated .bloop/spark-tutorial-build.json
2022.02.10 18:19:18 INFO  [success] Total time: 4 s, completed 10.02.2022, 18:19:19
2022.02.10 18:19:22 INFO  [info] loading settings for project spark-tutorial from build.sbt ...
2022.02.10 18:19:22 INFO  [info] set current project to SparkTutorialSBT (in build file:/Users/Johann/Documents/GitHub/spark-tutorial/)
2022.02.10 18:19:29 INFO  [warn] There may be incompatibilities among your library dependencies; run 'evicted' to see detailed eviction warnings.
2022.02.10 18:19:29 INFO  [success] Generated .bloop/spark-tutorial.json
2022.02.10 18:19:29 INFO  [success] Generated .bloop/spark-tutorial-test.json
2022.02.10 18:19:29 INFO  [success] Total time: 7 s, completed 10.02.2022, 18:19:30
2022.02.10 18:19:30 INFO  time: ran 'sbt bloopInstall' in 36s
2022.02.10 18:19:30 INFO  Attempting to connect to the build server...
2022.02.10 18:19:39 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/bsp.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/bsp.trace.json
2022.02.10 18:19:41 WARN  no build target for: /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:19:43 INFO  Attempting to connect to the build server...
2022.02.10 18:19:43 INFO  Attempting to connect to the build server...
2022.02.10 18:19:43 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/project/project/.metals/bsp.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/bsp.trace.json
2022.02.10 18:19:43 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/project/.metals/bsp.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/bsp.trace.json
2022.02.10 18:19:43 INFO  time: Connected to build server in 12s
2022.02.10 18:19:43 INFO  Connected to Build server: Bloop v1.4.12
2022.02.10 18:19:43 INFO  time: Imported build in 0.32s
2022.02.10 18:19:44 WARN  no build target for: /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:19:45 WARN  no build target for: /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:19:49 INFO  no build target found for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala. Using presentation compiler with project's scala-library version: 3.1.0
2022.02.10 18:19:49 INFO  time: code lens generation in 5.4s
2022.02.10 18:19:49 INFO  time: code lens generation in 5.4s
2022.02.10 18:19:50 INFO  time: code lens generation in 7.76s
2022.02.10 18:19:50 INFO  time: code lens generation in 7.76s
2022.02.10 18:19:50 INFO  time: code lens generation in 6.94s
2022.02.10 18:19:50 INFO  time: code lens generation in 6.94s
2022.02.10 18:19:59 INFO  time: indexed workspace in 15s
2022.02.10 18:20:00 INFO  compiling spark-tutorial (10 scala sources)
2022.02.10 18:20:22 WARN  there was one deprecation warning (since 2.11.0); re-run with -deprecation for details
2022.02.10 18:20:22 INFO  time: compiled spark-tutorial in 22s
2022.02.10 18:22:00 INFO  shutting down Metals
2022.02.10 18:22:00 INFO  Shut down connection with build server.
2022.02.10 18:22:00 INFO  Shut down connection with build server.
2022.02.10 18:22:00 INFO  Shut down connection with build server.
2022.02.10 18:22:38 INFO  tracing is disabled for protocol LSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/lsp.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/lsp.trace.json
2022.02.10 18:22:39 INFO  logging to file /Users/Johann/Documents/GitHub/spark-tutorial/.metals/metals.log
2022.02.10 18:22:39 INFO  Started: Metals version 0.11.1 in workspace '/Users/Johann/Documents/GitHub/spark-tutorial' for client Visual Studio Code 1.64.1.
2022.02.10 18:22:39 INFO  Parse release: 11.0.1
2022.02.10 18:22:42 INFO  time: initialize in 3.18s
2022.02.10 18:22:43 INFO  Attempting to connect to the build server...
2022.02.10 18:22:43 INFO  skipping build import with status 'Installed'
2022.02.10 18:22:43 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/bsp.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/bsp.trace.json
2022.02.10 18:22:43 INFO  Attempting to connect to the build server...
2022.02.10 18:22:43 INFO  Attempting to connect to the build server...
2022.02.10 18:22:43 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/project/project/.metals/bsp.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/bsp.trace.json
2022.02.10 18:22:43 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/project/.metals/bsp.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/bsp.trace.json
2022.02.10 18:22:43 INFO  time: Connected to build server in 0.45s
2022.02.10 18:22:43 INFO  Connected to Build server: Bloop v1.4.12
Feb. 10, 2022 6:22:51 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7
2022.02.10 18:22:53 INFO  time: indexed workspace in 10s
2022.02.10 18:23:53 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:23:56 INFO  time: compiled spark-tutorial in 2.79s
2022.02.10 18:23:57 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:23:58 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:23:58 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:23:59 INFO  time: compiled spark-tutorial in 1.92s
2022.02.10 18:23:59 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:24:02 INFO  time: compiled spark-tutorial in 1.87s
2022.02.10 18:24:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:24:03 INFO  time: compiled spark-tutorial in 0.7s
2022.02.10 18:24:05 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:24:07 INFO  time: compiled spark-tutorial in 2.04s
2022.02.10 18:24:26 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.10 18:24:27 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.10 18:24:27 INFO  Starting debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 18:24:34 INFO  Trying to attach to remote debuggee VM localhost:53427 .
2022.02.10 18:24:34 INFO  Attaching to debuggee VM succeeded.
2022.02.10 18:24:35 INFO  Canceling debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 18:24:35 INFO  Closing debug server tcp://0.0.0.0:53418
2022.02.10 18:24:53 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:24:53 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:24:53 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:28:25 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:28:25 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:28:53 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:29:01 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:33:44 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:42:49 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:42:49 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:44:15 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:44:16 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:44:16 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:44:16 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:44:16 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:44:17 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:44:20 INFO  time: compiled spark-tutorial in 3.12s
2022.02.10 18:44:30 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:44:32 INFO  time: compiled spark-tutorial in 1.47s
2022.02.10 18:44:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:44:38 INFO  time: compiled spark-tutorial in 1.55s
2022.02.10 18:44:46 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:44:48 INFO  time: compiled spark-tutorial in 1.53s
2022.02.10 18:47:08 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:47:10 INFO  time: compiled spark-tutorial in 2.38s
2022.02.10 18:47:11 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:47:12 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:47:12 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:47:13 INFO  time: compiled spark-tutorial in 1.78s
2022.02.10 18:47:13 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:47:14 INFO  time: compiled spark-tutorial in 1.1s
2022.02.10 18:49:34 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:49:35 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:49:35 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:49:36 INFO  time: compiled spark-tutorial in 1.94s
2022.02.10 18:49:38 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:49:40 INFO  time: compiled spark-tutorial in 1.93s
2022.02.10 18:49:45 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:49:47 INFO  time: compiled spark-tutorial in 1.72s
2022.02.10 18:49:47 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:49:47 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 18:49:48 INFO  time: compiled spark-tutorial in 0.92s
2022.02.10 18:50:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:50:39 INFO  time: compiled spark-tutorial in 1.46s
2022.02.10 18:50:41 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:50:43 INFO  time: compiled spark-tutorial in 1.82s
2022.02.10 18:50:46 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 18:50:47 INFO  time: compiled spark-tutorial in 1.65s
2022.02.10 21:38:35 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:38:37 INFO  time: compiled spark-tutorial in 1.47s
2022.02.10 21:38:38 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:38:38 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:38:38 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:38:39 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:38:39 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:38:39 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:38:40 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:38:39 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:38:41 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:38:41 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:38:41 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:38:41 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:38:42 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:38:44 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:38:44 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:38:44 INFO  time: compiled spark-tutorial in 1.63s
2022.02.10 21:38:48 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:38:49 INFO  time: compiled spark-tutorial in 1.56s
2022.02.10 21:39:24 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:39:26 INFO  time: compiled spark-tutorial in 1.27s
2022.02.10 21:39:55 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:39:56 INFO  time: compiled spark-tutorial in 1.54s
2022.02.10 21:39:57 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:39:59 INFO  time: compiled spark-tutorial in 1.3s
2022.02.10 21:41:32 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 3h 18m 48.984s)
2022.02.10 21:41:32 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.10 21:41:32 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.10 21:41:33 INFO  Starting debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 21:41:37 INFO  Trying to attach to remote debuggee VM localhost:55161 .
2022.02.10 21:41:37 INFO  Attaching to debuggee VM succeeded.
2022.02.10 21:41:38 INFO  Canceling debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 21:41:38 INFO  Closing debug server tcp://0.0.0.0:55155
2022.02.10 21:43:11 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:43:13 INFO  time: compiled spark-tutorial in 1.53s
2022.02.10 21:43:13 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:43:14 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:43:14 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:43:14 INFO  time: compiled spark-tutorial in 0.62s
2022.02.10 21:43:17 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:43:20 INFO  time: compiled spark-tutorial in 3.36s
2022.02.10 21:43:20 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:43:21 INFO  time: compiled spark-tutorial in 0.58s
2022.02.10 21:43:26 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:43:27 INFO  time: compiled spark-tutorial in 1.36s
2022.02.10 21:43:27 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:43:29 INFO  time: compiled spark-tutorial in 1.3s
2022.02.10 21:44:09 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:44:11 INFO  time: compiled spark-tutorial in 1.99s
2022.02.10 21:44:12 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:44:14 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:44:14 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:44:14 INFO  time: compiled spark-tutorial in 1.58s
2022.02.10 21:44:14 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:44:15 INFO  time: compiled spark-tutorial in 0.78s
2022.02.10 21:44:17 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:44:19 INFO  time: compiled spark-tutorial in 1.7s
2022.02.10 21:44:24 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 3h 21m 40.871s)
2022.02.10 21:44:24 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.10 21:44:24 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.10 21:44:25 INFO  Starting debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 21:44:29 INFO  Trying to attach to remote debuggee VM localhost:55272 .
2022.02.10 21:44:29 INFO  Attaching to debuggee VM succeeded.
2022.02.10 21:44:30 INFO  Canceling debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 21:44:29 INFO  Closing debug server tcp://0.0.0.0:55265
2022.02.10 21:45:58 INFO  shutting down Metals
2022.02.10 21:45:58 INFO  Shut down connection with build server.
2022.02.10 21:45:58 INFO  Shut down connection with build server.
2022.02.10 21:45:58 INFO  Shut down connection with build server.
2022.02.10 21:46:21 INFO  tracing is disabled for protocol LSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/lsp.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/lsp.trace.json
2022.02.10 21:46:22 INFO  logging to file /Users/Johann/Documents/GitHub/spark-tutorial/.metals/metals.log
2022.02.10 21:46:22 INFO  Started: Metals version 0.11.1 in workspace '/Users/Johann/Documents/GitHub/spark-tutorial' for client Visual Studio Code 1.64.2.
2022.02.10 21:46:22 INFO  Parse release: 11.0.1
2022.02.10 21:46:25 INFO  time: initialize in 3.14s
2022.02.10 21:46:26 INFO  Attempting to connect to the build server...
2022.02.10 21:46:26 INFO  skipping build import with status 'Installed'
2022.02.10 21:46:26 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/bsp.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/bsp.trace.json
2022.02.10 21:46:26 INFO  Attempting to connect to the build server...
2022.02.10 21:46:26 INFO  Attempting to connect to the build server...
2022.02.10 21:46:26 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/project/project/.metals/bsp.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/bsp.trace.json
2022.02.10 21:46:26 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/project/.metals/bsp.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/bsp.trace.json
2022.02.10 21:46:26 INFO  time: Connected to build server in 0.42s
2022.02.10 21:46:26 INFO  Connected to Build server: Bloop v1.4.12
2022.02.10 21:46:37 INFO  time: indexed workspace in 10s
Feb. 10, 2022 9:47:04 NACHM. org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
Feb. 10, 2022 9:47:45 NACHM. org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
Feb. 10, 2022 9:48:02 NACHM. org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
2022.02.10 21:51:24 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:51:26 INFO  time: compiled spark-tutorial in 2.02s
2022.02.10 21:51:26 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:51:27 INFO  time: compiled spark-tutorial in 0.67s
2022.02.10 21:51:31 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:51:35 INFO  time: compiled spark-tutorial in 3.32s
2022.02.10 21:51:38 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:51:39 INFO  time: compiled spark-tutorial in 1.52s
2022.02.10 21:52:46 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.10 21:52:47 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.10 21:52:47 INFO  Starting debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 21:52:51 INFO  Trying to attach to remote debuggee VM localhost:55537 .
2022.02.10 21:52:51 INFO  Attaching to debuggee VM succeeded.
2022.02.10 21:52:52 INFO  Canceling debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 21:52:52 INFO  Closing debug server tcp://0.0.0.0:55531
Feb. 10, 2022 9:52:52 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireError
SEVERE: java.net.SocketException: Socket closed
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.net.SocketException: Socket closed
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.debug.SocketEndpoint.consume(SocketEndpoint.scala:22)
	at scala.meta.internal.metals.debug.MessageIdAdapter.consume(MessageIdAdapter.scala:43)
	at scala.meta.internal.metals.debug.ServerAdapter.send(ServerAdapter.scala:30)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleClientMessage$1(DebugProxy.scala:138)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToClient$1(DebugProxy.scala:63)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketException: Socket closed
	at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:113)
	at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:69)
	... 21 more

2022.02.10 21:53:32 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:53:33 INFO  time: compiled spark-tutorial in 1.84s
2022.02.10 21:53:36 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:53:39 INFO  time: compiled spark-tutorial in 2.73s
2022.02.10 21:56:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:56:38 INFO  time: compiled spark-tutorial in 1.86s
2022.02.10 21:56:39 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:56:39 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:56:40 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:56:40 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:56:41 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:56:43 INFO  time: compiled spark-tutorial in 1.9s
2022.02.10 21:56:48 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:56:50 INFO  time: compiled spark-tutorial in 1.83s
2022.02.10 21:56:51 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:56:51 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:56:51 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:56:53 INFO  time: compiled spark-tutorial in 1.35s
2022.02.10 21:59:31 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:59:33 INFO  time: compiled spark-tutorial in 2.41s
2022.02.10 21:59:40 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:59:40 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:59:41 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:59:42 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:59:42 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 21:59:43 INFO  time: compiled spark-tutorial in 1.65s
2022.02.10 21:59:45 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:59:46 INFO  time: compiled spark-tutorial in 1.79s
2022.02.10 21:59:52 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:59:52 INFO  time: compiled spark-tutorial in 0.27s
2022.02.10 21:59:54 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 21:59:55 INFO  time: compiled spark-tutorial in 1.63s
2022.02.10 21:59:59 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:00:01 INFO  time: compiled spark-tutorial in 1.91s
2022.02.10 22:00:05 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:00:05 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:00:05 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:00:06 INFO  time: compiled spark-tutorial in 1.63s
2022.02.10 22:01:39 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:01:39 INFO  time: compiled spark-tutorial in 0.22s
2022.02.10 22:01:44 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:01:44 INFO  time: compiled spark-tutorial in 0.25s
2022.02.10 22:01:48 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:01:48 INFO  time: compiled spark-tutorial in 0.25s
2022.02.10 22:01:49 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:01:49 INFO  time: compiled spark-tutorial in 0.24s
2022.02.10 22:01:53 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:01:53 INFO  time: compiled spark-tutorial in 0.22s
2022.02.10 22:01:56 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:01:57 INFO  time: compiled spark-tutorial in 1.45s
2022.02.10 22:02:34 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:02:34 INFO  time: compiled spark-tutorial in 0.13s
2022.02.10 22:02:36 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:02:36 INFO  time: compiled spark-tutorial in 0.11s
2022.02.10 22:02:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:02:39 INFO  time: compiled spark-tutorial in 1.49s
2022.02.10 22:02:45 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:02:47 INFO  time: compiled spark-tutorial in 1.33s
2022.02.10 22:02:50 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:02:52 INFO  time: compiled spark-tutorial in 1.65s
2022.02.10 22:03:00 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:03:02 INFO  time: compiled spark-tutorial in 1.37s
2022.02.10 22:03:06 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:03:06 INFO  time: compiled spark-tutorial in 0.13s
2022.02.10 22:03:12 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:03:14 INFO  time: compiled spark-tutorial in 2.27s
2022.02.10 22:03:16 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 16m 49.667s)
2022.02.10 22:03:16 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.10 22:03:16 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.10 22:03:17 INFO  Starting debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 22:03:21 INFO  Trying to attach to remote debuggee VM localhost:55822 .
2022.02.10 22:03:21 INFO  Attaching to debuggee VM succeeded.
2022.02.10 22:03:23 INFO  Canceling debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 22:03:23 INFO  Closing debug server tcp://0.0.0.0:55815
2022.02.10 22:03:51 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:03:51 INFO  time: compiled spark-tutorial in 0.14s
2022.02.10 22:03:53 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:03:55 INFO  time: compiled spark-tutorial in 1.62s
2022.02.10 22:04:00 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:04:02 INFO  time: compiled spark-tutorial in 1.57s
2022.02.10 22:04:08 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:04:10 INFO  time: compiled spark-tutorial in 1.86s
2022.02.10 22:04:14 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:04:15 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:04:15 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:04:16 INFO  time: compiled spark-tutorial in 1.82s
2022.02.10 22:04:18 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:04:20 INFO  time: compiled spark-tutorial in 1.66s
2022.02.10 22:04:21 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:04:23 INFO  time: compiled spark-tutorial in 1.62s
2022.02.10 22:05:15 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 18m 49.103s)
2022.02.10 22:05:15 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.10 22:05:15 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.10 22:05:16 INFO  Starting debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 22:05:20 INFO  Trying to attach to remote debuggee VM localhost:55927 .
2022.02.10 22:05:20 INFO  Attaching to debuggee VM succeeded.
2022.02.10 22:05:21 INFO  Canceling debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 22:05:21 INFO  Closing debug server tcp://0.0.0.0:55921
2022.02.10 22:06:14 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:06:16 INFO  time: compiled spark-tutorial in 2.1s
2022.02.10 22:06:21 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:06:21 INFO  time: compiled spark-tutorial in 0.22s
2022.02.10 22:06:25 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:06:27 INFO  time: compiled spark-tutorial in 1.67s
2022.02.10 22:06:28 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:06:30 INFO  time: compiled spark-tutorial in 1.41s
2022.02.10 22:06:38 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:06:39 INFO  time: compiled spark-tutorial in 1.58s
2022.02.10 22:06:46 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 20m 19.793s)
2022.02.10 22:06:46 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.10 22:06:47 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.10 22:06:47 INFO  Starting debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 22:06:51 INFO  Trying to attach to remote debuggee VM localhost:55985 .
2022.02.10 22:06:51 INFO  Attaching to debuggee VM succeeded.
2022.02.10 22:06:52 INFO  Canceling debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 22:06:51 INFO  Closing debug server tcp://0.0.0.0:55977
2022.02.10 22:06:58 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:06:58 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:08:16 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:08:16 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:10:21 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:10:21 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:11:47 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:11:47 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:11:48 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:11:49 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:11:49 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:11:50 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:11:50 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:11:50 INFO  time: compiled spark-tutorial in 2.27s
2022.02.10 22:11:52 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:11:54 INFO  time: compiled spark-tutorial in 2.03s
2022.02.10 22:11:56 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:11:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:11:56 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:11:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:11:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:11:58 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:12:00 INFO  time: compiled spark-tutorial in 2.07s
2022.02.10 22:12:15 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 25m 49.166s)
2022.02.10 22:12:16 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.10 22:12:16 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.10 22:12:16 INFO  Starting debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 22:12:20 INFO  Trying to attach to remote debuggee VM localhost:56144 .
2022.02.10 22:12:20 INFO  Attaching to debuggee VM succeeded.
2022.02.10 22:12:21 INFO  Canceling debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 22:12:20 INFO  Closing debug server tcp://0.0.0.0:56137
2022.02.10 22:12:52 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:12:53 INFO  time: compiled spark-tutorial in 1.62s
2022.02.10 22:12:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:12:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:12:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:12:55 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:12:55 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:12:55 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:12:56 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:12:55 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:12:56 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:12:56 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:12:56 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:12:56 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:12:58 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:12:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:12:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/ScalaIntroduction.scala
2022.02.10 22:12:59 INFO  time: compiled spark-tutorial in 1.57s
2022.02.10 22:12:59 INFO  compiling spark-tutorial (1 scala source)
2022.02.10 22:12:59 INFO  time: compiled spark-tutorial in 0.58s
2022.02.10 22:25:09 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 38m 42.382s)
2022.02.10 22:25:09 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.10 22:25:09 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.10 22:25:09 INFO  Starting debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 22:25:14 INFO  Trying to attach to remote debuggee VM localhost:56300 .
2022.02.10 22:25:14 INFO  Attaching to debuggee VM succeeded.
2022.02.10 22:25:15 INFO  Canceling debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.10 22:25:14 INFO  Closing debug server tcp://0.0.0.0:56293
Feb. 10, 2022 10:25:24 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 962
2022.02.10 22:25:53 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 39m 26.434s)
2022.02.10 22:25:53 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.10 22:25:53 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.10 22:25:53 INFO  Starting debug proxy for [de.hpi.getting_started.SparkIntroduction]
2022.02.10 22:25:56 INFO  Trying to attach to remote debuggee VM localhost:56322 .
2022.02.10 22:25:56 INFO  Attaching to debuggee VM succeeded.
2022.02.10 22:25:57 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.10 22:25:57 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.10 22:25:57 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.10 22:25:57 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.10 22:25:57 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.10 22:25:57 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.10 22:26:12 INFO  Canceling debug proxy for [de.hpi.getting_started.SparkIntroduction]
2022.02.10 22:26:12 INFO  Closing debug server tcp://0.0.0.0:56316
2022.02.11 10:01:15 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 12h 14m 48.524s)
2022.02.11 10:01:15 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.11 10:01:16 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.11 10:01:16 INFO  Starting debug proxy for [de.hpi.getting_started.SparkIntroduction]
2022.02.11 10:01:23 INFO  Trying to attach to remote debuggee VM localhost:61585 .
2022.02.11 10:01:23 INFO  Attaching to debuggee VM succeeded.
2022.02.11 10:01:23 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 12h 14m 58.117s)
2022.02.11 10:01:25 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.11 10:01:25 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.11 10:01:25 INFO  Starting debug proxy for [de.hpi.getting_started.SparkIntroduction]
2022.02.11 10:01:28 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.11 10:01:28 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.11 10:01:28 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.11 10:01:28 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.11 10:01:28 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.11 10:01:28 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.11 10:01:35 INFO  Trying to attach to remote debuggee VM localhost:61602 .
2022.02.11 10:01:35 INFO  Attaching to debuggee VM succeeded.
2022.02.11 10:01:38 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.11 10:01:38 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.11 10:01:38 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.11 10:01:38 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.11 10:01:38 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.11 10:01:38 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.11 10:01:54 INFO  Canceling debug proxy for [de.hpi.getting_started.SparkIntroduction]
2022.02.11 10:01:54 INFO  Closing debug server tcp://0.0.0.0:61576
2022.02.11 10:01:54 ERROR Read data from io exception: java.net.SocketException: Socket closed
2022.02.11 10:02:03 INFO  Canceling debug proxy for [de.hpi.getting_started.SparkIntroduction]
2022.02.11 10:02:03 INFO  Closing debug server tcp://0.0.0.0:61591
2022.02.11 10:03:18 INFO  compiling spark-tutorial (1 scala source)
2022.02.11 10:03:23 WARN  there was one deprecation warning (since 2.11.0); re-run with -deprecation for details
2022.02.11 10:03:23 INFO  time: compiled spark-tutorial in 5.08s
2022.02.11 10:03:23 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:03:23 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:03:24 INFO  compiling spark-tutorial (1 scala source)
2022.02.11 10:03:25 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:03:25 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:03:25 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:03:26 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:03:27 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:03:27 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:03:28 WARN  there was one deprecation warning (since 2.11.0); re-run with -deprecation for details
2022.02.11 10:03:28 INFO  time: compiled spark-tutorial in 3.95s
2022.02.11 10:03:33 INFO  compiling spark-tutorial (1 scala source)
2022.02.11 10:03:36 WARN  there was one deprecation warning (since 2.11.0); re-run with -deprecation for details
2022.02.11 10:03:36 INFO  time: compiled spark-tutorial in 2.96s
2022.02.11 10:03:38 INFO  compiling spark-tutorial (1 scala source)
2022.02.11 10:03:41 WARN  there was one deprecation warning (since 2.11.0); re-run with -deprecation for details
2022.02.11 10:03:41 INFO  time: compiled spark-tutorial in 3.07s
2022.02.11 10:05:08 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 12h 18m 41.628s)
2022.02.11 10:05:08 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.11 10:05:08 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.11 10:05:09 INFO  Starting debug proxy for [de.hpi.getting_started.SparkIntroduction]
2022.02.11 10:05:13 INFO  Trying to attach to remote debuggee VM localhost:61686 .
2022.02.11 10:05:13 INFO  Attaching to debuggee VM succeeded.
2022.02.11 10:05:15 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.11 10:05:15 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.11 10:05:15 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.11 10:05:15 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.11 10:05:15 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.11 10:05:15 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.11 10:05:35 INFO  Canceling debug proxy for [de.hpi.getting_started.SparkIntroduction]
2022.02.11 10:05:35 INFO  Closing debug server tcp://0.0.0.0:61680
2022.02.11 10:07:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.11 10:07:06 WARN  there was one deprecation warning (since 2.11.0); re-run with -deprecation for details
2022.02.11 10:07:06 INFO  time: compiled spark-tutorial in 3.78s
2022.02.11 10:07:08 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:07:08 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:07:08 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:07:08 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:07:09 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:07:09 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:07:11 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:07:11 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:07:12 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:07:11 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:07:13 INFO  compiling spark-tutorial (1 scala source)
2022.02.11 10:07:15 WARN  there was one deprecation warning (since 2.11.0); re-run with -deprecation for details
2022.02.11 10:07:15 INFO  time: compiled spark-tutorial in 2.77s
2022.02.11 10:07:23 INFO  compiling spark-tutorial (1 scala source)
2022.02.11 10:07:26 WARN  there was one deprecation warning (since 2.11.0); re-run with -deprecation for details
2022.02.11 10:07:26 INFO  time: compiled spark-tutorial in 3.05s
2022.02.11 10:07:26 INFO  compiling spark-tutorial (1 scala source)
2022.02.11 10:07:28 WARN  there was one deprecation warning (since 2.11.0); re-run with -deprecation for details
2022.02.11 10:07:28 INFO  time: compiled spark-tutorial in 1.83s
2022.02.11 10:07:31 INFO  compiling spark-tutorial (1 scala source)
2022.02.11 10:07:34 WARN  there was one deprecation warning (since 2.11.0); re-run with -deprecation for details
2022.02.11 10:07:34 INFO  time: compiled spark-tutorial in 2.48s
2022.02.11 10:15:36 INFO  compiling spark-tutorial (1 scala source)
2022.02.11 10:15:36 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:15:36 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:15:40 WARN  there was one deprecation warning (since 2.11.0); re-run with -deprecation for details
2022.02.11 10:15:40 INFO  time: compiled spark-tutorial in 3.72s
2022.02.11 10:25:43 INFO  compiling spark-tutorial (1 scala source)
2022.02.11 10:25:46 WARN  there was one deprecation warning (since 2.11.0); re-run with -deprecation for details
2022.02.11 10:25:46 INFO  time: compiled spark-tutorial in 3.18s
2022.02.11 10:25:46 INFO  compiling spark-tutorial (1 scala source)
2022.02.11 10:25:47 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:47 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:48 INFO  time: compiled spark-tutorial in 1.08s
2022.02.11 10:25:48 INFO  compiling spark-tutorial (1 scala source)
2022.02.11 10:25:48 INFO  time: compiled spark-tutorial in 0.78s
2022.02.11 10:25:50 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:50 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:50 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:50 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:51 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:51 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:51 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:51 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:52 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:51 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:52 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:52 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:53 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:53 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:53 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:55 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:56 INFO  compiling spark-tutorial (1 scala source)
2022.02.11 10:25:56 INFO  time: compiled spark-tutorial in 0.82s
2022.02.11 10:25:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:25:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:00 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:01 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:01 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:01 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:01 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:01 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:01 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:02 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.11 10:26:02 INFO  time: compiled spark-tutorial in 0.69s
2022.02.11 10:26:03 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:03 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:04 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:03 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:05 INFO  compiling spark-tutorial (1 scala source)
2022.02.11 10:26:06 INFO  time: compiled spark-tutorial in 1.03s
2022.02.11 10:26:07 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:07 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:09 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:09 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:09 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:09 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:09 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.11 10:26:11 INFO  compiling spark-tutorial (1 scala source)
2022.02.11 10:26:11 INFO  time: compiled spark-tutorial in 0.96s
2022.02.11 10:26:12 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:58:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:58:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:09 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:09 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:09 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:09 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:10 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:09 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:11 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:11 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:12 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 10:59:12 INFO  time: compiled spark-tutorial in 0.73s
2022.02.12 10:59:13 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:13 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:13 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:14 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:14 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 10:59:13 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:14 INFO  time: compiled spark-tutorial in 0.58s
2022.02.12 10:59:16 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:16 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:17 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:17 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:17 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:18 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 10:59:18 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:18 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:18 INFO  time: compiled spark-tutorial in 0.71s
2022.02.12 10:59:19 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:21 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:21 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:22 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 10:59:22 INFO  time: compiled spark-tutorial in 0.5s
2022.02.12 10:59:26 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:27 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:27 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 10:59:28 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 10:59:31 WARN  there was one deprecation warning (since 2.11.0); re-run with -deprecation for details
2022.02.12 10:59:31 INFO  time: compiled spark-tutorial in 2.33s
2022.02.12 10:59:36 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 10:59:38 WARN  there was one deprecation warning (since 2.11.0); re-run with -deprecation for details
2022.02.12 10:59:38 INFO  time: compiled spark-tutorial in 1.59s
Feb. 12, 2022 11:02:25 VORM. org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
2022.02.12 11:02:41 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 11:02:43 INFO  time: compiled spark-tutorial in 2.44s
Feb. 12, 2022 11:09:32 VORM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1555
2022.02.12 11:09:32 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 11:09:33 WARN  there was one deprecation warning (since 2.11.0); re-run with -deprecation for details
2022.02.12 11:09:33 INFO  time: compiled spark-tutorial in 1.96s
2022.02.12 11:25:48 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 11:25:48 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/getting_started/SparkIntroduction.scala
2022.02.12 12:43:57 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 38h 57m 30.731s)
2022.02.12 12:43:57 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 12:43:57 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 12:43:58 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 12:44:04 INFO  Trying to attach to remote debuggee VM localhost:58343 .
2022.02.12 12:44:04 INFO  Attaching to debuggee VM succeeded.
2022.02.12 12:44:04 ERROR Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: Index 0 out of bounds for length 0
2022.02.12 12:44:04 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:7)
2022.02.12 12:44:04 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:5)
2022.02.12 12:44:04 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.12 12:44:04 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.12 12:44:04 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.12 12:44:04 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.12 12:44:04 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.12 12:44:04 ERROR 	at scala.App.main(App.scala:80)
2022.02.12 12:44:04 ERROR 	at scala.App.main$(App.scala:78)
2022.02.12 12:44:04 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:5)
2022.02.12 12:44:04 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.12 12:44:04 INFO  Closing debug server tcp://0.0.0.0:58336
Feb. 12, 2022 12:44:05 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireStreamClosed
INFO: Connection reset
java.net.SocketException: Connection reset
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:79)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)

2022.02.12 12:44:05 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 12:51:13 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 39h 4m 46.547s)
2022.02.12 12:51:13 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 12:51:13 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 12:51:13 INFO  Starting debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.12 12:51:18 INFO  Trying to attach to remote debuggee VM localhost:58443 .
2022.02.12 12:51:22 INFO  Attaching to debuggee VM succeeded.
2022.02.12 12:51:23 INFO  Canceling debug proxy for [de.hpi.getting_started.ScalaIntroduction]
2022.02.12 12:51:23 INFO  Closing debug server tcp://0.0.0.0:58435
2022.02.12 12:51:54 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 12:51:54 INFO  time: compiled spark-tutorial in 0.33s
2022.02.12 12:51:57 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 12:51:57 INFO  time: compiled spark-tutorial in 0.19s
2022.02.12 12:51:58 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 12:52:00 INFO  time: compiled spark-tutorial in 1.88s
2022.02.12 12:52:05 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 12:52:05 INFO  time: compiled spark-tutorial in 0.22s
2022.02.12 12:52:20 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 12:52:20 INFO  time: compiled spark-tutorial in 0.43s
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:20: stale bloop error: not found: value /
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                   ^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:26: stale bloop error: not found: value /
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                         ^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:33: stale bloop error: not found: value /
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                ^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:43: stale bloop error: not found: value /
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                          ^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:50: stale bloop error: not found: value /
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                 ^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:57: stale bloop error: not found: value tutorial
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                        ^^^^^^^^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:66: stale bloop error: not found: value src
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                 ^^^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:70: stale bloop error: missing argument list for method main in trait App
Unapplied methods are only converted to functions when a function type is expected.
You can make this conversion explicit by writing `main _` or `main(_)` instead of `main`.
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                     ^^^^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:84: stale bloop error: not found: value hpi
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                   ^^^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:88: stale bloop error: not found: value dbsII_exercises
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                       ^^^^^^^^^^^^^^^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:104: stale bloop error: not found: value Test_Input_Spark
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                                       ^^^^^^^^^^^^^^^^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:20: stale bloop error: not found: value /
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                   ^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:26: stale bloop error: not found: value /
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                         ^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:33: stale bloop error: not found: value /
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                ^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:43: stale bloop error: not found: value /
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                          ^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:50: stale bloop error: not found: value /
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                 ^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:57: stale bloop error: not found: value tutorial
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                        ^^^^^^^^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:66: stale bloop error: not found: value src
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                 ^^^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:70: stale bloop error: missing argument list for method main in trait App
Unapplied methods are only converted to functions when a function type is expected.
You can make this conversion explicit by writing `main _` or `main(_)` instead of `main`.
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                     ^^^^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:84: stale bloop error: not found: value hpi
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                   ^^^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:88: stale bloop error: not found: value dbsII_exercises
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                       ^^^^^^^^^^^^^^^
2022.02.12 12:52:27 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:104: stale bloop error: not found: value Test_Input_Spark
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                                       ^^^^^^^^^^^^^^^^
2022.02.12 12:52:28 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:20: stale bloop error: not found: value /
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                   ^
2022.02.12 12:52:28 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:26: stale bloop error: not found: value /
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                         ^
2022.02.12 12:52:28 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:33: stale bloop error: not found: value /
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                ^
2022.02.12 12:52:28 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:43: stale bloop error: not found: value /
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                          ^
2022.02.12 12:52:28 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:50: stale bloop error: not found: value /
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                 ^
2022.02.12 12:52:28 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:57: stale bloop error: not found: value tutorial
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                        ^^^^^^^^
2022.02.12 12:52:28 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:66: stale bloop error: not found: value src
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                 ^^^
2022.02.12 12:52:28 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:70: stale bloop error: missing argument list for method main in trait App
Unapplied methods are only converted to functions when a function type is expected.
You can make this conversion explicit by writing `main _` or `main(_)` instead of `main`.
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                     ^^^^
2022.02.12 12:52:28 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:84: stale bloop error: not found: value hpi
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                   ^^^
2022.02.12 12:52:28 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:88: stale bloop error: not found: value dbsII_exercises
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                       ^^^^^^^^^^^^^^^
2022.02.12 12:52:28 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:104: stale bloop error: not found: value Test_Input_Spark
  val pathToData = /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                                       ^^^^^^^^^^^^^^^^
2022.02.12 12:52:28 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 12:52:28 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:20: stale bloop error: unclosed string literal
  val pathToData = "/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                   ^
2022.02.12 12:52:28 INFO  time: compiled spark-tutorial in 0.18s
2022.02.12 12:52:29 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:20: stale bloop error: unclosed string literal
  val pathToData = "/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                   ^
2022.02.12 12:52:29 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:20: stale bloop error: unclosed string literal
  val pathToData = "/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                   ^
2022.02.12 12:52:29 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:20: stale bloop error: unclosed string literal
  val pathToData = "/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                   ^
2022.02.12 12:52:30 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 12:52:30 INFO  time: compiled spark-tutorial in 0.38s
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:20: stale bloop error: value Users is not a member of Symbol
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                   ^^^^^^^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:27: stale bloop error: not found: value /
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                          ^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:34: stale bloop error: not found: value /
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                 ^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:44: stale bloop error: not found: value /
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                           ^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:51: stale bloop error: not found: value /
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                  ^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:58: stale bloop error: not found: value tutorial
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                         ^^^^^^^^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:67: stale bloop error: not found: value src
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                  ^^^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:71: stale bloop error: missing argument list for method main in trait App
Unapplied methods are only converted to functions when a function type is expected.
You can make this conversion explicit by writing `main _` or `main(_)` instead of `main`.
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                      ^^^^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:85: stale bloop error: not found: value hpi
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                    ^^^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:89: stale bloop error: not found: value dbsII_exercises
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                        ^^^^^^^^^^^^^^^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:105: stale bloop error: not found: value Test_Input_Spark
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                                        ^^^^^^^^^^^^^^^^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:20: stale bloop error: value Users is not a member of Symbol
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                   ^^^^^^^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:27: stale bloop error: not found: value /
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                          ^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:34: stale bloop error: not found: value /
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                 ^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:44: stale bloop error: not found: value /
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                           ^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:51: stale bloop error: not found: value /
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                  ^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:58: stale bloop error: not found: value tutorial
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                         ^^^^^^^^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:67: stale bloop error: not found: value src
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                  ^^^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:71: stale bloop error: missing argument list for method main in trait App
Unapplied methods are only converted to functions when a function type is expected.
You can make this conversion explicit by writing `main _` or `main(_)` instead of `main`.
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                      ^^^^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:85: stale bloop error: not found: value hpi
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                    ^^^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:89: stale bloop error: not found: value dbsII_exercises
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                        ^^^^^^^^^^^^^^^
2022.02.12 12:52:33 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:105: stale bloop error: not found: value Test_Input_Spark
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                                        ^^^^^^^^^^^^^^^^
2022.02.12 12:52:34 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:20: stale bloop error: value Users is not a member of Symbol
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                   ^^^^^^^
2022.02.12 12:52:34 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:27: stale bloop error: not found: value /
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                          ^
2022.02.12 12:52:34 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:34: stale bloop error: not found: value /
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                 ^
2022.02.12 12:52:34 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:44: stale bloop error: not found: value /
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                           ^
2022.02.12 12:52:34 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:51: stale bloop error: not found: value /
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                  ^
2022.02.12 12:52:34 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:58: stale bloop error: not found: value tutorial
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                         ^^^^^^^^
2022.02.12 12:52:34 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:67: stale bloop error: not found: value src
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                  ^^^
2022.02.12 12:52:34 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:71: stale bloop error: missing argument list for method main in trait App
Unapplied methods are only converted to functions when a function type is expected.
You can make this conversion explicit by writing `main _` or `main(_)` instead of `main`.
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                      ^^^^
2022.02.12 12:52:34 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:85: stale bloop error: not found: value hpi
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                    ^^^
2022.02.12 12:52:34 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:89: stale bloop error: not found: value dbsII_exercises
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                        ^^^^^^^^^^^^^^^
2022.02.12 12:52:34 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:105: stale bloop error: not found: value Test_Input_Spark
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark//args(0)
                                                                                                        ^^^^^^^^^^^^^^^^
2022.02.12 12:52:34 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 12:52:34 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:122: stale bloop error: unclosed string literal
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark"//args(0)
                                                                                                                         ^
2022.02.12 12:52:34 INFO  time: compiled spark-tutorial in 0.18s
2022.02.12 12:52:36 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:122: stale bloop error: unclosed string literal
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark"//args(0)
                                                                                                                         ^
2022.02.12 12:52:36 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala:7:122: stale bloop error: unclosed string literal
  val pathToData = '/Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark"//args(0)
                                                                                                                         ^
2022.02.12 12:52:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 12:52:38 INFO  time: compiled spark-tutorial in 1.27s
2022.02.12 12:56:34 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 39h 10m 7.322s)
2022.02.12 12:56:34 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 12:56:34 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 12:56:34 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 12:56:38 INFO  Trying to attach to remote debuggee VM localhost:58585 .
2022.02.12 12:56:38 INFO  Attaching to debuggee VM succeeded.
2022.02.12 12:56:39 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 12:56:39 ERROR 22/02/12 12:56:39 WARN Utils: Your hostname, SchulzeTastPro-2.local resolves to a loopback address: 127.0.0.1; using 192.168.178.30 instead (on interface en0)
2022.02.12 12:56:39 ERROR 22/02/12 12:56:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2022.02.12 12:56:39 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 12:56:39 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 12:56:39 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 12:56:39 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 12:56:39 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 12:56:39 ERROR 22/02/12 12:56:39 INFO SparkContext: Running Spark version 3.0.0
2022.02.12 12:56:39 ERROR 22/02/12 12:56:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022.02.12 12:56:39 ERROR 22/02/12 12:56:39 INFO ResourceUtils: ==============================================================
2022.02.12 12:56:39 ERROR 22/02/12 12:56:39 INFO ResourceUtils: Resources for spark.driver:
2022.02.12 12:56:39 ERROR 
2022.02.12 12:56:39 ERROR 22/02/12 12:56:39 INFO ResourceUtils: ==============================================================
2022.02.12 12:56:39 ERROR 22/02/12 12:56:39 INFO SparkContext: Submitted application: SparkTutorial
2022.02.12 12:56:39 ERROR 22/02/12 12:56:39 INFO SecurityManager: Changing view acls to: Johann
2022.02.12 12:56:39 ERROR 22/02/12 12:56:39 INFO SecurityManager: Changing modify acls to: Johann
2022.02.12 12:56:39 ERROR 22/02/12 12:56:39 INFO SecurityManager: Changing view acls groups to: 
2022.02.12 12:56:39 ERROR 22/02/12 12:56:39 INFO SecurityManager: Changing modify acls groups to: 
2022.02.12 12:56:39 ERROR 22/02/12 12:56:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Johann); groups with view permissions: Set(); users  with modify permissions: Set(Johann); groups with modify permissions: Set()
2022.02.12 12:56:39 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:56:40 ERROR 22/02/12 12:56:40 INFO Utils: Successfully started service 'sparkDriver' on port 58587.
2022.02.12 12:56:40 ERROR 22/02/12 12:56:40 INFO SparkEnv: Registering MapOutputTracker
2022.02.12 12:56:40 ERROR 22/02/12 12:56:40 INFO SparkEnv: Registering BlockManagerMaster
2022.02.12 12:56:40 ERROR 22/02/12 12:56:40 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022.02.12 12:56:40 ERROR 22/02/12 12:56:40 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022.02.12 12:56:40 ERROR 22/02/12 12:56:40 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2022.02.12 12:56:40 ERROR 22/02/12 12:56:40 INFO DiskBlockManager: Created local directory at /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/blockmgr-f57d2a40-43ed-4753-92ea-f6d7ab89bcf2
2022.02.12 12:56:40 ERROR 22/02/12 12:56:40 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
2022.02.12 12:56:40 ERROR 22/02/12 12:56:40 INFO SparkEnv: Registering OutputCommitCoordinator
2022.02.12 12:56:40 ERROR 22/02/12 12:56:40 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2022.02.12 12:56:40 ERROR 22/02/12 12:56:40 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.178.30:4040
2022.02.12 12:56:40 ERROR 22/02/12 12:56:41 INFO Executor: Starting executor ID driver on host 192.168.178.30
2022.02.12 12:56:40 ERROR 22/02/12 12:56:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58588.
2022.02.12 12:56:40 ERROR 22/02/12 12:56:41 INFO NettyBlockTransferService: Server created on 192.168.178.30:58588
2022.02.12 12:56:40 ERROR 22/02/12 12:56:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022.02.12 12:56:40 ERROR 22/02/12 12:56:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.178.30, 58588, None)
2022.02.12 12:56:41 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:56:40 ERROR 22/02/12 12:56:41 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.178.30:58588 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.178.30, 58588, None)
2022.02.12 12:56:40 ERROR 22/02/12 12:56:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.178.30, 58588, None)
2022.02.12 12:56:40 ERROR 22/02/12 12:56:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.178.30, 58588, None)
2022.02.12 12:56:41 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:56:41 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:56:41 ERROR 22/02/12 12:56:41 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse').
2022.02.12 12:56:41 ERROR 22/02/12 12:56:41 INFO SharedState: Warehouse path is 'file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse'.
2022.02.12 12:56:41 ERROR 22/02/12 12:56:42 INFO InMemoryFileIndex: It took 48 ms to list leaf files for 1 paths.
2022.02.12 12:56:42 ERROR Exception in thread "main" org.apache.spark.sql.AnalysisException: Unable to infer schema for CSV. It must be specified manually.;
2022.02.12 12:56:42 ERROR 	at org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$12(DataSource.scala:195)
2022.02.12 12:56:42 ERROR 	at scala.Option.getOrElse(Option.scala:189)
2022.02.12 12:56:42 ERROR 	at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:195)
2022.02.12 12:56:42 ERROR 	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:401)
2022.02.12 12:56:42 ERROR 	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:279)
2022.02.12 12:56:42 ERROR 	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:268)
2022.02.12 12:56:42 ERROR 	at scala.Option.getOrElse(Option.scala:189)
2022.02.12 12:56:42 ERROR 	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:268)
2022.02.12 12:56:42 ERROR 	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:214)
2022.02.12 12:56:42 ERROR 	at de.hpi.dbsII_exercises.IOHelper$.readSparkCSV(IOHelper.scala:41)
2022.02.12 12:56:42 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:21)
2022.02.12 12:56:42 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:5)
2022.02.12 12:56:42 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.12 12:56:42 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.12 12:56:42 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.12 12:56:42 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.12 12:56:42 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.12 12:56:42 ERROR 	at scala.App.main(App.scala:80)
2022.02.12 12:56:42 ERROR 	at scala.App.main$(App.scala:78)
2022.02.12 12:56:42 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:5)
2022.02.12 12:56:42 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.12 12:56:42 ERROR 22/02/12 12:56:42 INFO SparkContext: Invoking stop() from shutdown hook
2022.02.12 12:56:42 ERROR 22/02/12 12:56:42 INFO SparkUI: Stopped Spark web UI at http://192.168.178.30:4040
2022.02.12 12:56:42 ERROR 22/02/12 12:56:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2022.02.12 12:56:42 ERROR 22/02/12 12:56:43 INFO MemoryStore: MemoryStore cleared
2022.02.12 12:56:42 ERROR 22/02/12 12:56:43 INFO BlockManager: BlockManager stopped
2022.02.12 12:56:42 ERROR 22/02/12 12:56:43 INFO BlockManagerMaster: BlockManagerMaster stopped
2022.02.12 12:56:42 ERROR 22/02/12 12:56:43 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2022.02.12 12:56:42 ERROR 22/02/12 12:56:43 INFO SparkContext: Successfully stopped SparkContext
2022.02.12 12:56:42 ERROR 22/02/12 12:56:43 INFO ShutdownHookManager: Shutdown hook called
2022.02.12 12:56:42 ERROR 22/02/12 12:56:43 INFO ShutdownHookManager: Deleting directory /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/spark-67a6183a-cac8-4adc-979d-5a1fb0607662
2022.02.12 12:56:42 INFO  Closing debug server tcp://0.0.0.0:58579
2022.02.12 12:56:43 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:56:43 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 12:57:38 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 39h 11m 11.733s)
2022.02.12 12:57:38 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 12:57:38 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 12:57:38 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 12:57:44 INFO  Trying to attach to remote debuggee VM localhost:58616 .
2022.02.12 12:57:44 INFO  Attaching to debuggee VM succeeded.
2022.02.12 12:57:45 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 12:57:45 ERROR 22/02/12 12:57:45 WARN Utils: Your hostname, SchulzeTastPro-2.local resolves to a loopback address: 127.0.0.1; using 192.168.178.30 instead (on interface en0)
2022.02.12 12:57:45 ERROR 22/02/12 12:57:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2022.02.12 12:57:45 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 12:57:45 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 12:57:45 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 12:57:45 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 12:57:45 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 12:57:45 ERROR 22/02/12 12:57:45 INFO SparkContext: Running Spark version 3.0.0
2022.02.12 12:57:45 ERROR 22/02/12 12:57:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022.02.12 12:57:45 ERROR 22/02/12 12:57:46 INFO ResourceUtils: ==============================================================
2022.02.12 12:57:45 ERROR 22/02/12 12:57:46 INFO ResourceUtils: Resources for spark.driver:
2022.02.12 12:57:45 ERROR 
2022.02.12 12:57:45 ERROR 22/02/12 12:57:46 INFO ResourceUtils: ==============================================================
2022.02.12 12:57:45 ERROR 22/02/12 12:57:46 INFO SparkContext: Submitted application: SparkTutorial
2022.02.12 12:57:45 ERROR 22/02/12 12:57:46 INFO SecurityManager: Changing view acls to: Johann
2022.02.12 12:57:45 ERROR 22/02/12 12:57:46 INFO SecurityManager: Changing modify acls to: Johann
2022.02.12 12:57:45 ERROR 22/02/12 12:57:46 INFO SecurityManager: Changing view acls groups to: 
2022.02.12 12:57:45 ERROR 22/02/12 12:57:46 INFO SecurityManager: Changing modify acls groups to: 
2022.02.12 12:57:45 ERROR 22/02/12 12:57:46 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Johann); groups with view permissions: Set(); users  with modify permissions: Set(Johann); groups with modify permissions: Set()
2022.02.12 12:57:46 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:57:46 ERROR 22/02/12 12:57:46 INFO Utils: Successfully started service 'sparkDriver' on port 58618.
2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO SparkEnv: Registering MapOutputTracker
2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO SparkEnv: Registering BlockManagerMaster
2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO DiskBlockManager: Created local directory at /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/blockmgr-7d92a4c9-0f22-46e3-ac67-4d36df64637d
2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO SparkEnv: Registering OutputCommitCoordinator
2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.178.30:4040
2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO Executor: Starting executor ID driver on host 192.168.178.30
2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58619.
2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO NettyBlockTransferService: Server created on 192.168.178.30:58619
2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.178.30, 58619, None)
2022.02.12 12:57:47 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.178.30:58619 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.178.30, 58619, None)
2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.178.30, 58619, None)
2022.02.12 12:57:47 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:57:46 ERROR 22/02/12 12:57:47 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.178.30, 58619, None)
2022.02.12 12:57:47 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:57:48 ERROR 22/02/12 12:57:48 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse').
2022.02.12 12:57:48 ERROR 22/02/12 12:57:48 INFO SharedState: Warehouse path is 'file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse'.
2022.02.12 12:57:49 ERROR 22/02/12 12:57:49 INFO InMemoryFileIndex: It took 96 ms to list leaf files for 1 paths.
2022.02.12 12:57:49 ERROR 22/02/12 12:57:49 INFO InMemoryFileIndex: It took 15 ms to list leaf files for 6 paths.
2022.02.12 12:57:52 ERROR 22/02/12 12:57:52 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 12:57:52 ERROR 22/02/12 12:57:52 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 12:57:52 ERROR 22/02/12 12:57:52 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2022.02.12 12:57:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:57:52 ERROR 22/02/12 12:57:52 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 12:57:52 ERROR 22/02/12 12:57:52 INFO CodeGenerator: Code generated in 220.815889 ms
2022.02.12 12:57:52 ERROR 22/02/12 12:57:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 12:57:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 12:57:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.178.30:58619 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO SparkContext: Created broadcast 0 from load at IOHelper.scala:41
2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 30064196 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO DAGScheduler: Got job 0 (load at IOHelper.scala:41) with 1 output partitions
2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO DAGScheduler: Final stage: ResultStage 0 (load at IOHelper.scala:41)
2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 12:57:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO DAGScheduler: Missing parents: List()
2022.02.12 12:57:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022.02.12 12:57:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022.02.12 12:57:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.178.30:58619 (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0))
2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7847 bytes)
2022.02.12 12:57:53 ERROR 22/02/12 12:57:53 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2022.02.12 12:57:53 ERROR 22/02/12 12:57:54 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark/part_1.csv, range: 0-8164356, partition values: [empty row]
2022.02.12 12:57:53 ERROR 22/02/12 12:57:54 INFO CodeGenerator: Code generated in 17.366896 ms
2022.02.12 12:57:53 ERROR 22/02/12 12:57:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1658 bytes result sent to driver
2022.02.12 12:57:53 ERROR 22/02/12 12:57:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 421 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 12:57:53 ERROR 22/02/12 12:57:54 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022.02.12 12:57:53 ERROR 22/02/12 12:57:54 INFO DAGScheduler: ResultStage 0 (load at IOHelper.scala:41) finished in 0,599 s
2022.02.12 12:57:53 ERROR 22/02/12 12:57:54 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 12:57:53 ERROR 22/02/12 12:57:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2022.02.12 12:57:53 ERROR 22/02/12 12:57:54 INFO DAGScheduler: Job 0 finished: load at IOHelper.scala:41, took 0,662567 s
2022.02.12 12:57:53 ERROR 22/02/12 12:57:54 INFO CodeGenerator: Code generated in 15.120157 ms
2022.02.12 12:57:53 ERROR 22/02/12 12:57:54 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 12:57:53 ERROR 22/02/12 12:57:54 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 12:57:53 ERROR 22/02/12 12:57:54 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 12:57:53 ERROR 22/02/12 12:57:54 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 12:57:53 ERROR 22/02/12 12:57:54 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 12:57:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 12:57:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.178.30:58619 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO SparkContext: Created broadcast 2 from load at IOHelper.scala:41
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 30064196 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO DAGScheduler: Got job 1 (load at IOHelper.scala:41) with 5 output partitions
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO DAGScheduler: Final stage: ResultStage 1 (load at IOHelper.scala:41)
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO DAGScheduler: Missing parents: List()
2022.02.12 12:57:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 12:57:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.1 KiB, free 2.2 GiB)
2022.02.12 12:57:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 2.2 GiB)
2022.02.12 12:57:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.178.30:58619 (size: 7.5 KiB, free: 2.2 GiB)
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7847 bytes)
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7847 bytes)
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 7847 bytes)
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, 192.168.178.30, executor driver, partition 3, PROCESS_LOCAL, 7847 bytes)
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark/part_1.csv, range: 0-8164356, partition values: [empty row]
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark/part_4.csv, range: 0-7878939, partition values: [empty row]
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark/part_0.csv, range: 0-7859637, partition values: [empty row]
2022.02.12 12:57:54 ERROR 22/02/12 12:57:54 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark/part_3.csv, range: 0-7712365, partition values: [empty row]
2022.02.12 12:57:56 ERROR 22/02/12 12:57:56 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.178.30:58619 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 12:57:56 ERROR 22/02/12 12:57:56 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.178.30:58619 in memory (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 12:57:59 ERROR 22/02/12 12:57:59 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark/part_4.csv, range: 0-7878939, partition values: [empty row]
2022.02.12 12:57:59 ERROR 22/02/12 12:57:59 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark/part_1.csv, range: 0-8164356, partition values: [empty row]
2022.02.12 12:57:59 ERROR 22/02/12 12:57:59 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark/part_0.csv, range: 0-7859637, partition values: [empty row]
2022.02.12 12:57:59 ERROR 22/02/12 12:57:59 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark/part_3.csv, range: 0-7712365, partition values: [empty row]
2022.02.12 12:58:03 ERROR 22/02/12 12:58:03 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1800 bytes result sent to driver
2022.02.12 12:58:03 ERROR 22/02/12 12:58:03 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1800 bytes result sent to driver
2022.02.12 12:58:03 ERROR 22/02/12 12:58:03 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1800 bytes result sent to driver
2022.02.12 12:58:03 ERROR 22/02/12 12:58:03 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1800 bytes result sent to driver
2022.02.12 12:58:03 ERROR 22/02/12 12:58:03 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5, 192.168.178.30, executor driver, partition 4, PROCESS_LOCAL, 7847 bytes)
2022.02.12 12:58:03 ERROR 22/02/12 12:58:03 INFO Executor: Running task 4.0 in stage 1.0 (TID 5)
2022.02.12 12:58:03 ERROR 22/02/12 12:58:03 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 8609 ms on 192.168.178.30 (executor driver) (1/5)
2022.02.12 12:58:03 ERROR 22/02/12 12:58:03 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 8611 ms on 192.168.178.30 (executor driver) (2/5)
2022.02.12 12:58:03 ERROR 22/02/12 12:58:03 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 8653 ms on 192.168.178.30 (executor driver) (3/5)
2022.02.12 12:58:03 ERROR 22/02/12 12:58:03 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark/part_2.csv, range: 0-7541576, partition values: [empty row]
2022.02.12 12:58:03 ERROR 22/02/12 12:58:03 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 8742 ms on 192.168.178.30 (executor driver) (4/5)
2022.02.12 12:58:06 ERROR 22/02/12 12:58:06 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Test_Input_Spark/part_2.csv, range: 0-7541576, partition values: [empty row]
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO Executor: Finished task 4.0 in stage 1.0 (TID 5). 1757 bytes result sent to driver
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 6067 ms on 192.168.178.30 (executor driver) (5/5)
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO DAGScheduler: ResultStage 1 (load at IOHelper.scala:41) finished in 14,731 s
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO DAGScheduler: Job 1 finished: load at IOHelper.scala:41, took 14,738489 s
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO FileSourceStrategy: Output Data Schema: struct<Dataset_ID: string, Timestamp: timestamp, EntityID: int, AttributeName: string, newValue: string ... 3 more fields>
2022.02.12 12:58:09 ERROR Exception in thread "main" scala.NotImplementedError: an implementation is missing
2022.02.12 12:58:09 ERROR 	at scala.Predef$.$qmark$qmark$qmark(Predef.scala:288)
2022.02.12 12:58:09 ERROR 	at de.hpi.dbsII_exercises.Exercise_3a.execute(Exercise_3a.scala:19)
2022.02.12 12:58:09 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:25)
2022.02.12 12:58:09 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:5)
2022.02.12 12:58:09 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.12 12:58:09 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.12 12:58:09 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.12 12:58:09 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.12 12:58:09 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.12 12:58:09 ERROR 	at scala.App.main(App.scala:80)
2022.02.12 12:58:09 ERROR 	at scala.App.main$(App.scala:78)
2022.02.12 12:58:09 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:5)
2022.02.12 12:58:09 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO SparkContext: Invoking stop() from shutdown hook
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO SparkUI: Stopped Spark web UI at http://192.168.178.30:4040
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO MemoryStore: MemoryStore cleared
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO BlockManager: BlockManager stopped
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO BlockManagerMaster: BlockManagerMaster stopped
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO SparkContext: Successfully stopped SparkContext
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO ShutdownHookManager: Shutdown hook called
2022.02.12 12:58:09 ERROR 22/02/12 12:58:09 INFO ShutdownHookManager: Deleting directory /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/spark-a9e913df-4d1c-4926-8981-106e3ed2aa46
2022.02.12 12:58:09 INFO  Closing debug server tcp://0.0.0.0:58610
2022.02.12 12:58:09 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 12:58:09 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:08:16 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:08:18 INFO  time: compiled spark-tutorial in 1.28s
2022.02.12 15:08:33 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:08:38 INFO  time: compiled spark-tutorial in 4.35s
2022.02.12 15:09:41 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:09:42 INFO  time: compiled spark-tutorial in 1.29s
2022.02.12 15:09:49 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 41h 23m 22.674s)
2022.02.12 15:09:49 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 15:09:49 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 15:09:50 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:09:56 INFO  Trying to attach to remote debuggee VM localhost:59986 .
2022.02.12 15:09:56 INFO  Attaching to debuggee VM succeeded.
2022.02.12 15:09:58 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 15:09:58 ERROR 22/02/12 15:09:58 WARN Utils: Your hostname, SchulzeTastPro-2.local resolves to a loopback address: 127.0.0.1; using 192.168.178.30 instead (on interface en0)
2022.02.12 15:09:58 ERROR 22/02/12 15:09:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2022.02.12 15:09:58 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 15:09:58 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 15:09:58 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 15:09:58 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 15:09:58 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 15:09:58 ERROR 22/02/12 15:09:58 INFO SparkContext: Running Spark version 3.0.0
2022.02.12 15:09:58 ERROR 22/02/12 15:09:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022.02.12 15:09:58 ERROR 22/02/12 15:09:59 INFO ResourceUtils: ==============================================================
2022.02.12 15:09:58 ERROR 22/02/12 15:09:59 INFO ResourceUtils: Resources for spark.driver:
2022.02.12 15:09:58 ERROR 
2022.02.12 15:09:58 ERROR 22/02/12 15:09:59 INFO ResourceUtils: ==============================================================
2022.02.12 15:09:58 ERROR 22/02/12 15:09:59 INFO SparkContext: Submitted application: SparkTutorial
2022.02.12 15:09:59 ERROR 22/02/12 15:09:59 INFO SecurityManager: Changing view acls to: Johann
2022.02.12 15:09:59 ERROR 22/02/12 15:09:59 INFO SecurityManager: Changing modify acls to: Johann
2022.02.12 15:09:59 ERROR 22/02/12 15:09:59 INFO SecurityManager: Changing view acls groups to: 
2022.02.12 15:09:59 ERROR 22/02/12 15:09:59 INFO SecurityManager: Changing modify acls groups to: 
2022.02.12 15:09:59 ERROR 22/02/12 15:09:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Johann); groups with view permissions: Set(); users  with modify permissions: Set(Johann); groups with modify permissions: Set()
2022.02.12 15:09:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:09:59 ERROR 22/02/12 15:09:59 INFO Utils: Successfully started service 'sparkDriver' on port 59989.
2022.02.12 15:09:59 ERROR 22/02/12 15:09:59 INFO SparkEnv: Registering MapOutputTracker
2022.02.12 15:09:59 ERROR 22/02/12 15:09:59 INFO SparkEnv: Registering BlockManagerMaster
2022.02.12 15:09:59 ERROR 22/02/12 15:09:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022.02.12 15:09:59 ERROR 22/02/12 15:09:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022.02.12 15:09:59 ERROR 22/02/12 15:09:59 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2022.02.12 15:09:59 ERROR 22/02/12 15:09:59 INFO DiskBlockManager: Created local directory at /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/blockmgr-8714e17d-3ec8-45a7-9636-0a2f6fc8d85b
2022.02.12 15:09:59 ERROR 22/02/12 15:09:59 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
2022.02.12 15:09:59 ERROR 22/02/12 15:10:00 INFO SparkEnv: Registering OutputCommitCoordinator
2022.02.12 15:10:00 ERROR 22/02/12 15:10:00 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2022.02.12 15:10:00 ERROR 22/02/12 15:10:00 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.178.30:4040
2022.02.12 15:10:00 ERROR 22/02/12 15:10:00 INFO Executor: Starting executor ID driver on host 192.168.178.30
2022.02.12 15:10:00 ERROR 22/02/12 15:10:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59990.
2022.02.12 15:10:00 ERROR 22/02/12 15:10:00 INFO NettyBlockTransferService: Server created on 192.168.178.30:59990
2022.02.12 15:10:00 ERROR 22/02/12 15:10:00 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022.02.12 15:10:00 ERROR 22/02/12 15:10:00 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.178.30, 59990, None)
2022.02.12 15:10:00 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:00 ERROR 22/02/12 15:10:00 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.178.30:59990 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.178.30, 59990, None)
2022.02.12 15:10:00 ERROR 22/02/12 15:10:00 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.178.30, 59990, None)
2022.02.12 15:10:00 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:00 ERROR 22/02/12 15:10:00 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.178.30, 59990, None)
2022.02.12 15:10:00 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:01 ERROR 22/02/12 15:10:01 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse').
2022.02.12 15:10:01 ERROR 22/02/12 15:10:01 INFO SharedState: Warehouse path is 'file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse'.
2022.02.12 15:10:03 ERROR 22/02/12 15:10:03 INFO InMemoryFileIndex: It took 106 ms to list leaf files for 1 paths.
2022.02.12 15:10:03 ERROR 22/02/12 15:10:03 INFO InMemoryFileIndex: It took 19 ms to list leaf files for 9 paths.
2022.02.12 15:10:06 ERROR 22/02/12 15:10:06 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:10:06 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:06 ERROR 22/02/12 15:10:06 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:10:06 ERROR 22/02/12 15:10:06 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2022.02.12 15:10:06 ERROR 22/02/12 15:10:06 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:10:06 ERROR 22/02/12 15:10:07 INFO CodeGenerator: Code generated in 297.336786 ms
2022.02.12 15:10:06 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:07 ERROR 22/02/12 15:10:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:10:08 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.178.30:59990 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO SparkContext: Created broadcast 0 from load at IOHelper.scala:41
2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 16782014 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO DAGScheduler: Got job 0 (load at IOHelper.scala:41) with 1 output partitions
2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO DAGScheduler: Final stage: ResultStage 0 (load at IOHelper.scala:41)
2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:10:08 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:10:08 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022.02.12 15:10:08 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022.02.12 15:10:08 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.178.30:59990 (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0))
2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 8009 bytes)
2022.02.12 15:10:07 ERROR 22/02/12 15:10:08 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala, range: 0-2839, partition values: [empty row]
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO CodeGenerator: Code generated in 18.650824 ms
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1634 bytes result sent to driver
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 508 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO DAGScheduler: ResultStage 0 (load at IOHelper.scala:41) finished in 0,708 s
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO DAGScheduler: Job 0 finished: load at IOHelper.scala:41, took 0,772457 s
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO CodeGenerator: Code generated in 18.700527 ms
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:10:09 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:10:09 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.178.30:59990 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO SparkContext: Created broadcast 2 from load at IOHelper.scala:41
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileSourceScanExec: Planning scan with bin packing, max size: 16782014 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO DAGScheduler: Got job 1 (load at IOHelper.scala:41) with 4 output partitions
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO DAGScheduler: Final stage: ResultStage 1 (load at IOHelper.scala:41)
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:10:09 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:10:09 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.0 KiB, free 2.2 GiB)
2022.02.12 15:10:09 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 2.2 GiB)
2022.02.12 15:10:09 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.178.30:59990 (size: 7.5 KiB, free: 2.2 GiB)
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 8009 bytes)
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 8018 bytes)
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 8142 bytes)
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, 192.168.178.30, executor driver, partition 3, PROCESS_LOCAL, 7976 bytes)
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala, range: 0-1347, partition values: [empty row]
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala, range: 0-2839, partition values: [empty row]
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/IOHelper.scala, range: 0-1112, partition values: [empty row]
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala, range: 0-561, partition values: [empty row]
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ChangeRecord.scala, range: 0-399, partition values: [empty row]
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala, range: 0-1347, partition values: [empty row]
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/IOHelper.scala, range: 0-1112, partition values: [empty row]
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ChangeRecord.scala, range: 0-399, partition values: [empty row]
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala, range: 0-2839, partition values: [empty row]
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3d.scala, range: 0-1284, partition values: [empty row]
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3a.scala, range: 0-631, partition values: [empty row]
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1590 bytes result sent to driver
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3d.scala, range: 0-1284, partition values: [empty row]
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 172 ms on 192.168.178.30 (executor driver) (1/4)
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3a.scala, range: 0-631, partition values: [empty row]
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala, range: 0-561, partition values: [empty row]
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1590 bytes result sent to driver
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 183 ms on 192.168.178.30 (executor driver) (2/4)
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala, range: 0-1423, partition values: [empty row]
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1590 bytes result sent to driver
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 196 ms on 192.168.178.30 (executor driver) (3/4)
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala, range: 0-1423, partition values: [empty row]
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1590 bytes result sent to driver
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 214 ms on 192.168.178.30 (executor driver) (4/4)
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO DAGScheduler: ResultStage 1 (load at IOHelper.scala:41) finished in 0,276 s
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2022.02.12 15:10:09 ERROR 22/02/12 15:10:09 INFO DAGScheduler: Job 1 finished: load at IOHelper.scala:41, took 0,284682 s
2022.02.12 15:10:10 ERROR 22/02/12 15:10:10 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:10:10 ERROR 22/02/12 15:10:10 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:10:10 ERROR 22/02/12 15:10:10 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:10:10 ERROR 22/02/12 15:10:10 INFO FileSourceStrategy: Output Data Schema: struct<package de.hpi.dbsII_exercises: string>
2022.02.12 15:10:10 ERROR 22/02/12 15:10:10 INFO CodeGenerator: Code generated in 23.215545 ms
2022.02.12 15:10:10 ERROR 22/02/12 15:10:10 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 15:10:10 ERROR 22/02/12 15:10:10 INFO CodeGenerator: Code generated in 29.824933 ms
2022.02.12 15:10:10 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:10 ERROR 22/02/12 15:10:10 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 15:10:10 ERROR 22/02/12 15:10:10 INFO CodeGenerator: Code generated in 37.506013 ms
2022.02.12 15:10:10 ERROR 22/02/12 15:10:10 INFO CodeGenerator: Code generated in 46.127422 ms
2022.02.12 15:10:10 ERROR 22/02/12 15:10:10 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:10:10 ERROR 22/02/12 15:10:10 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:10:10 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:10 ERROR 22/02/12 15:10:10 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.178.30:59990 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:10:10 ERROR 22/02/12 15:10:10 INFO SparkContext: Created broadcast 4 from collect at Exercise_3a.scala:19
2022.02.12 15:10:10 ERROR 22/02/12 15:10:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8391007 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:10:10 ERROR 22/02/12 15:10:10 INFO CodeGenerator: Code generated in 13.826919 ms
2022.02.12 15:10:10 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO SparkContext: Starting job: collect at Exercise_3a.scala:19
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO DAGScheduler: Registering RDD 17 (collect at Exercise_3a.scala:19) as input to shuffle 0
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO DAGScheduler: Got job 2 (collect at Exercise_3a.scala:19) with 8 output partitions
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO DAGScheduler: Final stage: ResultStage 3 (collect at Exercise_3a.scala:19)
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at collect at Exercise_3a.scala:19), which has no missing parents
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 39.1 KiB, free 2.2 GiB)
2022.02.12 15:10:10 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:10 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 2.2 GiB)
2022.02.12 15:10:10 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.178.30:59990 (size: 15.8 KiB, free: 2.2 GiB)
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at collect at Exercise_3a.scala:19) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 4 tasks
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7934 bytes)
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 6, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7943 bytes)
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 8067 bytes)
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 8, 192.168.178.30, executor driver, partition 3, PROCESS_LOCAL, 7795 bytes)
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO Executor: Running task 1.0 in stage 2.0 (TID 6)
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO Executor: Running task 3.0 in stage 2.0 (TID 8)
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO Executor: Running task 2.0 in stage 2.0 (TID 7)
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala, range: 0-2839, partition values: [empty row]
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/IOHelper.scala, range: 0-1112, partition values: [empty row]
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala, range: 0-1347, partition values: [empty row]
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ChangeRecord.scala, range: 0-399, partition values: [empty row]
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 WARN BlockManager: Putting block rdd_13_1 failed due to exception java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1.
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 WARN BlockManager: Putting block rdd_13_2 failed due to exception java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1.
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 WARN BlockManager: Putting block rdd_13_0 failed due to exception java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1.
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 WARN BlockManager: Putting block rdd_13_3 failed due to exception java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1.
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 WARN BlockManager: Block rdd_13_1 could not be removed as it was not found on disk or in memory
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 WARN BlockManager: Block rdd_13_3 could not be removed as it was not found on disk or in memory
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 WARN BlockManager: Block rdd_13_2 could not be removed as it was not found on disk or in memory
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 WARN BlockManager: Block rdd_13_0 could not be removed as it was not found on disk or in memory
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 ERROR Executor: Exception in task 1.0 in stage 2.0 (TID 6)
2022.02.12 15:10:11 ERROR java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:174)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getAs(Row.scala:356)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getAs$(Row.scala:356)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:166)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getTimestamp(Row.scala:303)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getTimestamp$(Row.scala:303)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getTimestamp(rows.scala:166)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:12)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:10:11 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:10:11 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:10:11 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 ERROR Executor: Exception in task 2.0 in stage 2.0 (TID 7)
2022.02.12 15:10:11 ERROR java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:174)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getAs(Row.scala:356)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getAs$(Row.scala:356)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:166)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getTimestamp(Row.scala:303)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getTimestamp$(Row.scala:303)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getTimestamp(rows.scala:166)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:12)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:10:11 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:10:11 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:10:11 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 5)
2022.02.12 15:10:11 ERROR java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:174)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getAs(Row.scala:356)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getAs$(Row.scala:356)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:166)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getTimestamp(Row.scala:303)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getTimestamp$(Row.scala:303)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getTimestamp(rows.scala:166)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:12)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:10:11 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:10:11 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:10:11 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 ERROR Executor: Exception in task 3.0 in stage 2.0 (TID 8)
2022.02.12 15:10:11 ERROR java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:174)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getAs(Row.scala:356)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getAs$(Row.scala:356)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:166)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getTimestamp(Row.scala:303)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getTimestamp$(Row.scala:303)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getTimestamp(rows.scala:166)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:12)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:10:11 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:10:11 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:10:11 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 WARN TaskSetManager: Lost task 3.0 in stage 2.0 (TID 8, 192.168.178.30, executor driver): java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:174)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getAs(Row.scala:356)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getAs$(Row.scala:356)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:166)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getTimestamp(Row.scala:303)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getTimestamp$(Row.scala:303)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getTimestamp(rows.scala:166)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:12)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:10:11 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:10:11 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:10:11 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:10:11 ERROR 
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 ERROR TaskSetManager: Task 3 in stage 2.0 failed 1 times; aborting job
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO TaskSetManager: Lost task 0.0 in stage 2.0 (TID 5) on 192.168.178.30, executor driver: java.lang.ArrayIndexOutOfBoundsException (Index 1 out of bounds for length 1) [duplicate 1]
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO TaskSetManager: Lost task 1.0 in stage 2.0 (TID 6) on 192.168.178.30, executor driver: java.lang.ArrayIndexOutOfBoundsException (Index 1 out of bounds for length 1) [duplicate 2]
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO TaskSetManager: Lost task 2.0 in stage 2.0 (TID 7) on 192.168.178.30, executor driver: java.lang.ArrayIndexOutOfBoundsException (Index 1 out of bounds for length 1) [duplicate 3]
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO TaskSchedulerImpl: Cancelling stage 2
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage cancelled
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO DAGScheduler: ShuffleMapStage 2 (collect at Exercise_3a.scala:19) failed in 0,620 s due to Job aborted due to stage failure: Task 3 in stage 2.0 failed 1 times, most recent failure: Lost task 3.0 in stage 2.0 (TID 8, 192.168.178.30, executor driver): java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:174)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getAs(Row.scala:356)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getAs$(Row.scala:356)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:166)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getTimestamp(Row.scala:303)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getTimestamp$(Row.scala:303)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getTimestamp(rows.scala:166)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:12)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:10:11 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:10:11 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:10:11 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:10:11 ERROR 
2022.02.12 15:10:11 ERROR Driver stacktrace:
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO DAGScheduler: Job 2 failed: collect at Exercise_3a.scala:19, took 0,649941 s
2022.02.12 15:10:11 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 2.0 failed 1 times, most recent failure: Lost task 3.0 in stage 2.0 (TID 8, 192.168.178.30, executor driver): java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:174)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getAs(Row.scala:356)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getAs$(Row.scala:356)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:166)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getTimestamp(Row.scala:303)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getTimestamp$(Row.scala:303)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getTimestamp(rows.scala:166)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:12)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:10:11 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:10:11 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:10:11 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:10:11 ERROR 
2022.02.12 15:10:11 ERROR Driver stacktrace:
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2023)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1972)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1971)
2022.02.12 15:10:11 ERROR 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
2022.02.12 15:10:11 ERROR 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
2022.02.12 15:10:11 ERROR 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1971)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:950)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:950)
2022.02.12 15:10:11 ERROR 	at scala.Option.foreach(Option.scala:407)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:950)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2203)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2152)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2141)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2133)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:388)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.collect(RDD.scala:1003)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:304)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.prepareShuffleDependency(ShuffleExchangeExec.scala:199)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.shuffleDependency$lzycompute(ShuffleExchangeExec.scala:87)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.shuffleDependency(ShuffleExchangeExec.scala:81)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.$anonfun$doExecute$1(ShuffleExchangeExec.scala:98)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:95)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:525)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:453)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:452)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:496)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:132)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:720)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:316)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:382)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3625)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:2938)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3616)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3614)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Dataset.collect(Dataset.scala:2938)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.Exercise_3a.execute(Exercise_3a.scala:19)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:25)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:5)
2022.02.12 15:10:11 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.12 15:10:11 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.12 15:10:11 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.12 15:10:11 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.12 15:10:11 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.12 15:10:11 ERROR 	at scala.App.main(App.scala:80)
2022.02.12 15:10:11 ERROR 	at scala.App.main$(App.scala:78)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:5)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.12 15:10:11 ERROR Caused by: java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:174)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getAs(Row.scala:356)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getAs$(Row.scala:356)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:166)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getTimestamp(Row.scala:303)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.Row.getTimestamp$(Row.scala:303)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getTimestamp(rows.scala:166)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:12)
2022.02.12 15:10:11 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:10:11 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:10:11 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:10:11 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:10:11 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO SparkContext: Invoking stop() from shutdown hook
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO SparkUI: Stopped Spark web UI at http://192.168.178.30:4040
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO MemoryStore: MemoryStore cleared
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO BlockManager: BlockManager stopped
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO BlockManagerMaster: BlockManagerMaster stopped
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO SparkContext: Successfully stopped SparkContext
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO ShutdownHookManager: Shutdown hook called
2022.02.12 15:10:11 ERROR 22/02/12 15:10:11 INFO ShutdownHookManager: Deleting directory /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/spark-4624b47a-8394-4a85-91fa-cb3305af4f31
2022.02.12 15:10:11 INFO  Closing debug server tcp://0.0.0.0:59980
Feb. 12, 2022 3:10:29 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireError
SEVERE: java.net.SocketException: Broken pipe (Write failed)
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.net.SocketException: Broken pipe (Write failed)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.debug.SocketEndpoint.consume(SocketEndpoint.scala:22)
	at scala.meta.internal.metals.debug.MessageIdAdapter.consume(MessageIdAdapter.scala:43)
	at scala.meta.internal.metals.debug.ServerAdapter.send(ServerAdapter.scala:30)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleClientMessage$1(DebugProxy.scala:138)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToClient$1(DebugProxy.scala:63)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.base/java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)
	at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:69)
	... 21 more

2022.02.12 15:10:36 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

Feb. 12, 2022 3:10:36 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireStreamClosed
INFO: Connection reset
java.net.SocketException: Connection reset
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:79)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:36 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:10:42 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:10:44 INFO  time: compiled spark-tutorial in 1.4s
2022.02.12 15:10:44 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 41h 24m 18.484s)
2022.02.12 15:10:45 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 15:10:46 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 15:10:46 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:10:51 INFO  Trying to attach to remote debuggee VM localhost:60025 .
2022.02.12 15:10:51 INFO  Attaching to debuggee VM succeeded.
2022.02.12 15:10:52 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 15:10:52 ERROR 22/02/12 15:10:52 WARN Utils: Your hostname, SchulzeTastPro-2.local resolves to a loopback address: 127.0.0.1; using 192.168.178.30 instead (on interface en0)
2022.02.12 15:10:52 ERROR 22/02/12 15:10:52 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2022.02.12 15:10:52 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 15:10:52 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 15:10:52 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 15:10:52 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 15:10:52 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 15:10:52 ERROR 22/02/12 15:10:52 INFO SparkContext: Running Spark version 3.0.0
2022.02.12 15:10:52 ERROR 22/02/12 15:10:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022.02.12 15:10:52 ERROR 22/02/12 15:10:53 INFO ResourceUtils: ==============================================================
2022.02.12 15:10:52 ERROR 22/02/12 15:10:53 INFO ResourceUtils: Resources for spark.driver:
2022.02.12 15:10:52 ERROR 
2022.02.12 15:10:52 ERROR 22/02/12 15:10:53 INFO ResourceUtils: ==============================================================
2022.02.12 15:10:52 ERROR 22/02/12 15:10:53 INFO SparkContext: Submitted application: SparkTutorial
2022.02.12 15:10:53 ERROR 22/02/12 15:10:53 INFO SecurityManager: Changing view acls to: Johann
2022.02.12 15:10:53 ERROR 22/02/12 15:10:53 INFO SecurityManager: Changing modify acls to: Johann
2022.02.12 15:10:53 ERROR 22/02/12 15:10:53 INFO SecurityManager: Changing view acls groups to: 
2022.02.12 15:10:53 ERROR 22/02/12 15:10:53 INFO SecurityManager: Changing modify acls groups to: 
2022.02.12 15:10:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:53 ERROR 22/02/12 15:10:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Johann); groups with view permissions: Set(); users  with modify permissions: Set(Johann); groups with modify permissions: Set()
2022.02.12 15:10:53 ERROR 22/02/12 15:10:54 INFO Utils: Successfully started service 'sparkDriver' on port 60029.
2022.02.12 15:10:53 ERROR 22/02/12 15:10:54 INFO SparkEnv: Registering MapOutputTracker
2022.02.12 15:10:53 ERROR 22/02/12 15:10:54 INFO SparkEnv: Registering BlockManagerMaster
2022.02.12 15:10:53 ERROR 22/02/12 15:10:54 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022.02.12 15:10:53 ERROR 22/02/12 15:10:54 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022.02.12 15:10:53 ERROR 22/02/12 15:10:54 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2022.02.12 15:10:53 ERROR 22/02/12 15:10:54 INFO DiskBlockManager: Created local directory at /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/blockmgr-f2d3c9d2-5ad0-4173-9ddd-2101026142be
2022.02.12 15:10:53 ERROR 22/02/12 15:10:54 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
2022.02.12 15:10:53 ERROR 22/02/12 15:10:54 INFO SparkEnv: Registering OutputCommitCoordinator
2022.02.12 15:10:54 ERROR 22/02/12 15:10:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2022.02.12 15:10:54 ERROR 22/02/12 15:10:54 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.178.30:4040
2022.02.12 15:10:54 ERROR 22/02/12 15:10:54 INFO Executor: Starting executor ID driver on host 192.168.178.30
2022.02.12 15:10:54 ERROR 22/02/12 15:10:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60030.
2022.02.12 15:10:54 ERROR 22/02/12 15:10:55 INFO NettyBlockTransferService: Server created on 192.168.178.30:60030
2022.02.12 15:10:54 ERROR 22/02/12 15:10:55 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022.02.12 15:10:54 ERROR 22/02/12 15:10:55 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.178.30, 60030, None)
2022.02.12 15:10:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:54 ERROR 22/02/12 15:10:55 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.178.30:60030 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.178.30, 60030, None)
2022.02.12 15:10:54 ERROR 22/02/12 15:10:55 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.178.30, 60030, None)
2022.02.12 15:10:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:54 ERROR 22/02/12 15:10:55 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.178.30, 60030, None)
2022.02.12 15:10:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:55 ERROR 22/02/12 15:10:55 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse').
2022.02.12 15:10:55 ERROR 22/02/12 15:10:55 INFO SharedState: Warehouse path is 'file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse'.
2022.02.12 15:10:56 ERROR 22/02/12 15:10:56 INFO InMemoryFileIndex: It took 217 ms to list leaf files for 1 paths.
2022.02.12 15:10:56 ERROR 22/02/12 15:10:57 INFO InMemoryFileIndex: It took 26 ms to list leaf files for 9 paths.
2022.02.12 15:10:59 ERROR 22/02/12 15:10:59 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:10:59 ERROR 22/02/12 15:10:59 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:10:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:10:59 ERROR 22/02/12 15:10:59 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2022.02.12 15:10:59 ERROR 22/02/12 15:10:59 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:10:59 ERROR 22/02/12 15:11:00 INFO CodeGenerator: Code generated in 270.054658 ms
2022.02.12 15:10:59 ERROR 22/02/12 15:11:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:10:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:11:01 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.178.30:60030 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO SparkContext: Created broadcast 0 from load at IOHelper.scala:41
2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 16782013 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO DAGScheduler: Got job 0 (load at IOHelper.scala:41) with 1 output partitions
2022.02.12 15:11:01 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO DAGScheduler: Final stage: ResultStage 0 (load at IOHelper.scala:41)
2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:11:01 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022.02.12 15:11:01 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022.02.12 15:11:01 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.178.30:60030 (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0))
2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 8009 bytes)
2022.02.12 15:11:01 ERROR 22/02/12 15:11:01 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala, range: 0-2839, partition values: [empty row]
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO CodeGenerator: Code generated in 20.720126 ms
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1634 bytes result sent to driver
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 485 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO DAGScheduler: ResultStage 0 (load at IOHelper.scala:41) finished in 0,740 s
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO DAGScheduler: Job 0 finished: load at IOHelper.scala:41, took 0,818510 s
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO CodeGenerator: Code generated in 14.358229 ms
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:11:02 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:11:02 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.178.30:60030 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO SparkContext: Created broadcast 2 from load at IOHelper.scala:41
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 16782013 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:11:02 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO DAGScheduler: Got job 1 (load at IOHelper.scala:41) with 4 output partitions
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO DAGScheduler: Final stage: ResultStage 1 (load at IOHelper.scala:41)
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:11:02 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.0 KiB, free 2.2 GiB)
2022.02.12 15:11:02 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 2.2 GiB)
2022.02.12 15:11:02 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.178.30:60030 (size: 7.5 KiB, free: 2.2 GiB)
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 8009 bytes)
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 8018 bytes)
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 8142 bytes)
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, 192.168.178.30, executor driver, partition 3, PROCESS_LOCAL, 7976 bytes)
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala, range: 0-2839, partition values: [empty row]
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala, range: 0-561, partition values: [empty row]
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala, range: 0-1346, partition values: [empty row]
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/IOHelper.scala, range: 0-1112, partition values: [empty row]
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ChangeRecord.scala, range: 0-399, partition values: [empty row]
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala, range: 0-1346, partition values: [empty row]
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/IOHelper.scala, range: 0-1112, partition values: [empty row]
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ChangeRecord.scala, range: 0-399, partition values: [empty row]
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala, range: 0-2839, partition values: [empty row]
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3d.scala, range: 0-1284, partition values: [empty row]
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3a.scala, range: 0-631, partition values: [empty row]
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1590 bytes result sent to driver
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 177 ms on 192.168.178.30 (executor driver) (1/4)
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3d.scala, range: 0-1284, partition values: [empty row]
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3a.scala, range: 0-631, partition values: [empty row]
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala, range: 0-1423, partition values: [empty row]
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala, range: 0-561, partition values: [empty row]
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1590 bytes result sent to driver
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 194 ms on 192.168.178.30 (executor driver) (2/4)
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1590 bytes result sent to driver
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 198 ms on 192.168.178.30 (executor driver) (3/4)
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala, range: 0-1423, partition values: [empty row]
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1590 bytes result sent to driver
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 223 ms on 192.168.178.30 (executor driver) (4/4)
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO DAGScheduler: ResultStage 1 (load at IOHelper.scala:41) finished in 0,294 s
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO DAGScheduler: Job 1 finished: load at IOHelper.scala:41, took 0,302421 s
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:11:02 ERROR 22/02/12 15:11:02 INFO FileSourceStrategy: Output Data Schema: struct<package de.hpi.dbsII_exercises: string>
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO CodeGenerator: Code generated in 24.480473 ms
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO CodeGenerator: Code generated in 29.175509 ms
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO CodeGenerator: Code generated in 32.285756 ms
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO CodeGenerator: Code generated in 42.85477 ms
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:11:03 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:11:03 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.178.30:60030 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO SparkContext: Created broadcast 4 from collect at Exercise_3a.scala:19
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8391006 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO CodeGenerator: Code generated in 12.431048 ms
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO SparkContext: Starting job: collect at Exercise_3a.scala:19
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO DAGScheduler: Registering RDD 17 (collect at Exercise_3a.scala:19) as input to shuffle 0
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO DAGScheduler: Got job 2 (collect at Exercise_3a.scala:19) with 8 output partitions
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO DAGScheduler: Final stage: ResultStage 3 (collect at Exercise_3a.scala:19)
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
2022.02.12 15:11:03 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:03 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at collect at Exercise_3a.scala:19), which has no missing parents
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 39.1 KiB, free 2.2 GiB)
2022.02.12 15:11:03 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.8 KiB, free 2.2 GiB)
2022.02.12 15:11:03 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.178.30:60030 (size: 15.8 KiB, free: 2.2 GiB)
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at collect at Exercise_3a.scala:19) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO TaskSchedulerImpl: Adding task set 2.0 with 4 tasks
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7934 bytes)
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 6, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7943 bytes)
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 8067 bytes)
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 8, 192.168.178.30, executor driver, partition 3, PROCESS_LOCAL, 7795 bytes)
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO Executor: Running task 1.0 in stage 2.0 (TID 6)
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO Executor: Running task 3.0 in stage 2.0 (TID 8)
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO Executor: Running task 2.0 in stage 2.0 (TID 7)
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/IOHelper.scala, range: 0-1112, partition values: [empty row]
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala, range: 0-1346, partition values: [empty row]
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala, range: 0-2839, partition values: [empty row]
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ChangeRecord.scala, range: 0-399, partition values: [empty row]
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 WARN BlockManager: Putting block rdd_13_0 failed due to exception java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1.
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 WARN BlockManager: Putting block rdd_13_3 failed due to exception java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1.
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 WARN BlockManager: Putting block rdd_13_1 failed due to exception java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1.
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 WARN BlockManager: Putting block rdd_13_2 failed due to exception java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1.
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 WARN BlockManager: Block rdd_13_2 could not be removed as it was not found on disk or in memory
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 WARN BlockManager: Block rdd_13_1 could not be removed as it was not found on disk or in memory
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 WARN BlockManager: Block rdd_13_3 could not be removed as it was not found on disk or in memory
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 WARN BlockManager: Block rdd_13_0 could not be removed as it was not found on disk or in memory
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 5)
2022.02.12 15:11:03 ERROR java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:174)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getAs(Row.scala:356)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getAs$(Row.scala:356)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:166)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getTimestamp(Row.scala:303)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getTimestamp$(Row.scala:303)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getTimestamp(rows.scala:166)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:12)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:11:03 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:11:03 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:11:03 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 ERROR Executor: Exception in task 1.0 in stage 2.0 (TID 6)
2022.02.12 15:11:03 ERROR java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:174)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getAs(Row.scala:356)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getAs$(Row.scala:356)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:166)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getTimestamp(Row.scala:303)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getTimestamp$(Row.scala:303)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getTimestamp(rows.scala:166)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:12)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:11:03 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:11:03 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:11:03 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 ERROR Executor: Exception in task 3.0 in stage 2.0 (TID 8)
2022.02.12 15:11:03 ERROR java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:174)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getAs(Row.scala:356)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getAs$(Row.scala:356)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:166)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getTimestamp(Row.scala:303)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getTimestamp$(Row.scala:303)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getTimestamp(rows.scala:166)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:12)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:11:03 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:11:03 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:11:03 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 ERROR Executor: Exception in task 2.0 in stage 2.0 (TID 7)
2022.02.12 15:11:03 ERROR java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:174)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getAs(Row.scala:356)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getAs$(Row.scala:356)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:166)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getTimestamp(Row.scala:303)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getTimestamp$(Row.scala:303)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getTimestamp(rows.scala:166)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:12)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:11:03 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:11:03 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:11:03 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 WARN TaskSetManager: Lost task 0.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver): java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:174)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getAs(Row.scala:356)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getAs$(Row.scala:356)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:166)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getTimestamp(Row.scala:303)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getTimestamp$(Row.scala:303)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getTimestamp(rows.scala:166)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:12)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:11:03 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:11:03 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:11:03 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:11:03 ERROR 
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 ERROR TaskSetManager: Task 0 in stage 2.0 failed 1 times; aborting job
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO TaskSetManager: Lost task 2.0 in stage 2.0 (TID 7) on 192.168.178.30, executor driver: java.lang.ArrayIndexOutOfBoundsException (Index 1 out of bounds for length 1) [duplicate 1]
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO TaskSetManager: Lost task 3.0 in stage 2.0 (TID 8) on 192.168.178.30, executor driver: java.lang.ArrayIndexOutOfBoundsException (Index 1 out of bounds for length 1) [duplicate 2]
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO TaskSetManager: Lost task 1.0 in stage 2.0 (TID 6) on 192.168.178.30, executor driver: java.lang.ArrayIndexOutOfBoundsException (Index 1 out of bounds for length 1) [duplicate 3]
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO TaskSchedulerImpl: Cancelling stage 2
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage cancelled
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO DAGScheduler: ShuffleMapStage 2 (collect at Exercise_3a.scala:19) failed in 0,224 s due to Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver): java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:174)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getAs(Row.scala:356)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getAs$(Row.scala:356)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:166)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getTimestamp(Row.scala:303)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getTimestamp$(Row.scala:303)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getTimestamp(rows.scala:166)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:12)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:11:03 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:11:03 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:11:03 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:11:03 ERROR 
2022.02.12 15:11:03 ERROR Driver stacktrace:
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO DAGScheduler: Job 2 failed: collect at Exercise_3a.scala:19, took 0,255976 s
2022.02.12 15:11:03 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver): java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:174)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getAs(Row.scala:356)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getAs$(Row.scala:356)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:166)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getTimestamp(Row.scala:303)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getTimestamp$(Row.scala:303)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getTimestamp(rows.scala:166)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:12)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:11:03 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:11:03 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:11:03 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:11:03 ERROR 
2022.02.12 15:11:03 ERROR Driver stacktrace:
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2023)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1972)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1971)
2022.02.12 15:11:03 ERROR 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
2022.02.12 15:11:03 ERROR 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
2022.02.12 15:11:03 ERROR 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1971)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:950)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:950)
2022.02.12 15:11:03 ERROR 	at scala.Option.foreach(Option.scala:407)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:950)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2203)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2152)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2141)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2133)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:388)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.collect(RDD.scala:1003)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:304)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.prepareShuffleDependency(ShuffleExchangeExec.scala:199)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.shuffleDependency$lzycompute(ShuffleExchangeExec.scala:87)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.shuffleDependency(ShuffleExchangeExec.scala:81)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.$anonfun$doExecute$1(ShuffleExchangeExec.scala:98)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:95)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:525)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:453)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:452)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:496)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:132)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:720)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:316)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:382)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3625)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:2938)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3616)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3614)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Dataset.collect(Dataset.scala:2938)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.Exercise_3a.execute(Exercise_3a.scala:19)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:25)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:5)
2022.02.12 15:11:03 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.12 15:11:03 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.12 15:11:03 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.12 15:11:03 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.12 15:11:03 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.12 15:11:03 ERROR 	at scala.App.main(App.scala:80)
2022.02.12 15:11:03 ERROR 	at scala.App.main$(App.scala:78)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:5)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.12 15:11:03 ERROR Caused by: java.lang.ArrayIndexOutOfBoundsException: Index 1 out of bounds for length 1
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:174)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getAs(Row.scala:356)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getAs$(Row.scala:356)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:166)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getTimestamp(Row.scala:303)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.Row.getTimestamp$(Row.scala:303)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getTimestamp(rows.scala:166)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:12)
2022.02.12 15:11:03 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:11:03 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:11:03 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:11:03 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:11:03 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO SparkContext: Invoking stop() from shutdown hook
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO SparkUI: Stopped Spark web UI at http://192.168.178.30:4040
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO MemoryStore: MemoryStore cleared
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO BlockManager: BlockManager stopped
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO BlockManagerMaster: BlockManagerMaster stopped
2022.02.12 15:11:03 ERROR 22/02/12 15:11:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2022.02.12 15:11:03 ERROR 22/02/12 15:11:04 INFO SparkContext: Successfully stopped SparkContext
2022.02.12 15:11:03 ERROR 22/02/12 15:11:04 INFO ShutdownHookManager: Shutdown hook called
2022.02.12 15:11:03 ERROR 22/02/12 15:11:04 INFO ShutdownHookManager: Deleting directory /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/spark-0c7c9d90-5691-49d6-ab13-c3512d9715c6
2022.02.12 15:11:04 INFO  Closing debug server tcp://0.0.0.0:60016
Feb. 12, 2022 3:11:14 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireError
SEVERE: java.net.SocketException: Broken pipe (Write failed)
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.net.SocketException: Broken pipe (Write failed)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.debug.SocketEndpoint.consume(SocketEndpoint.scala:22)
	at scala.meta.internal.metals.debug.MessageIdAdapter.consume(MessageIdAdapter.scala:43)
	at scala.meta.internal.metals.debug.ServerAdapter.send(ServerAdapter.scala:30)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleClientMessage$1(DebugProxy.scala:138)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToClient$1(DebugProxy.scala:63)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.base/java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)
	at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:69)
	... 21 more

Feb. 12, 2022 3:11:14 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireError
SEVERE: java.net.SocketException: Broken pipe (Write failed)
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.net.SocketException: Broken pipe (Write failed)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.debug.SocketEndpoint.consume(SocketEndpoint.scala:22)
	at scala.meta.internal.metals.debug.MessageIdAdapter.consume(MessageIdAdapter.scala:43)
	at scala.meta.internal.metals.debug.ServerAdapter.send(ServerAdapter.scala:30)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleClientMessage$1(DebugProxy.scala:138)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToClient$1(DebugProxy.scala:63)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.base/java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)
	at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:69)
	... 21 more

Feb. 12, 2022 3:11:14 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireError
SEVERE: java.net.SocketException: Broken pipe (Write failed)
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.net.SocketException: Broken pipe (Write failed)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.debug.SocketEndpoint.consume(SocketEndpoint.scala:22)
	at scala.meta.internal.metals.debug.MessageIdAdapter.consume(MessageIdAdapter.scala:43)
	at scala.meta.internal.metals.debug.ServerAdapter.send(ServerAdapter.scala:30)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleClientMessage$1(DebugProxy.scala:138)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToClient$1(DebugProxy.scala:63)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.base/java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)
	at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:69)
	... 21 more

2022.02.12 15:11:15 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

Feb. 12, 2022 3:11:15 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireStreamClosed
INFO: Connection reset
java.net.SocketException: Connection reset
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:79)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)

2022.02.12 15:11:15 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:12:26 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:12:27 INFO  time: compiled spark-tutorial in 1.18s
2022.02.12 15:12:32 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:12:33 INFO  time: compiled spark-tutorial in 1.03s
2022.02.12 15:12:40 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:12:41 INFO  time: compiled spark-tutorial in 1.23s
2022.02.12 15:12:53 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:12:55 INFO  time: compiled spark-tutorial in 1.5s
2022.02.12 15:13:06 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:13:07 INFO  time: compiled spark-tutorial in 1.14s
2022.02.12 15:13:14 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:13:15 INFO  time: compiled spark-tutorial in 1.43s
Feb. 12, 2022 3:13:15 NACHM. scala.meta.internal.pc.CompilerAccess retryWithCleanCompiler
INFO: compiler crashed due to an error in the Scala compiler, retrying with new compiler instance.
2022.02.12 15:13:16 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 41h 26m 49.997s)
2022.02.12 15:13:16 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 15:13:18 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 15:13:18 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:13:22 INFO  Trying to attach to remote debuggee VM localhost:60110 .
2022.02.12 15:13:22 INFO  Attaching to debuggee VM succeeded.
2022.02.12 15:13:23 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 15:13:23 ERROR 22/02/12 15:13:23 WARN Utils: Your hostname, SchulzeTastPro-2.local resolves to a loopback address: 127.0.0.1; using 192.168.178.30 instead (on interface en0)
2022.02.12 15:13:23 ERROR 22/02/12 15:13:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2022.02.12 15:13:23 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 15:13:23 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 15:13:23 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 15:13:23 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 15:13:23 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 15:13:23 ERROR 22/02/12 15:13:24 INFO SparkContext: Running Spark version 3.0.0
2022.02.12 15:13:23 ERROR 22/02/12 15:13:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022.02.12 15:13:23 ERROR 22/02/12 15:13:24 INFO ResourceUtils: ==============================================================
2022.02.12 15:13:24 ERROR 22/02/12 15:13:24 INFO ResourceUtils: Resources for spark.driver:
2022.02.12 15:13:24 ERROR 
2022.02.12 15:13:24 ERROR 22/02/12 15:13:24 INFO ResourceUtils: ==============================================================
2022.02.12 15:13:24 ERROR 22/02/12 15:13:24 INFO SparkContext: Submitted application: SparkTutorial
2022.02.12 15:13:24 ERROR 22/02/12 15:13:24 INFO SecurityManager: Changing view acls to: Johann
2022.02.12 15:13:24 ERROR 22/02/12 15:13:24 INFO SecurityManager: Changing modify acls to: Johann
2022.02.12 15:13:24 ERROR 22/02/12 15:13:24 INFO SecurityManager: Changing view acls groups to: 
2022.02.12 15:13:24 ERROR 22/02/12 15:13:24 INFO SecurityManager: Changing modify acls groups to: 
2022.02.12 15:13:24 ERROR 22/02/12 15:13:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Johann); groups with view permissions: Set(); users  with modify permissions: Set(Johann); groups with modify permissions: Set()
2022.02.12 15:13:24 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:24 ERROR 22/02/12 15:13:25 INFO Utils: Successfully started service 'sparkDriver' on port 60113.
2022.02.12 15:13:24 ERROR 22/02/12 15:13:25 INFO SparkEnv: Registering MapOutputTracker
2022.02.12 15:13:24 ERROR 22/02/12 15:13:25 INFO SparkEnv: Registering BlockManagerMaster
2022.02.12 15:13:24 ERROR 22/02/12 15:13:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022.02.12 15:13:24 ERROR 22/02/12 15:13:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022.02.12 15:13:24 ERROR 22/02/12 15:13:25 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2022.02.12 15:13:24 ERROR 22/02/12 15:13:25 INFO DiskBlockManager: Created local directory at /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/blockmgr-a32c50ee-4b92-4a2c-b153-238c86ef1507
2022.02.12 15:13:24 ERROR 22/02/12 15:13:25 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
2022.02.12 15:13:24 ERROR 22/02/12 15:13:25 INFO SparkEnv: Registering OutputCommitCoordinator
2022.02.12 15:13:26 ERROR 22/02/12 15:13:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2022.02.12 15:13:26 ERROR 22/02/12 15:13:26 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.178.30:4040
2022.02.12 15:13:26 ERROR 22/02/12 15:13:26 INFO Executor: Starting executor ID driver on host 192.168.178.30
2022.02.12 15:13:26 ERROR 22/02/12 15:13:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60114.
2022.02.12 15:13:26 ERROR 22/02/12 15:13:26 INFO NettyBlockTransferService: Server created on 192.168.178.30:60114
2022.02.12 15:13:26 ERROR 22/02/12 15:13:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022.02.12 15:13:26 ERROR 22/02/12 15:13:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.178.30, 60114, None)
2022.02.12 15:13:26 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:26 ERROR 22/02/12 15:13:26 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.178.30:60114 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.178.30, 60114, None)
2022.02.12 15:13:26 ERROR 22/02/12 15:13:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.178.30, 60114, None)
2022.02.12 15:13:26 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:26 ERROR 22/02/12 15:13:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.178.30, 60114, None)
2022.02.12 15:13:26 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:27 ERROR 22/02/12 15:13:27 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse').
2022.02.12 15:13:27 ERROR 22/02/12 15:13:27 INFO SharedState: Warehouse path is 'file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse'.
2022.02.12 15:13:28 ERROR 22/02/12 15:13:28 INFO InMemoryFileIndex: It took 255 ms to list leaf files for 1 paths.
2022.02.12 15:13:28 ERROR 22/02/12 15:13:28 INFO InMemoryFileIndex: It took 130 ms to list leaf files for 3 paths.
2022.02.12 15:13:31 ERROR 22/02/12 15:13:31 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:13:31 ERROR 22/02/12 15:13:31 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:13:31 ERROR 22/02/12 15:13:31 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2022.02.12 15:13:31 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:31 ERROR 22/02/12 15:13:31 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:13:31 ERROR 22/02/12 15:13:31 INFO CodeGenerator: Code generated in 329.988098 ms
2022.02.12 15:13:31 ERROR 22/02/12 15:13:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:13:31 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:13:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.178.30:60114 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO SparkContext: Created broadcast 0 from load at IOHelper.scala:41
2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195847 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO DAGScheduler: Got job 0 (load at IOHelper.scala:41) with 1 output partitions
2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO DAGScheduler: Final stage: ResultStage 0 (load at IOHelper.scala:41)
2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:13:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:13:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022.02.12 15:13:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022.02.12 15:13:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.178.30:60114 (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0))
2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:13:32 ERROR 22/02/12 15:13:32 INFO CodeGenerator: Code generated in 17.099455 ms
2022.02.12 15:13:32 ERROR 22/02/12 15:13:33 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1810 bytes result sent to driver
2022.02.12 15:13:32 ERROR 22/02/12 15:13:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 443 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 15:13:32 ERROR 22/02/12 15:13:33 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022.02.12 15:13:32 ERROR 22/02/12 15:13:33 INFO DAGScheduler: ResultStage 0 (load at IOHelper.scala:41) finished in 0,590 s
2022.02.12 15:13:32 ERROR 22/02/12 15:13:33 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:13:32 ERROR 22/02/12 15:13:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2022.02.12 15:13:32 ERROR 22/02/12 15:13:33 INFO DAGScheduler: Job 0 finished: load at IOHelper.scala:41, took 0,644986 s
2022.02.12 15:13:32 ERROR 22/02/12 15:13:33 INFO CodeGenerator: Code generated in 17.246078 ms
2022.02.12 15:13:32 ERROR 22/02/12 15:13:33 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:13:32 ERROR 22/02/12 15:13:33 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:13:32 ERROR 22/02/12 15:13:33 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:13:32 ERROR 22/02/12 15:13:33 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:13:32 ERROR 22/02/12 15:13:33 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:13:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:32 ERROR 22/02/12 15:13:33 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:13:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:32 ERROR 22/02/12 15:13:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.178.30:60114 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:13:32 ERROR 22/02/12 15:13:33 INFO SparkContext: Created broadcast 2 from load at IOHelper.scala:41
2022.02.12 15:13:32 ERROR 22/02/12 15:13:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195847 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO DAGScheduler: Got job 1 (load at IOHelper.scala:41) with 3 output partitions
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO DAGScheduler: Final stage: ResultStage 1 (load at IOHelper.scala:41)
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:13:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:13:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.2 KiB, free 2.2 GiB)
2022.02.12 15:13:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
2022.02.12 15:13:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.178.30:60114 (size: 7.6 KiB, free: 2.2 GiB)
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 7791 bytes)
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1600 bytes result sent to driver
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1648 bytes result sent to driver
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1600 bytes result sent to driver
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 152 ms on 192.168.178.30 (executor driver) (1/3)
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 152 ms on 192.168.178.30 (executor driver) (2/3)
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 154 ms on 192.168.178.30 (executor driver) (3/3)
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO DAGScheduler: ResultStage 1 (load at IOHelper.scala:41) finished in 0,223 s
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO DAGScheduler: Job 1 finished: load at IOHelper.scala:41, took 0,232918 s
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:13:33 ERROR 22/02/12 15:13:33 INFO FileSourceStrategy: Output Data Schema: struct<Dies ist ein Scala Project: string,  welches bereits alle Apache-Spark (https://spark.apache.org/) Dependencies und Build-Konfigurationen enthält um eine jar Datei zu bauen: string,  welche auf einem Cluster ausgeführt werden kann.: string ... 1 more fields>
2022.02.12 15:13:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:33 ERROR 22/02/12 15:13:34 INFO CodeGenerator: Code generated in 22.075158 ms
2022.02.12 15:13:33 ERROR 22/02/12 15:13:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 15:13:33 ERROR 22/02/12 15:13:34 INFO CodeGenerator: Code generated in 29.055154 ms
2022.02.12 15:13:33 ERROR 22/02/12 15:13:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 15:13:33 ERROR 22/02/12 15:13:34 INFO CodeGenerator: Code generated in 27.805873 ms
2022.02.12 15:13:33 ERROR 22/02/12 15:13:34 INFO CodeGenerator: Code generated in 70.324318 ms
2022.02.12 15:13:33 ERROR 22/02/12 15:13:34 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:13:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:33 ERROR 22/02/12 15:13:34 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:13:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:33 ERROR 22/02/12 15:13:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.178.30:60114 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:13:33 ERROR 22/02/12 15:13:34 INFO SparkContext: Created broadcast 4 from collect at Exercise_3a.scala:19
2022.02.12 15:13:33 ERROR 22/02/12 15:13:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO CodeGenerator: Code generated in 10.915153 ms
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO SparkContext: Starting job: collect at Exercise_3a.scala:19
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO DAGScheduler: Registering RDD 17 (collect at Exercise_3a.scala:19) as input to shuffle 0
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO DAGScheduler: Got job 2 (collect at Exercise_3a.scala:19) with 8 output partitions
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO DAGScheduler: Final stage: ResultStage 3 (collect at Exercise_3a.scala:19)
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
2022.02.12 15:13:34 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:34 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at collect at Exercise_3a.scala:19), which has no missing parents
2022.02.12 15:13:34 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 41.2 KiB, free 2.2 GiB)
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 2.2 GiB)
2022.02.12 15:13:34 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.178.30:60114 (size: 16.4 KiB, free: 2.2 GiB)
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at collect at Exercise_3a.scala:19) (first 15 tasks are for partitions Vector(0, 1))
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7748 bytes)
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7748 bytes)
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO CodeGenerator: Code generated in 18.798226 ms
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:
2022.02.12 15:13:34 ERROR  Header length: 1, schema size: 3
2022.02.12 15:13:34 ERROR CSV file: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 WARN BlockManager: Putting block rdd_13_0 failed due to exception java.lang.NullPointerException: Value at index 2 is null.
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 WARN BlockManager: Putting block rdd_13_1 failed due to exception java.lang.NullPointerException: Value at index 2 is null.
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 WARN BlockManager: Block rdd_13_1 could not be removed as it was not found on disk or in memory
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 WARN BlockManager: Block rdd_13_0 could not be removed as it was not found on disk or in memory
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 4)
2022.02.12 15:13:34 ERROR java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:13:34 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:13:34 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:13:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:13:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:13:34 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 ERROR Executor: Exception in task 1.0 in stage 2.0 (TID 5)
2022.02.12 15:13:34 ERROR java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:13:34 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:13:34 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:13:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:13:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:13:34 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 WARN TaskSetManager: Lost task 1.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:13:34 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:13:34 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:13:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:13:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:13:34 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:13:34 ERROR 
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 ERROR TaskSetManager: Task 1 in stage 2.0 failed 1 times; aborting job
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO TaskSetManager: Lost task 0.0 in stage 2.0 (TID 4) on 192.168.178.30, executor driver: java.lang.NullPointerException (Value at index 2 is null) [duplicate 1]
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO TaskSchedulerImpl: Cancelling stage 2
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage cancelled
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO DAGScheduler: ShuffleMapStage 2 (collect at Exercise_3a.scala:19) failed in 0,329 s due to Job aborted due to stage failure: Task 1 in stage 2.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:13:34 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:13:34 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:13:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:13:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:13:34 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:13:34 ERROR 
2022.02.12 15:13:34 ERROR Driver stacktrace:
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO DAGScheduler: Job 2 failed: collect at Exercise_3a.scala:19, took 0,377222 s
2022.02.12 15:13:34 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 2.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:13:34 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:13:34 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:13:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:13:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:13:34 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:13:34 ERROR 
2022.02.12 15:13:34 ERROR Driver stacktrace:
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2023)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1972)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1971)
2022.02.12 15:13:34 ERROR 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
2022.02.12 15:13:34 ERROR 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
2022.02.12 15:13:34 ERROR 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1971)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:950)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:950)
2022.02.12 15:13:34 ERROR 	at scala.Option.foreach(Option.scala:407)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:950)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2203)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2152)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2141)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2133)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:388)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.collect(RDD.scala:1003)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:304)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.prepareShuffleDependency(ShuffleExchangeExec.scala:199)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.shuffleDependency$lzycompute(ShuffleExchangeExec.scala:87)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.shuffleDependency(ShuffleExchangeExec.scala:81)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.$anonfun$doExecute$1(ShuffleExchangeExec.scala:98)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:95)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:525)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:453)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:452)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:496)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:132)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:720)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:316)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:382)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3625)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:2938)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3616)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3614)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Dataset.collect(Dataset.scala:2938)
2022.02.12 15:13:34 ERROR 	at de.hpi.dbsII_exercises.Exercise_3a.execute(Exercise_3a.scala:19)
2022.02.12 15:13:34 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:25)
2022.02.12 15:13:34 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:5)
2022.02.12 15:13:34 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.12 15:13:34 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.12 15:13:34 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.12 15:13:34 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.12 15:13:34 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.12 15:13:34 ERROR 	at scala.App.main(App.scala:80)
2022.02.12 15:13:34 ERROR 	at scala.App.main$(App.scala:78)
2022.02.12 15:13:34 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:5)
2022.02.12 15:13:34 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.12 15:13:34 ERROR Caused by: java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:13:34 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:13:34 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:13:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:13:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:13:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:13:34 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO SparkContext: Invoking stop() from shutdown hook
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO SparkUI: Stopped Spark web UI at http://192.168.178.30:4040
2022.02.12 15:13:34 ERROR 22/02/12 15:13:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2022.02.12 15:13:34 ERROR 22/02/12 15:13:35 INFO MemoryStore: MemoryStore cleared
2022.02.12 15:13:34 ERROR 22/02/12 15:13:35 INFO BlockManager: BlockManager stopped
2022.02.12 15:13:34 ERROR 22/02/12 15:13:35 INFO BlockManagerMaster: BlockManagerMaster stopped
2022.02.12 15:13:34 ERROR 22/02/12 15:13:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2022.02.12 15:13:34 ERROR 22/02/12 15:13:35 INFO SparkContext: Successfully stopped SparkContext
2022.02.12 15:13:34 ERROR 22/02/12 15:13:35 INFO ShutdownHookManager: Shutdown hook called
2022.02.12 15:13:34 ERROR 22/02/12 15:13:35 INFO ShutdownHookManager: Deleting directory /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/spark-58ba4a09-a6f3-4317-82fa-571339f266e8
2022.02.12 15:13:34 INFO  Closing debug server tcp://0.0.0.0:60103
Feb. 12, 2022 3:13:40 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireError
SEVERE: java.net.SocketException: Broken pipe (Write failed)
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.net.SocketException: Broken pipe (Write failed)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.debug.SocketEndpoint.consume(SocketEndpoint.scala:22)
	at scala.meta.internal.metals.debug.MessageIdAdapter.consume(MessageIdAdapter.scala:43)
	at scala.meta.internal.metals.debug.ServerAdapter.send(ServerAdapter.scala:30)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleClientMessage$1(DebugProxy.scala:138)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToClient$1(DebugProxy.scala:63)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.base/java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)
	at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:69)
	... 21 more

2022.02.12 15:13:45 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

Feb. 12, 2022 3:13:45 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireStreamClosed
INFO: Connection reset
java.net.SocketException: Connection reset
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:79)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)

2022.02.12 15:13:45 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:13:52 INFO  compiling spark-tutorial (1 scala source)
Feb. 12, 2022 3:13:53 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2293
2022.02.12 15:13:55 INFO  time: compiled spark-tutorial in 2.75s
2022.02.12 15:13:56 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:13:57 INFO  time: compiled spark-tutorial in 1.18s
2022.02.12 15:13:59 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:14:00 INFO  time: compiled spark-tutorial in 1.44s
2022.02.12 15:14:07 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 41h 27m 40.964s)
2022.02.12 15:14:07 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 15:14:07 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 15:14:08 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:14:12 INFO  Trying to attach to remote debuggee VM localhost:60157 .
2022.02.12 15:14:12 INFO  Attaching to debuggee VM succeeded.
2022.02.12 15:14:14 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 15:14:14 ERROR 22/02/12 15:14:14 WARN Utils: Your hostname, SchulzeTastPro-2.local resolves to a loopback address: 127.0.0.1; using 192.168.178.30 instead (on interface en0)
2022.02.12 15:14:14 ERROR 22/02/12 15:14:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2022.02.12 15:14:14 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 15:14:14 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 15:14:14 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 15:14:14 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 15:14:14 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 15:14:14 ERROR 22/02/12 15:14:14 INFO SparkContext: Running Spark version 3.0.0
2022.02.12 15:14:14 ERROR 22/02/12 15:14:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022.02.12 15:14:14 ERROR 22/02/12 15:14:14 INFO ResourceUtils: ==============================================================
2022.02.12 15:14:14 ERROR 22/02/12 15:14:14 INFO ResourceUtils: Resources for spark.driver:
2022.02.12 15:14:14 ERROR 
2022.02.12 15:14:14 ERROR 22/02/12 15:14:14 INFO ResourceUtils: ==============================================================
2022.02.12 15:14:14 ERROR 22/02/12 15:14:14 INFO SparkContext: Submitted application: SparkTutorial
2022.02.12 15:14:14 ERROR 22/02/12 15:14:14 INFO SecurityManager: Changing view acls to: Johann
2022.02.12 15:14:14 ERROR 22/02/12 15:14:14 INFO SecurityManager: Changing modify acls to: Johann
2022.02.12 15:14:14 ERROR 22/02/12 15:14:14 INFO SecurityManager: Changing view acls groups to: 
2022.02.12 15:14:14 ERROR 22/02/12 15:14:14 INFO SecurityManager: Changing modify acls groups to: 
2022.02.12 15:14:14 ERROR 22/02/12 15:14:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Johann); groups with view permissions: Set(); users  with modify permissions: Set(Johann); groups with modify permissions: Set()
2022.02.12 15:14:14 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:15 ERROR 22/02/12 15:14:15 INFO Utils: Successfully started service 'sparkDriver' on port 60159.
2022.02.12 15:14:15 ERROR 22/02/12 15:14:15 INFO SparkEnv: Registering MapOutputTracker
2022.02.12 15:14:15 ERROR 22/02/12 15:14:15 INFO SparkEnv: Registering BlockManagerMaster
2022.02.12 15:14:15 ERROR 22/02/12 15:14:15 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022.02.12 15:14:15 ERROR 22/02/12 15:14:15 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022.02.12 15:14:15 ERROR 22/02/12 15:14:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2022.02.12 15:14:15 ERROR 22/02/12 15:14:16 INFO DiskBlockManager: Created local directory at /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/blockmgr-74a07690-9038-4242-ac1b-d871ec2937f6
2022.02.12 15:14:15 ERROR 22/02/12 15:14:16 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
2022.02.12 15:14:15 ERROR 22/02/12 15:14:16 INFO SparkEnv: Registering OutputCommitCoordinator
2022.02.12 15:14:15 ERROR 22/02/12 15:14:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2022.02.12 15:14:15 ERROR 22/02/12 15:14:16 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.178.30:4040
2022.02.12 15:14:16 ERROR 22/02/12 15:14:16 INFO Executor: Starting executor ID driver on host 192.168.178.30
2022.02.12 15:14:16 ERROR 22/02/12 15:14:16 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60161.
2022.02.12 15:14:16 ERROR 22/02/12 15:14:16 INFO NettyBlockTransferService: Server created on 192.168.178.30:60161
2022.02.12 15:14:16 ERROR 22/02/12 15:14:16 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022.02.12 15:14:16 ERROR 22/02/12 15:14:16 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.178.30, 60161, None)
2022.02.12 15:14:16 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:16 ERROR 22/02/12 15:14:16 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.178.30:60161 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.178.30, 60161, None)
2022.02.12 15:14:16 ERROR 22/02/12 15:14:16 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.178.30, 60161, None)
2022.02.12 15:14:16 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:16 ERROR 22/02/12 15:14:16 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.178.30, 60161, None)
2022.02.12 15:14:16 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:16 ERROR 22/02/12 15:14:17 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse').
2022.02.12 15:14:16 ERROR 22/02/12 15:14:17 INFO SharedState: Warehouse path is 'file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse'.
2022.02.12 15:14:18 ERROR 22/02/12 15:14:18 INFO InMemoryFileIndex: It took 208 ms to list leaf files for 1 paths.
2022.02.12 15:14:18 ERROR 22/02/12 15:14:18 INFO InMemoryFileIndex: It took 84 ms to list leaf files for 3 paths.
2022.02.12 15:14:21 ERROR 22/02/12 15:14:21 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:14:21 ERROR 22/02/12 15:14:21 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:14:21 ERROR 22/02/12 15:14:21 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2022.02.12 15:14:21 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:21 ERROR 22/02/12 15:14:21 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:14:21 ERROR 22/02/12 15:14:22 INFO CodeGenerator: Code generated in 233.134863 ms
2022.02.12 15:14:21 ERROR 22/02/12 15:14:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:14:21 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:21 ERROR 22/02/12 15:14:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:14:21 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:21 ERROR 22/02/12 15:14:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.178.30:60161 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:14:21 ERROR 22/02/12 15:14:22 INFO SparkContext: Created broadcast 0 from load at IOHelper.scala:41
2022.02.12 15:14:21 ERROR 22/02/12 15:14:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195847 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:14:22 ERROR 22/02/12 15:14:22 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:14:22 ERROR 22/02/12 15:14:22 INFO DAGScheduler: Got job 0 (load at IOHelper.scala:41) with 1 output partitions
2022.02.12 15:14:22 ERROR 22/02/12 15:14:22 INFO DAGScheduler: Final stage: ResultStage 0 (load at IOHelper.scala:41)
2022.02.12 15:14:22 ERROR 22/02/12 15:14:22 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:14:22 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:22 ERROR 22/02/12 15:14:22 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:14:22 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:22 ERROR 22/02/12 15:14:22 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:14:22 ERROR 22/02/12 15:14:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022.02.12 15:14:22 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:22 ERROR 22/02/12 15:14:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022.02.12 15:14:22 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:22 ERROR 22/02/12 15:14:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.178.30:60161 (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 15:14:22 ERROR 22/02/12 15:14:22 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:14:22 ERROR 22/02/12 15:14:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0))
2022.02.12 15:14:22 ERROR 22/02/12 15:14:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
2022.02.12 15:14:22 ERROR 22/02/12 15:14:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:14:22 ERROR 22/02/12 15:14:22 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO CodeGenerator: Code generated in 18.199201 ms
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1810 bytes result sent to driver
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 443 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO DAGScheduler: ResultStage 0 (load at IOHelper.scala:41) finished in 0,606 s
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO DAGScheduler: Job 0 finished: load at IOHelper.scala:41, took 0,663008 s
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO CodeGenerator: Code generated in 19.420399 ms
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:14:22 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:14:22 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.178.30:60161 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO SparkContext: Created broadcast 2 from load at IOHelper.scala:41
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195847 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO DAGScheduler: Got job 1 (load at IOHelper.scala:41) with 3 output partitions
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO DAGScheduler: Final stage: ResultStage 1 (load at IOHelper.scala:41)
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:14:22 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:14:22 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.2 KiB, free 2.2 GiB)
2022.02.12 15:14:22 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
2022.02.12 15:14:22 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:22 ERROR 22/02/12 15:14:23 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.178.30:60161 (size: 7.6 KiB, free: 2.2 GiB)
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 7791 bytes)
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1600 bytes result sent to driver
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1600 bytes result sent to driver
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1648 bytes result sent to driver
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 171 ms on 192.168.178.30 (executor driver) (1/3)
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 175 ms on 192.168.178.30 (executor driver) (2/3)
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 177 ms on 192.168.178.30 (executor driver) (3/3)
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO DAGScheduler: ResultStage 1 (load at IOHelper.scala:41) finished in 0,237 s
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO DAGScheduler: Job 1 finished: load at IOHelper.scala:41, took 0,247853 s
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:14:23 ERROR 22/02/12 15:14:23 INFO FileSourceStrategy: Output Data Schema: struct<Dies ist ein Scala Project: string,  welches bereits alle Apache-Spark (https://spark.apache.org/) Dependencies und Build-Konfigurationen enthält um eine jar Datei zu bauen: string,  welche auf einem Cluster ausgeführt werden kann.: string ... 1 more fields>
2022.02.12 15:14:23 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:23 ERROR 22/02/12 15:14:24 INFO CodeGenerator: Code generated in 26.417493 ms
2022.02.12 15:14:23 ERROR 22/02/12 15:14:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 15:14:23 ERROR 22/02/12 15:14:24 INFO CodeGenerator: Code generated in 37.248294 ms
2022.02.12 15:14:23 ERROR 22/02/12 15:14:24 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 15:14:23 ERROR 22/02/12 15:14:24 INFO CodeGenerator: Code generated in 27.584545 ms
2022.02.12 15:14:23 ERROR 22/02/12 15:14:24 INFO CodeGenerator: Code generated in 49.123888 ms
2022.02.12 15:14:23 ERROR 22/02/12 15:14:24 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:14:23 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:23 ERROR 22/02/12 15:14:24 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:14:23 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:23 ERROR 22/02/12 15:14:24 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.178.30:60161 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:14:23 ERROR 22/02/12 15:14:24 INFO SparkContext: Created broadcast 4 from collect at Exercise_3a.scala:19
2022.02.12 15:14:23 ERROR 22/02/12 15:14:24 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:14:23 ERROR 22/02/12 15:14:24 INFO CodeGenerator: Code generated in 10.813057 ms
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO SparkContext: Starting job: collect at Exercise_3a.scala:19
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO DAGScheduler: Registering RDD 17 (collect at Exercise_3a.scala:19) as input to shuffle 0
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO DAGScheduler: Got job 2 (collect at Exercise_3a.scala:19) with 8 output partitions
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO DAGScheduler: Final stage: ResultStage 3 (collect at Exercise_3a.scala:19)
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
2022.02.12 15:14:23 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:23 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at collect at Exercise_3a.scala:19), which has no missing parents
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 41.2 KiB, free 2.2 GiB)
2022.02.12 15:14:23 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 2.2 GiB)
2022.02.12 15:14:23 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.178.30:60161 (size: 16.4 KiB, free: 2.2 GiB)
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at collect at Exercise_3a.scala:19) (first 15 tasks are for partitions Vector(0, 1))
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7748 bytes)
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7748 bytes)
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO CodeGenerator: Code generated in 12.34495 ms
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:
2022.02.12 15:14:24 ERROR  Header length: 1, schema size: 3
2022.02.12 15:14:24 ERROR CSV file: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 WARN BlockManager: Putting block rdd_13_1 failed due to exception java.lang.NullPointerException: Value at index 2 is null.
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 WARN BlockManager: Putting block rdd_13_0 failed due to exception java.lang.NullPointerException: Value at index 2 is null.
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 WARN BlockManager: Block rdd_13_1 could not be removed as it was not found on disk or in memory
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 WARN BlockManager: Block rdd_13_0 could not be removed as it was not found on disk or in memory
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 ERROR Executor: Exception in task 1.0 in stage 2.0 (TID 5)
2022.02.12 15:14:24 ERROR java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:14:24 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:14:24 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:14:24 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:14:24 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:14:24 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 4)
2022.02.12 15:14:24 ERROR java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:14:24 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:14:24 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:14:24 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:14:24 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:14:24 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 WARN TaskSetManager: Lost task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:14:24 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:14:24 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:14:24 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:14:24 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:14:24 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:14:24 ERROR 
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 ERROR TaskSetManager: Task 0 in stage 2.0 failed 1 times; aborting job
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO TaskSetManager: Lost task 1.0 in stage 2.0 (TID 5) on 192.168.178.30, executor driver: java.lang.NullPointerException (Value at index 2 is null) [duplicate 1]
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO TaskSchedulerImpl: Cancelling stage 2
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage cancelled
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO DAGScheduler: ShuffleMapStage 2 (collect at Exercise_3a.scala:19) failed in 0,254 s due to Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:14:24 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:14:24 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:14:24 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:14:24 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:14:24 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:14:24 ERROR 
2022.02.12 15:14:24 ERROR Driver stacktrace:
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO DAGScheduler: Job 2 failed: collect at Exercise_3a.scala:19, took 0,288700 s
2022.02.12 15:14:24 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:14:24 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:14:24 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:14:24 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:14:24 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:14:24 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:14:24 ERROR 
2022.02.12 15:14:24 ERROR Driver stacktrace:
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2023)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1972)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1971)
2022.02.12 15:14:24 ERROR 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
2022.02.12 15:14:24 ERROR 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
2022.02.12 15:14:24 ERROR 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1971)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:950)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:950)
2022.02.12 15:14:24 ERROR 	at scala.Option.foreach(Option.scala:407)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:950)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2203)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2152)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2141)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2133)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:388)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.collect(RDD.scala:1003)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:304)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.prepareShuffleDependency(ShuffleExchangeExec.scala:199)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.shuffleDependency$lzycompute(ShuffleExchangeExec.scala:87)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.shuffleDependency(ShuffleExchangeExec.scala:81)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.$anonfun$doExecute$1(ShuffleExchangeExec.scala:98)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:95)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:525)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:453)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:452)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:496)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:132)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:720)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:316)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:382)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3625)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:2938)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3616)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3614)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Dataset.collect(Dataset.scala:2938)
2022.02.12 15:14:24 ERROR 	at de.hpi.dbsII_exercises.Exercise_3a.execute(Exercise_3a.scala:19)
2022.02.12 15:14:24 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:25)
2022.02.12 15:14:24 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:5)
2022.02.12 15:14:24 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.12 15:14:24 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.12 15:14:24 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.12 15:14:24 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.12 15:14:24 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.12 15:14:24 ERROR 	at scala.App.main(App.scala:80)
2022.02.12 15:14:24 ERROR 	at scala.App.main$(App.scala:78)
2022.02.12 15:14:24 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:5)
2022.02.12 15:14:24 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.12 15:14:24 ERROR Caused by: java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:14:24 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:14:24 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:14:24 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:14:24 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:14:24 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:14:24 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO SparkContext: Invoking stop() from shutdown hook
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO SparkUI: Stopped Spark web UI at http://192.168.178.30:4040
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO MemoryStore: MemoryStore cleared
2022.02.12 15:14:24 ERROR 22/02/12 15:14:24 INFO BlockManager: BlockManager stopped
2022.02.12 15:14:24 ERROR 22/02/12 15:14:25 INFO BlockManagerMaster: BlockManagerMaster stopped
2022.02.12 15:14:24 ERROR 22/02/12 15:14:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2022.02.12 15:14:24 ERROR 22/02/12 15:14:25 INFO SparkContext: Successfully stopped SparkContext
2022.02.12 15:14:24 ERROR 22/02/12 15:14:25 INFO ShutdownHookManager: Shutdown hook called
2022.02.12 15:14:24 ERROR 22/02/12 15:14:25 INFO ShutdownHookManager: Deleting directory /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/spark-24c6c2ba-0954-4aed-b951-74442ff5d90c
2022.02.12 15:14:24 INFO  Closing debug server tcp://0.0.0.0:60149
2022.02.12 15:14:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

Feb. 12, 2022 3:14:33 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireStreamClosed
INFO: Connection reset
java.net.SocketException: Connection reset
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:79)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)

2022.02.12 15:14:33 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:14:54 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 41h 28m 27.369s)
2022.02.12 15:14:54 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 15:14:54 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 15:14:54 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:14:58 INFO  Trying to attach to remote debuggee VM localhost:60179 .
2022.02.12 15:14:58 INFO  Attaching to debuggee VM succeeded.
2022.02.12 15:16:11 ERROR [error response][evaluate]: Cannot evaluate because of ch.epfl.scala.debugadapter.internal.evaluator.ExpressionCompilationFailed: unclosed string literal.
2022.02.12 15:16:37 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 15:16:37 ERROR 22/02/12 15:16:37 WARN Utils: Your hostname, SchulzeTastPro-2.local resolves to a loopback address: 127.0.0.1; using 192.168.178.30 instead (on interface en0)
2022.02.12 15:16:37 ERROR 22/02/12 15:16:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2022.02.12 15:16:37 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 15:16:37 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 15:16:37 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 15:16:37 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 15:16:37 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 15:16:37 ERROR 22/02/12 15:16:38 INFO SparkContext: Running Spark version 3.0.0
2022.02.12 15:16:44 ERROR 22/02/12 15:16:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022.02.12 15:16:48 ERROR 22/02/12 15:16:48 INFO ResourceUtils: ==============================================================
2022.02.12 15:16:48 ERROR 22/02/12 15:16:48 INFO ResourceUtils: Resources for spark.driver:
2022.02.12 15:16:48 ERROR 
2022.02.12 15:16:48 ERROR 22/02/12 15:16:48 INFO ResourceUtils: ==============================================================
2022.02.12 15:16:48 ERROR 22/02/12 15:16:48 INFO SparkContext: Submitted application: SparkTutorial
2022.02.12 15:16:48 ERROR 22/02/12 15:16:48 INFO SecurityManager: Changing view acls to: Johann
2022.02.12 15:16:48 ERROR 22/02/12 15:16:48 INFO SecurityManager: Changing modify acls to: Johann
2022.02.12 15:16:48 ERROR 22/02/12 15:16:48 INFO SecurityManager: Changing view acls groups to: 
2022.02.12 15:16:48 ERROR 22/02/12 15:16:48 INFO SecurityManager: Changing modify acls groups to: 
2022.02.12 15:16:48 ERROR 22/02/12 15:16:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Johann); groups with view permissions: Set(); users  with modify permissions: Set(Johann); groups with modify permissions: Set()
2022.02.12 15:16:48 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:16:57 ERROR 22/02/12 15:16:57 INFO Utils: Successfully started service 'sparkDriver' on port 60203.
2022.02.12 15:16:57 ERROR 22/02/12 15:16:58 INFO SparkEnv: Registering MapOutputTracker
2022.02.12 15:16:57 ERROR 22/02/12 15:16:58 INFO SparkEnv: Registering BlockManagerMaster
2022.02.12 15:16:57 ERROR 22/02/12 15:16:58 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022.02.12 15:16:57 ERROR 22/02/12 15:16:58 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022.02.12 15:16:57 ERROR 22/02/12 15:16:58 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2022.02.12 15:16:57 ERROR 22/02/12 15:16:58 INFO DiskBlockManager: Created local directory at /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/blockmgr-829fa5b4-1f8a-4f78-8df5-5b531878f9b4
2022.02.12 15:16:59 ERROR 22/02/12 15:16:59 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
2022.02.12 15:16:59 ERROR 22/02/12 15:16:59 INFO SparkEnv: Registering OutputCommitCoordinator
2022.02.12 15:17:01 ERROR 22/02/12 15:17:01 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2022.02.12 15:17:01 ERROR 22/02/12 15:17:01 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.178.30:4040
2022.02.12 15:17:06 ERROR 22/02/12 15:17:06 INFO Executor: Starting executor ID driver on host 192.168.178.30
2022.02.12 15:17:06 ERROR 22/02/12 15:17:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60205.
2022.02.12 15:17:06 ERROR 22/02/12 15:17:06 INFO NettyBlockTransferService: Server created on 192.168.178.30:60205
2022.02.12 15:17:06 ERROR 22/02/12 15:17:06 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022.02.12 15:17:06 ERROR 22/02/12 15:17:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.178.30, 60205, None)
2022.02.12 15:17:06 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:17:06 ERROR 22/02/12 15:17:06 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.178.30:60205 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.178.30, 60205, None)
2022.02.12 15:17:06 ERROR 22/02/12 15:17:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.178.30, 60205, None)
2022.02.12 15:17:06 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:17:06 ERROR 22/02/12 15:17:06 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.178.30, 60205, None)
2022.02.12 15:17:06 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:19:47 ERROR 22/02/12 15:19:47 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse').
2022.02.12 15:19:47 ERROR 22/02/12 15:19:47 INFO SharedState: Warehouse path is 'file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse'.
2022.02.12 15:20:29 ERROR 22/02/12 15:20:29 INFO InMemoryFileIndex: It took 4201 ms to list leaf files for 1 paths.
2022.02.12 15:20:34 ERROR 22/02/12 15:20:34 INFO InMemoryFileIndex: It took 3305 ms to list leaf files for 3 paths.
2022.02.12 15:21:03 ERROR 22/02/12 15:21:03 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:21:03 ERROR 22/02/12 15:21:03 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:21:03 ERROR 22/02/12 15:21:03 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2022.02.12 15:21:03 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:21:03 ERROR 22/02/12 15:21:03 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:21:30 ERROR 22/02/12 15:21:30 INFO CodeGenerator: Code generated in 19327.187978 ms
2022.02.12 15:21:30 ERROR 22/02/12 15:21:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:21:31 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:21:32 ERROR 22/02/12 15:21:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:21:31 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:21:32 ERROR 22/02/12 15:21:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.178.30:60205 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:21:32 ERROR 22/02/12 15:21:32 INFO SparkContext: Created broadcast 0 from load at IOHelper.scala:41
2022.02.12 15:21:32 ERROR 22/02/12 15:21:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195847 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:21:34 ERROR 22/02/12 15:21:34 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:21:34 ERROR 22/02/12 15:21:34 INFO DAGScheduler: Got job 0 (load at IOHelper.scala:41) with 1 output partitions
2022.02.12 15:21:34 ERROR 22/02/12 15:21:34 INFO DAGScheduler: Final stage: ResultStage 0 (load at IOHelper.scala:41)
2022.02.12 15:21:34 ERROR 22/02/12 15:21:34 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:21:34 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:21:34 ERROR 22/02/12 15:21:34 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:21:34 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:21:34 ERROR 22/02/12 15:21:34 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:21:34 ERROR 22/02/12 15:21:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022.02.12 15:21:34 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:21:34 ERROR 22/02/12 15:21:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022.02.12 15:21:34 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:21:34 ERROR 22/02/12 15:21:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.178.30:60205 (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 15:21:34 ERROR 22/02/12 15:21:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:21:34 ERROR 22/02/12 15:21:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0))
2022.02.12 15:21:34 ERROR 22/02/12 15:21:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
2022.02.12 15:21:34 ERROR 22/02/12 15:21:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:21:34 ERROR 22/02/12 15:21:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2022.02.12 15:21:34 ERROR 22/02/12 15:21:35 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:21:34 ERROR 22/02/12 15:21:35 INFO CodeGenerator: Code generated in 48.122357 ms
2022.02.12 15:21:35 ERROR 22/02/12 15:21:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1767 bytes result sent to driver
2022.02.12 15:21:35 ERROR 22/02/12 15:21:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 721 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 15:21:35 ERROR 22/02/12 15:21:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022.02.12 15:21:35 ERROR 22/02/12 15:21:35 INFO DAGScheduler: ResultStage 0 (load at IOHelper.scala:41) finished in 1,144 s
2022.02.12 15:21:35 ERROR 22/02/12 15:21:35 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:21:35 ERROR 22/02/12 15:21:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2022.02.12 15:21:35 ERROR 22/02/12 15:21:35 INFO DAGScheduler: Job 0 finished: load at IOHelper.scala:41, took 1,288174 s
2022.02.12 15:21:35 ERROR 22/02/12 15:21:36 INFO CodeGenerator: Code generated in 260.150454 ms
2022.02.12 15:21:39 ERROR 22/02/12 15:21:39 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:21:39 ERROR 22/02/12 15:21:39 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:21:39 ERROR 22/02/12 15:21:39 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:21:39 ERROR 22/02/12 15:21:39 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:21:39 ERROR 22/02/12 15:21:40 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:21:40 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:21:39 ERROR 22/02/12 15:21:40 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:21:40 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:21:39 ERROR 22/02/12 15:21:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.178.30:60205 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:21:39 ERROR 22/02/12 15:21:40 INFO SparkContext: Created broadcast 2 from load at IOHelper.scala:41
2022.02.12 15:21:39 ERROR 22/02/12 15:21:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195847 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO DAGScheduler: Got job 1 (load at IOHelper.scala:41) with 3 output partitions
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO DAGScheduler: Final stage: ResultStage 1 (load at IOHelper.scala:41)
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:21:42 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:21:42 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.2 KiB, free 2.2 GiB)
2022.02.12 15:21:42 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:21:42 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.178.30:60205 (size: 7.6 KiB, free: 2.2 GiB)
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 7791 bytes)
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:21:42 ERROR 22/02/12 15:21:42 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:21:42 ERROR 22/02/12 15:21:43 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:21:42 ERROR 22/02/12 15:21:43 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1600 bytes result sent to driver
2022.02.12 15:21:42 ERROR 22/02/12 15:21:43 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1600 bytes result sent to driver
2022.02.12 15:21:42 ERROR 22/02/12 15:21:43 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1648 bytes result sent to driver
2022.02.12 15:21:42 ERROR 22/02/12 15:21:43 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 272 ms on 192.168.178.30 (executor driver) (1/3)
2022.02.12 15:21:42 ERROR 22/02/12 15:21:43 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 268 ms on 192.168.178.30 (executor driver) (2/3)
2022.02.12 15:21:42 ERROR 22/02/12 15:21:43 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 270 ms on 192.168.178.30 (executor driver) (3/3)
2022.02.12 15:21:42 ERROR 22/02/12 15:21:43 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022.02.12 15:21:42 ERROR 22/02/12 15:21:43 INFO DAGScheduler: ResultStage 1 (load at IOHelper.scala:41) finished in 0,413 s
2022.02.12 15:21:42 ERROR 22/02/12 15:21:43 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:21:42 ERROR 22/02/12 15:21:43 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2022.02.12 15:21:42 ERROR 22/02/12 15:21:43 INFO DAGScheduler: Job 1 finished: load at IOHelper.scala:41, took 0,434183 s
2022.02.12 15:22:10 ERROR 22/02/12 15:22:10 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:22:10 ERROR 22/02/12 15:22:10 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:22:10 ERROR 22/02/12 15:22:10 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:22:10 ERROR 22/02/12 15:22:10 INFO FileSourceStrategy: Output Data Schema: struct<Dies ist ein Scala Project: string,  welches bereits alle Apache-Spark (https://spark.apache.org/) Dependencies und Build-Konfigurationen enthält um eine jar Datei zu bauen: string,  welche auf einem Cluster ausgeführt werden kann.: string ... 1 more fields>
2022.02.12 15:22:10 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:22:53 ERROR 22/02/12 15:22:53 INFO CodeGenerator: Code generated in 632.21341 ms
2022.02.12 15:22:53 ERROR 22/02/12 15:22:53 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 15:22:54 ERROR 22/02/12 15:22:54 INFO CodeGenerator: Code generated in 634.774571 ms
2022.02.12 15:22:54 ERROR 22/02/12 15:22:54 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 15:22:54 ERROR 22/02/12 15:22:55 INFO CodeGenerator: Code generated in 550.84123 ms
2022.02.12 15:22:57 ERROR 22/02/12 15:22:57 INFO CodeGenerator: Code generated in 960.397009 ms
2022.02.12 15:22:57 ERROR 22/02/12 15:22:57 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:22:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:22:57 ERROR 22/02/12 15:22:57 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:22:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:22:57 ERROR 22/02/12 15:22:57 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.178.30:60205 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:22:57 ERROR 22/02/12 15:22:57 INFO SparkContext: Created broadcast 4 from collect at Exercise_3a.scala:19
2022.02.12 15:22:57 ERROR 22/02/12 15:22:57 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:23:00 ERROR 22/02/12 15:23:00 INFO CodeGenerator: Code generated in 228.892041 ms
2022.02.12 15:23:01 ERROR 22/02/12 15:23:01 INFO SparkContext: Starting job: collect at Exercise_3a.scala:19
2022.02.12 15:23:01 ERROR 22/02/12 15:23:01 INFO DAGScheduler: Registering RDD 17 (collect at Exercise_3a.scala:19) as input to shuffle 0
2022.02.12 15:23:01 ERROR 22/02/12 15:23:01 INFO DAGScheduler: Got job 2 (collect at Exercise_3a.scala:19) with 8 output partitions
2022.02.12 15:23:01 ERROR 22/02/12 15:23:01 INFO DAGScheduler: Final stage: ResultStage 3 (collect at Exercise_3a.scala:19)
2022.02.12 15:23:01 ERROR 22/02/12 15:23:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
2022.02.12 15:23:01 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:23:01 ERROR 22/02/12 15:23:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
2022.02.12 15:23:01 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:23:01 ERROR 22/02/12 15:23:01 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at collect at Exercise_3a.scala:19), which has no missing parents
2022.02.12 15:23:01 ERROR 22/02/12 15:23:01 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 41.2 KiB, free 2.2 GiB)
2022.02.12 15:23:01 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:23:01 ERROR 22/02/12 15:23:01 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 2.2 GiB)
2022.02.12 15:23:01 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:23:01 ERROR 22/02/12 15:23:01 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.178.30:60205 (size: 16.4 KiB, free: 2.2 GiB)
2022.02.12 15:23:01 ERROR 22/02/12 15:23:01 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:23:01 ERROR 22/02/12 15:23:01 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at collect at Exercise_3a.scala:19) (first 15 tasks are for partitions Vector(0, 1))
2022.02.12 15:23:01 ERROR 22/02/12 15:23:01 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
2022.02.12 15:23:01 ERROR 22/02/12 15:23:01 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7748 bytes)
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7748 bytes)
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 INFO CodeGenerator: Code generated in 46.974759 ms
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:
2022.02.12 15:23:01 ERROR  Header length: 1, schema size: 3
2022.02.12 15:23:01 ERROR CSV file: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 WARN BlockManager: Putting block rdd_13_1 failed due to exception java.lang.NullPointerException: Value at index 2 is null.
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 WARN BlockManager: Putting block rdd_13_0 failed due to exception java.lang.NullPointerException: Value at index 2 is null.
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 WARN BlockManager: Block rdd_13_0 could not be removed as it was not found on disk or in memory
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 WARN BlockManager: Block rdd_13_1 could not be removed as it was not found on disk or in memory
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 ERROR Executor: Exception in task 1.0 in stage 2.0 (TID 5)
2022.02.12 15:23:01 ERROR java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:23:01 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:23:01 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:23:01 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:23:01 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:23:01 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 4)
2022.02.12 15:23:01 ERROR java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:23:01 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:23:01 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:23:01 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:23:01 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:23:01 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 WARN TaskSetManager: Lost task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:23:01 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:23:01 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:23:01 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:23:01 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:23:01 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:23:01 ERROR 
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 ERROR TaskSetManager: Task 0 in stage 2.0 failed 1 times; aborting job
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 INFO TaskSetManager: Lost task 1.0 in stage 2.0 (TID 5) on 192.168.178.30, executor driver: java.lang.NullPointerException (Value at index 2 is null) [duplicate 1]
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 INFO TaskSchedulerImpl: Cancelling stage 2
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage cancelled
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 INFO DAGScheduler: ShuffleMapStage 2 (collect at Exercise_3a.scala:19) failed in 0,354 s due to Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:23:01 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:23:01 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:23:01 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:23:01 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:23:01 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:23:01 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:23:01 ERROR 
2022.02.12 15:23:01 ERROR Driver stacktrace:
2022.02.12 15:23:01 ERROR 22/02/12 15:23:02 INFO DAGScheduler: Job 2 failed: collect at Exercise_3a.scala:19, took 0,410176 s
2022.02.12 15:23:55 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:23:55 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:23:55 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:23:55 INFO  Closing debug server tcp://0.0.0.0:60173
2022.02.12 15:23:55 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:23:55 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:23:55 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:23:55 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:23:55 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:23:55 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:23:55 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:23:55 ERROR 
2022.02.12 15:23:55 ERROR Driver stacktrace:
2022.02.12 15:24:16 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 41h 37m 49.596s)
2022.02.12 15:24:16 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 15:24:17 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 15:24:17 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:24:21 INFO  Trying to attach to remote debuggee VM localhost:60279 .
2022.02.12 15:24:21 INFO  Attaching to debuggee VM succeeded.
2022.02.12 15:24:23 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 15:24:23 ERROR 22/02/12 15:24:23 WARN Utils: Your hostname, SchulzeTastPro-2.local resolves to a loopback address: 127.0.0.1; using 192.168.178.30 instead (on interface en0)
2022.02.12 15:24:23 ERROR 22/02/12 15:24:23 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2022.02.12 15:24:23 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 15:24:23 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 15:24:23 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 15:24:23 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 15:24:23 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 15:24:23 ERROR 22/02/12 15:24:23 INFO SparkContext: Running Spark version 3.0.0
2022.02.12 15:24:23 ERROR 22/02/12 15:24:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022.02.12 15:24:23 ERROR 22/02/12 15:24:24 INFO ResourceUtils: ==============================================================
2022.02.12 15:24:23 ERROR 22/02/12 15:24:24 INFO ResourceUtils: Resources for spark.driver:
2022.02.12 15:24:23 ERROR 
2022.02.12 15:24:23 ERROR 22/02/12 15:24:24 INFO ResourceUtils: ==============================================================
2022.02.12 15:24:23 ERROR 22/02/12 15:24:24 INFO SparkContext: Submitted application: SparkTutorial
2022.02.12 15:24:23 ERROR 22/02/12 15:24:24 INFO SecurityManager: Changing view acls to: Johann
2022.02.12 15:24:23 ERROR 22/02/12 15:24:24 INFO SecurityManager: Changing modify acls to: Johann
2022.02.12 15:24:23 ERROR 22/02/12 15:24:24 INFO SecurityManager: Changing view acls groups to: 
2022.02.12 15:24:24 ERROR 22/02/12 15:24:24 INFO SecurityManager: Changing modify acls groups to: 
2022.02.12 15:24:24 ERROR 22/02/12 15:24:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Johann); groups with view permissions: Set(); users  with modify permissions: Set(Johann); groups with modify permissions: Set()
2022.02.12 15:24:24 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:24 ERROR 22/02/12 15:24:25 INFO Utils: Successfully started service 'sparkDriver' on port 60282.
2022.02.12 15:24:24 ERROR 22/02/12 15:24:25 INFO SparkEnv: Registering MapOutputTracker
2022.02.12 15:24:24 ERROR 22/02/12 15:24:25 INFO SparkEnv: Registering BlockManagerMaster
2022.02.12 15:24:24 ERROR 22/02/12 15:24:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022.02.12 15:24:24 ERROR 22/02/12 15:24:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022.02.12 15:24:24 ERROR 22/02/12 15:24:25 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2022.02.12 15:24:24 ERROR 22/02/12 15:24:25 INFO DiskBlockManager: Created local directory at /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/blockmgr-de9f814d-eaf8-4f48-b134-4af9ffee48ca
2022.02.12 15:24:24 ERROR 22/02/12 15:24:25 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
2022.02.12 15:24:24 ERROR 22/02/12 15:24:25 INFO SparkEnv: Registering OutputCommitCoordinator
2022.02.12 15:24:25 ERROR 22/02/12 15:24:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2022.02.12 15:24:25 ERROR 22/02/12 15:24:25 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.178.30:4040
2022.02.12 15:24:25 ERROR 22/02/12 15:24:26 INFO Executor: Starting executor ID driver on host 192.168.178.30
2022.02.12 15:24:25 ERROR 22/02/12 15:24:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60283.
2022.02.12 15:24:25 ERROR 22/02/12 15:24:26 INFO NettyBlockTransferService: Server created on 192.168.178.30:60283
2022.02.12 15:24:25 ERROR 22/02/12 15:24:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022.02.12 15:24:25 ERROR 22/02/12 15:24:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.178.30, 60283, None)
2022.02.12 15:24:26 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:25 ERROR 22/02/12 15:24:26 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.178.30:60283 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.178.30, 60283, None)
2022.02.12 15:24:26 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:25 ERROR 22/02/12 15:24:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.178.30, 60283, None)
2022.02.12 15:24:25 ERROR 22/02/12 15:24:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.178.30, 60283, None)
2022.02.12 15:24:26 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:26 ERROR 22/02/12 15:24:26 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse').
2022.02.12 15:24:26 ERROR 22/02/12 15:24:26 INFO SharedState: Warehouse path is 'file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse'.
2022.02.12 15:24:28 ERROR 22/02/12 15:24:28 INFO InMemoryFileIndex: It took 286 ms to list leaf files for 1 paths.
2022.02.12 15:24:28 ERROR 22/02/12 15:24:28 INFO InMemoryFileIndex: It took 108 ms to list leaf files for 3 paths.
2022.02.12 15:24:31 ERROR 22/02/12 15:24:31 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:24:31 ERROR 22/02/12 15:24:31 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:24:31 ERROR 22/02/12 15:24:31 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2022.02.12 15:24:31 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:31 ERROR 22/02/12 15:24:31 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:24:31 ERROR 22/02/12 15:24:31 INFO CodeGenerator: Code generated in 291.58677 ms
2022.02.12 15:24:31 ERROR 22/02/12 15:24:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:24:31 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:24:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.178.30:60283 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO SparkContext: Created broadcast 0 from load at IOHelper.scala:41
2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195847 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO DAGScheduler: Got job 0 (load at IOHelper.scala:41) with 1 output partitions
2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO DAGScheduler: Final stage: ResultStage 0 (load at IOHelper.scala:41)
2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:24:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:24:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022.02.12 15:24:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022.02.12 15:24:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.178.30:60283 (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0))
2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO CodeGenerator: Code generated in 14.953155 ms
2022.02.12 15:24:32 ERROR 22/02/12 15:24:32 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1810 bytes result sent to driver
2022.02.12 15:24:32 ERROR 22/02/12 15:24:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 427 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 15:24:32 ERROR 22/02/12 15:24:33 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022.02.12 15:24:32 ERROR 22/02/12 15:24:33 INFO DAGScheduler: ResultStage 0 (load at IOHelper.scala:41) finished in 0,606 s
2022.02.12 15:24:32 ERROR 22/02/12 15:24:33 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:24:32 ERROR 22/02/12 15:24:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2022.02.12 15:24:32 ERROR 22/02/12 15:24:33 INFO DAGScheduler: Job 0 finished: load at IOHelper.scala:41, took 0,670188 s
2022.02.12 15:24:32 ERROR 22/02/12 15:24:33 INFO CodeGenerator: Code generated in 14.741201 ms
2022.02.12 15:24:32 ERROR 22/02/12 15:24:33 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:24:32 ERROR 22/02/12 15:24:33 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:24:32 ERROR 22/02/12 15:24:33 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:24:32 ERROR 22/02/12 15:24:33 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:24:32 ERROR 22/02/12 15:24:33 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:24:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:24:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.178.30:60283 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO SparkContext: Created broadcast 2 from load at IOHelper.scala:41
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195847 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO DAGScheduler: Got job 1 (load at IOHelper.scala:41) with 3 output partitions
2022.02.12 15:24:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO DAGScheduler: Final stage: ResultStage 1 (load at IOHelper.scala:41)
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.2 KiB, free 2.2 GiB)
2022.02.12 15:24:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
2022.02.12 15:24:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.178.30:60283 (size: 7.6 KiB, free: 2.2 GiB)
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 7791 bytes)
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1600 bytes result sent to driver
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1600 bytes result sent to driver
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1648 bytes result sent to driver
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 145 ms on 192.168.178.30 (executor driver) (1/3)
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 147 ms on 192.168.178.30 (executor driver) (2/3)
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 146 ms on 192.168.178.30 (executor driver) (3/3)
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO DAGScheduler: ResultStage 1 (load at IOHelper.scala:41) finished in 0,213 s
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO DAGScheduler: Job 1 finished: load at IOHelper.scala:41, took 0,220836 s
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO FileSourceStrategy: Output Data Schema: struct<Dies ist ein Scala Project: string,  welches bereits alle Apache-Spark (https://spark.apache.org/) Dependencies und Build-Konfigurationen enthält um eine jar Datei zu bauen: string,  welche auf einem Cluster ausgeführt werden kann.: string ... 1 more fields>
2022.02.12 15:24:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO CodeGenerator: Code generated in 19.405307 ms
2022.02.12 15:24:33 ERROR 22/02/12 15:24:33 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 15:24:33 ERROR 22/02/12 15:24:34 INFO CodeGenerator: Code generated in 31.325559 ms
2022.02.12 15:24:33 ERROR 22/02/12 15:24:34 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 15:24:33 ERROR 22/02/12 15:24:34 INFO CodeGenerator: Code generated in 30.51501 ms
2022.02.12 15:24:33 ERROR 22/02/12 15:24:34 INFO CodeGenerator: Code generated in 48.569389 ms
2022.02.12 15:24:33 ERROR 22/02/12 15:24:34 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:24:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:33 ERROR 22/02/12 15:24:34 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:24:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:33 ERROR 22/02/12 15:24:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.178.30:60283 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:24:33 ERROR 22/02/12 15:24:34 INFO SparkContext: Created broadcast 4 from collect at Exercise_3a.scala:19
2022.02.12 15:24:33 ERROR 22/02/12 15:24:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO CodeGenerator: Code generated in 13.639733 ms
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO SparkContext: Starting job: collect at Exercise_3a.scala:19
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO DAGScheduler: Registering RDD 17 (collect at Exercise_3a.scala:19) as input to shuffle 0
2022.02.12 15:24:34 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO DAGScheduler: Got job 2 (collect at Exercise_3a.scala:19) with 8 output partitions
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO DAGScheduler: Final stage: ResultStage 3 (collect at Exercise_3a.scala:19)
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
2022.02.12 15:24:34 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at collect at Exercise_3a.scala:19), which has no missing parents
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 41.2 KiB, free 2.2 GiB)
2022.02.12 15:24:34 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 2.2 GiB)
2022.02.12 15:24:34 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.178.30:60283 (size: 16.4 KiB, free: 2.2 GiB)
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at collect at Exercise_3a.scala:19) (first 15 tasks are for partitions Vector(0, 1))
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7748 bytes)
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7748 bytes)
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO CodeGenerator: Code generated in 12.066701 ms
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:
2022.02.12 15:24:34 ERROR  Header length: 1, schema size: 3
2022.02.12 15:24:34 ERROR CSV file: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 WARN BlockManager: Putting block rdd_13_0 failed due to exception java.lang.NullPointerException: Value at index 2 is null.
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 WARN BlockManager: Putting block rdd_13_1 failed due to exception java.lang.NullPointerException: Value at index 2 is null.
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 WARN BlockManager: Block rdd_13_1 could not be removed as it was not found on disk or in memory
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 WARN BlockManager: Block rdd_13_0 could not be removed as it was not found on disk or in memory
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 4)
2022.02.12 15:24:34 ERROR java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:24:34 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:24:34 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:24:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:24:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:24:34 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 ERROR Executor: Exception in task 1.0 in stage 2.0 (TID 5)
2022.02.12 15:24:34 ERROR java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:24:34 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:24:34 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:24:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:24:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:24:34 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 WARN TaskSetManager: Lost task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:24:34 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:24:34 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:24:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:24:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:24:34 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:24:34 ERROR 
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 ERROR TaskSetManager: Task 0 in stage 2.0 failed 1 times; aborting job
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO TaskSetManager: Lost task 1.0 in stage 2.0 (TID 5) on 192.168.178.30, executor driver: java.lang.NullPointerException (Value at index 2 is null) [duplicate 1]
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO TaskSchedulerImpl: Cancelling stage 2
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage cancelled
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO DAGScheduler: ShuffleMapStage 2 (collect at Exercise_3a.scala:19) failed in 0,223 s due to Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:24:34 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:24:34 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:24:34 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:24:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:24:34 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:24:34 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:24:34 ERROR 
2022.02.12 15:24:34 ERROR Driver stacktrace:
2022.02.12 15:24:34 ERROR 22/02/12 15:24:34 INFO DAGScheduler: Job 2 failed: collect at Exercise_3a.scala:19, took 0,254008 s
2022.02.12 15:25:20 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 41h 38m 53.63s)
2022.02.12 15:25:20 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 15:25:20 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 15:25:20 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:25:25 INFO  Trying to attach to remote debuggee VM localhost:60313 .
2022.02.12 15:25:25 INFO  Attaching to debuggee VM succeeded.
2022.02.12 15:25:26 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 15:25:26 ERROR 22/02/12 15:25:26 WARN Utils: Your hostname, SchulzeTastPro-2.local resolves to a loopback address: 127.0.0.1; using 192.168.178.30 instead (on interface en0)
2022.02.12 15:25:26 ERROR 22/02/12 15:25:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2022.02.12 15:25:26 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 15:25:26 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 15:25:26 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 15:25:26 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 15:25:26 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 15:25:26 ERROR 22/02/12 15:25:26 INFO SparkContext: Running Spark version 3.0.0
2022.02.12 15:25:26 ERROR 22/02/12 15:25:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022.02.12 15:25:26 ERROR 22/02/12 15:25:27 INFO ResourceUtils: ==============================================================
2022.02.12 15:25:26 ERROR 22/02/12 15:25:27 INFO ResourceUtils: Resources for spark.driver:
2022.02.12 15:25:26 ERROR 
2022.02.12 15:25:26 ERROR 22/02/12 15:25:27 INFO ResourceUtils: ==============================================================
2022.02.12 15:25:26 ERROR 22/02/12 15:25:27 INFO SparkContext: Submitted application: SparkTutorial
2022.02.12 15:25:26 ERROR 22/02/12 15:25:27 INFO SecurityManager: Changing view acls to: Johann
2022.02.12 15:25:26 ERROR 22/02/12 15:25:27 INFO SecurityManager: Changing modify acls to: Johann
2022.02.12 15:25:26 ERROR 22/02/12 15:25:27 INFO SecurityManager: Changing view acls groups to: 
2022.02.12 15:25:26 ERROR 22/02/12 15:25:27 INFO SecurityManager: Changing modify acls groups to: 
2022.02.12 15:25:26 ERROR 22/02/12 15:25:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Johann); groups with view permissions: Set(); users  with modify permissions: Set(Johann); groups with modify permissions: Set()
2022.02.12 15:25:27 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:27 ERROR 22/02/12 15:25:27 INFO Utils: Successfully started service 'sparkDriver' on port 60315.
2022.02.12 15:25:27 ERROR 22/02/12 15:25:27 INFO SparkEnv: Registering MapOutputTracker
2022.02.12 15:25:27 ERROR 22/02/12 15:25:27 INFO SparkEnv: Registering BlockManagerMaster
2022.02.12 15:25:27 ERROR 22/02/12 15:25:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022.02.12 15:25:27 ERROR 22/02/12 15:25:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022.02.12 15:25:27 ERROR 22/02/12 15:25:27 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2022.02.12 15:25:27 ERROR 22/02/12 15:25:27 INFO DiskBlockManager: Created local directory at /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/blockmgr-918b71c6-cda6-4e20-9bd1-0a0bb500cec9
2022.02.12 15:25:27 ERROR 22/02/12 15:25:28 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
2022.02.12 15:25:27 ERROR 22/02/12 15:25:28 INFO SparkEnv: Registering OutputCommitCoordinator
2022.02.12 15:25:27 ERROR 22/02/12 15:25:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
2022.02.12 15:25:27 ERROR 22/02/12 15:25:28 INFO Utils: Successfully started service 'SparkUI' on port 4041.
2022.02.12 15:25:27 ERROR 22/02/12 15:25:28 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.178.30:4041
2022.02.12 15:25:27 ERROR 22/02/12 15:25:28 INFO Executor: Starting executor ID driver on host 192.168.178.30
2022.02.12 15:25:27 ERROR 22/02/12 15:25:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60316.
2022.02.12 15:25:27 ERROR 22/02/12 15:25:28 INFO NettyBlockTransferService: Server created on 192.168.178.30:60316
2022.02.12 15:25:27 ERROR 22/02/12 15:25:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022.02.12 15:25:27 ERROR 22/02/12 15:25:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.178.30, 60316, None)
2022.02.12 15:25:28 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:27 ERROR 22/02/12 15:25:28 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.178.30:60316 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.178.30, 60316, None)
2022.02.12 15:25:27 ERROR 22/02/12 15:25:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.178.30, 60316, None)
2022.02.12 15:25:28 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:28 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:27 ERROR 22/02/12 15:25:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.178.30, 60316, None)
2022.02.12 15:25:29 ERROR 22/02/12 15:25:29 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse').
2022.02.12 15:25:29 ERROR 22/02/12 15:25:29 INFO SharedState: Warehouse path is 'file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse'.
2022.02.12 15:25:30 ERROR 22/02/12 15:25:30 INFO InMemoryFileIndex: It took 233 ms to list leaf files for 1 paths.
2022.02.12 15:25:30 ERROR 22/02/12 15:25:31 INFO InMemoryFileIndex: It took 92 ms to list leaf files for 3 paths.
2022.02.12 15:25:34 ERROR 22/02/12 15:25:34 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:25:34 ERROR 22/02/12 15:25:34 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:25:34 ERROR 22/02/12 15:25:34 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2022.02.12 15:25:34 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:34 ERROR 22/02/12 15:25:34 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:25:35 ERROR 22/02/12 15:25:35 INFO CodeGenerator: Code generated in 367.104533 ms
2022.02.12 15:25:35 ERROR 22/02/12 15:25:35 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:25:35 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:35 ERROR 22/02/12 15:25:35 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:25:35 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:35 ERROR 22/02/12 15:25:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.178.30:60316 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:25:35 ERROR 22/02/12 15:25:35 INFO SparkContext: Created broadcast 0 from load at IOHelper.scala:41
2022.02.12 15:25:35 ERROR 22/02/12 15:25:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195847 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:25:35 ERROR 22/02/12 15:25:35 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:25:35 ERROR 22/02/12 15:25:35 INFO DAGScheduler: Got job 0 (load at IOHelper.scala:41) with 1 output partitions
2022.02.12 15:25:35 ERROR 22/02/12 15:25:35 INFO DAGScheduler: Final stage: ResultStage 0 (load at IOHelper.scala:41)
2022.02.12 15:25:35 ERROR 22/02/12 15:25:35 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:25:35 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:35 ERROR 22/02/12 15:25:35 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:25:35 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:35 ERROR 22/02/12 15:25:35 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:25:35 ERROR 22/02/12 15:25:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022.02.12 15:25:35 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:35 ERROR 22/02/12 15:25:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022.02.12 15:25:35 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:35 ERROR 22/02/12 15:25:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.178.30:60316 (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 15:25:35 ERROR 22/02/12 15:25:36 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:25:35 ERROR 22/02/12 15:25:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0))
2022.02.12 15:25:35 ERROR 22/02/12 15:25:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
2022.02.12 15:25:35 ERROR 22/02/12 15:25:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:25:35 ERROR 22/02/12 15:25:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO CodeGenerator: Code generated in 15.886546 ms
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1810 bytes result sent to driver
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 451 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO DAGScheduler: ResultStage 0 (load at IOHelper.scala:41) finished in 0,632 s
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO DAGScheduler: Job 0 finished: load at IOHelper.scala:41, took 0,698100 s
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO CodeGenerator: Code generated in 13.643485 ms
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:25:36 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:25:36 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.178.30:60316 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO SparkContext: Created broadcast 2 from load at IOHelper.scala:41
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195847 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO DAGScheduler: Got job 1 (load at IOHelper.scala:41) with 3 output partitions
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO DAGScheduler: Final stage: ResultStage 1 (load at IOHelper.scala:41)
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:25:36 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:25:36 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.2 KiB, free 2.2 GiB)
2022.02.12 15:25:36 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
2022.02.12 15:25:36 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.178.30:60316 (size: 7.6 KiB, free: 2.2 GiB)
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 7791 bytes)
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
2022.02.12 15:25:36 ERROR 22/02/12 15:25:36 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1600 bytes result sent to driver
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1600 bytes result sent to driver
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1648 bytes result sent to driver
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 146 ms on 192.168.178.30 (executor driver) (1/3)
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 149 ms on 192.168.178.30 (executor driver) (2/3)
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 149 ms on 192.168.178.30 (executor driver) (3/3)
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO DAGScheduler: ResultStage 1 (load at IOHelper.scala:41) finished in 0,212 s
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO DAGScheduler: Job 1 finished: load at IOHelper.scala:41, took 0,221264 s
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:25:36 ERROR 22/02/12 15:25:37 INFO FileSourceStrategy: Output Data Schema: struct<Dies ist ein Scala Project: string,  welches bereits alle Apache-Spark (https://spark.apache.org/) Dependencies und Build-Konfigurationen enthält um eine jar Datei zu bauen: string,  welche auf einem Cluster ausgeführt werden kann.: string ... 1 more fields>
2022.02.12 15:25:36 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:25:43 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:25:43 INFO  Closing debug server tcp://0.0.0.0:60273
2022.02.12 15:25:43 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:25:43 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:25:43 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:25:43 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:25:43 ERROR Read data from io exception: java.net.SocketException: Socket closed
2022.02.12 15:25:43 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:25:43 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:25:43 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:25:43 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:25:43 ERROR 
2022.02.12 15:25:43 ERROR Driver stacktrace:
2022.02.12 15:25:43 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2023)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1972)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1971)
2022.02.12 15:25:43 ERROR 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
2022.02.12 15:25:43 ERROR 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
2022.02.12 15:25:43 ERROR 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1971)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:950)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:950)
2022.02.12 15:25:43 ERROR 	at scala.Option.foreach(Option.scala:407)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:950)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2203)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2152)
2022.02.12 15:25:43 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2141)
2022.02.12 15:25:57 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:25:57 INFO  Closing debug server tcp://0.0.0.0:60300
2022.02.12 15:26:21 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:26:22 INFO  time: compiled spark-tutorial in 1.15s
2022.02.12 15:26:23 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:26:25 INFO  time: compiled spark-tutorial in 1.43s
2022.02.12 15:26:25 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:26:25 INFO  time: compiled spark-tutorial in 0.23s
2022.02.12 15:26:26 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 15:26:26 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 15:26:27 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:26:28 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 15:26:28 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 15:26:29 INFO  time: compiled spark-tutorial in 2.14s
2022.02.12 15:27:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:27:02 INFO  time: compiled spark-tutorial in 0.17s
2022.02.12 15:27:03 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:27:03 INFO  time: compiled spark-tutorial in 0.18s
2022.02.12 15:27:08 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:27:08 INFO  time: compiled spark-tutorial in 0.17s
2022.02.12 15:27:10 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:27:10 INFO  time: compiled spark-tutorial in 0.15s
2022.02.12 15:27:13 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:27:13 INFO  time: compiled spark-tutorial in 0.14s
2022.02.12 15:27:16 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:27:16 INFO  time: compiled spark-tutorial in 0.17s
2022.02.12 15:27:20 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:27:20 INFO  time: compiled spark-tutorial in 0.15s
2022.02.12 15:27:23 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:27:23 INFO  time: compiled spark-tutorial in 0.24s
Feb. 12, 2022 3:27:24 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2688
2022.02.12 15:27:56 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:27:56 INFO  time: compiled spark-tutorial in 0.14s
2022.02.12 15:28:03 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:28:03 INFO  time: compiled spark-tutorial in 0.17s
2022.02.12 15:28:06 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:28:07 INFO  time: compiled spark-tutorial in 1.17s
2022.02.12 15:28:13 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:28:13 INFO  time: compiled spark-tutorial in 0.17s
2022.02.12 15:28:15 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:28:15 INFO  time: compiled spark-tutorial in 0.14s
2022.02.12 15:28:17 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:28:17 INFO  time: compiled spark-tutorial in 0.14s
2022.02.12 15:28:20 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:28:20 INFO  time: compiled spark-tutorial in 0.18s
2022.02.12 15:28:46 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:28:46 INFO  time: compiled spark-tutorial in 0.18s
2022.02.12 15:28:52 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3a.scala:19:5: stale bloop error: type mismatch;
 found   : Unit
 required: String
    println(_)
    ^^^^^^^^^^
2022.02.12 15:28:52 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3a.scala:19:5: stale bloop error: type mismatch;
 found   : Unit
 required: String
    println(_)
    ^^^^^^^^^^
2022.02.12 15:28:55 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:28:55 INFO  time: compiled spark-tutorial in 0.14s
2022.02.12 15:29:00 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:29:00 INFO  time: compiled spark-tutorial in 0.17s
2022.02.12 15:29:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:29:02 INFO  time: compiled spark-tutorial in 0.14s
2022.02.12 15:29:13 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:29:13 INFO  time: compiled spark-tutorial in 0.13s
2022.02.12 15:29:15 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:29:15 INFO  time: compiled spark-tutorial in 0.15s
2022.02.12 15:29:36 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:29:36 INFO  time: compiled spark-tutorial in 0.14s
2022.02.12 15:38:06 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:38:06 INFO  time: compiled spark-tutorial in 0.26s
2022.02.12 15:38:08 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:38:09 INFO  time: compiled spark-tutorial in 1.61s
2022.02.12 15:38:29 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:38:29 INFO  time: compiled spark-tutorial in 0.17s
2022.02.12 15:38:56 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:38:56 INFO  time: compiled spark-tutorial in 0.27s
2022.02.12 15:39:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:39:02 INFO  time: compiled spark-tutorial in 0.12s
2022.02.12 15:39:05 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:39:05 INFO  time: compiled spark-tutorial in 0.14s
2022.02.12 15:39:09 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:39:09 INFO  time: compiled spark-tutorial in 0.28s
2022.02.12 15:39:11 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:39:11 INFO  time: compiled spark-tutorial in 0.18s
2022.02.12 15:39:14 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:39:14 INFO  time: compiled spark-tutorial in 0.19s
2022.02.12 15:39:17 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:39:17 INFO  time: compiled spark-tutorial in 0.12s
2022.02.12 15:39:20 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:39:22 INFO  time: compiled spark-tutorial in 1.51s
2022.02.12 15:39:26 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:39:28 INFO  time: compiled spark-tutorial in 1.61s
2022.02.12 15:39:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:39:37 INFO  time: compiled spark-tutorial in 0.14s
2022.02.12 15:39:39 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:39:39 INFO  time: compiled spark-tutorial in 0.21s
2022.02.12 15:39:44 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:39:45 INFO  time: compiled spark-tutorial in 1.49s
2022.02.12 15:40:11 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:40:13 INFO  time: compiled spark-tutorial in 1.38s
2022.02.12 15:40:15 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3a.scala
2022.02.12 15:40:16 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:40:17 INFO  time: compiled spark-tutorial in 1.82s
2022.02.12 15:40:19 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:40:21 INFO  time: compiled spark-tutorial in 1.34s
2022.02.12 15:40:22 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:40:24 INFO  time: compiled spark-tutorial in 1.99s
2022.02.12 15:40:25 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:40:26 INFO  time: compiled spark-tutorial in 1.4s
2022.02.12 15:40:48 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:40:48 INFO  time: compiled spark-tutorial in 0.18s
2022.02.12 15:40:51 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:40:52 INFO  time: compiled spark-tutorial in 1.41s
2022.02.12 15:46:57 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:46:57 INFO  time: compiled spark-tutorial in 0.36s
2022.02.12 15:47:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:47:02 INFO  time: compiled spark-tutorial in 0.66s
2022.02.12 15:47:05 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:47:05 INFO  time: compiled spark-tutorial in 0.29s
2022.02.12 15:47:07 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:47:07 INFO  time: compiled spark-tutorial in 0.29s
2022.02.12 15:47:08 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:47:10 INFO  time: compiled spark-tutorial in 1.53s
2022.02.12 15:47:16 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:47:17 INFO  time: compiled spark-tutorial in 1.14s
2022.02.12 15:47:22 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:47:24 INFO  time: compiled spark-tutorial in 1.91s
2022.02.12 15:47:41 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 15:47:41 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 15:47:42 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:47:43 INFO  time: compiled spark-tutorial in 1.24s
2022.02.12 15:47:45 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:47:45 INFO  time: compiled spark-tutorial in 0.52s
2022.02.12 15:47:47 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:47:47 INFO  time: compiled spark-tutorial in 0.16s
2022.02.12 15:47:49 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:47:50 INFO  time: compiled spark-tutorial in 1.48s
2022.02.12 15:47:57 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 1m 31.061s)
2022.02.12 15:47:57 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 15:47:57 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 15:47:58 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:48:05 INFO  Trying to attach to remote debuggee VM localhost:60959 .
2022.02.12 15:48:05 INFO  Attaching to debuggee VM succeeded.
2022.02.12 15:48:06 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 15:48:06 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 15:48:06 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 15:48:06 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 15:48:06 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 15:48:06 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 15:48:06 ERROR 22/02/12 15:48:07 INFO SparkContext: Running Spark version 3.0.0
2022.02.12 15:48:06 ERROR 22/02/12 15:48:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022.02.12 15:48:07 ERROR 22/02/12 15:48:07 INFO ResourceUtils: ==============================================================
2022.02.12 15:48:07 ERROR 22/02/12 15:48:07 INFO ResourceUtils: Resources for spark.driver:
2022.02.12 15:48:07 ERROR 
2022.02.12 15:48:07 ERROR 22/02/12 15:48:07 INFO ResourceUtils: ==============================================================
2022.02.12 15:48:07 ERROR 22/02/12 15:48:07 INFO SparkContext: Submitted application: SparkTutorial
2022.02.12 15:48:07 ERROR 22/02/12 15:48:07 INFO SecurityManager: Changing view acls to: Johann
2022.02.12 15:48:07 ERROR 22/02/12 15:48:07 INFO SecurityManager: Changing modify acls to: Johann
2022.02.12 15:48:07 ERROR 22/02/12 15:48:07 INFO SecurityManager: Changing view acls groups to: 
2022.02.12 15:48:07 ERROR 22/02/12 15:48:07 INFO SecurityManager: Changing modify acls groups to: 
2022.02.12 15:48:07 ERROR 22/02/12 15:48:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Johann); groups with view permissions: Set(); users  with modify permissions: Set(Johann); groups with modify permissions: Set()
2022.02.12 15:48:07 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:07 ERROR 22/02/12 15:48:08 INFO Utils: Successfully started service 'sparkDriver' on port 60963.
2022.02.12 15:48:07 ERROR 22/02/12 15:48:08 INFO SparkEnv: Registering MapOutputTracker
2022.02.12 15:48:07 ERROR 22/02/12 15:48:08 INFO SparkEnv: Registering BlockManagerMaster
2022.02.12 15:48:07 ERROR 22/02/12 15:48:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022.02.12 15:48:07 ERROR 22/02/12 15:48:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022.02.12 15:48:07 ERROR 22/02/12 15:48:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2022.02.12 15:48:07 ERROR 22/02/12 15:48:08 INFO DiskBlockManager: Created local directory at /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/blockmgr-f0f98314-4b3d-4182-8938-2d62c36f5047
2022.02.12 15:48:08 ERROR 22/02/12 15:48:08 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
2022.02.12 15:48:08 ERROR 22/02/12 15:48:08 INFO SparkEnv: Registering OutputCommitCoordinator
2022.02.12 15:48:08 ERROR 22/02/12 15:48:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2022.02.12 15:48:09 ERROR 22/02/12 15:48:09 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.178.30:4040
2022.02.12 15:48:09 ERROR 22/02/12 15:48:10 INFO Executor: Starting executor ID driver on host 192.168.178.30
2022.02.12 15:48:09 ERROR 22/02/12 15:48:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60964.
2022.02.12 15:48:09 ERROR 22/02/12 15:48:10 INFO NettyBlockTransferService: Server created on 192.168.178.30:60964
2022.02.12 15:48:09 ERROR 22/02/12 15:48:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022.02.12 15:48:09 ERROR 22/02/12 15:48:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.178.30, 60964, None)
2022.02.12 15:48:10 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:09 ERROR 22/02/12 15:48:10 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.178.30:60964 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.178.30, 60964, None)
2022.02.12 15:48:09 ERROR 22/02/12 15:48:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.178.30, 60964, None)
2022.02.12 15:48:10 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:09 ERROR 22/02/12 15:48:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.178.30, 60964, None)
2022.02.12 15:48:10 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:11 ERROR 22/02/12 15:48:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse').
2022.02.12 15:48:11 ERROR 22/02/12 15:48:11 INFO SharedState: Warehouse path is 'file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse'.
2022.02.12 15:48:12 ERROR 22/02/12 15:48:12 INFO InMemoryFileIndex: It took 303 ms to list leaf files for 1 paths.
2022.02.12 15:48:12 ERROR 22/02/12 15:48:13 INFO InMemoryFileIndex: It took 88 ms to list leaf files for 3 paths.
2022.02.12 15:48:16 ERROR 22/02/12 15:48:16 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:48:16 ERROR 22/02/12 15:48:16 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:48:16 ERROR 22/02/12 15:48:16 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2022.02.12 15:48:16 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:16 ERROR 22/02/12 15:48:16 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO CodeGenerator: Code generated in 296.540071 ms
2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:48:17 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:48:17 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.178.30:60964 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO SparkContext: Created broadcast 0 from load at IOHelper.scala:41
2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195847 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO DAGScheduler: Got job 0 (load at IOHelper.scala:41) with 1 output partitions
2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO DAGScheduler: Final stage: ResultStage 0 (load at IOHelper.scala:41)
2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:48:17 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:48:17 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022.02.12 15:48:17 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022.02.12 15:48:17 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.178.30:60964 (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0))
2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:48:17 ERROR 22/02/12 15:48:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO CodeGenerator: Code generated in 18.859609 ms
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1767 bytes result sent to driver
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 454 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO DAGScheduler: ResultStage 0 (load at IOHelper.scala:41) finished in 0,646 s
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO DAGScheduler: Job 0 finished: load at IOHelper.scala:41, took 0,719312 s
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO CodeGenerator: Code generated in 19.027898 ms
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:48:18 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:48:18 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.178.30:60964 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO SparkContext: Created broadcast 2 from load at IOHelper.scala:41
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195847 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO DAGScheduler: Got job 1 (load at IOHelper.scala:41) with 3 output partitions
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO DAGScheduler: Final stage: ResultStage 1 (load at IOHelper.scala:41)
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:48:18 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:48:18 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.2 KiB, free 2.2 GiB)
2022.02.12 15:48:18 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
2022.02.12 15:48:18 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.178.30:60964 (size: 7.6 KiB, free: 2.2 GiB)
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 7791 bytes)
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1648 bytes result sent to driver
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1600 bytes result sent to driver
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1600 bytes result sent to driver
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 159 ms on 192.168.178.30 (executor driver) (1/3)
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 173 ms on 192.168.178.30 (executor driver) (2/3)
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 173 ms on 192.168.178.30 (executor driver) (3/3)
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO DAGScheduler: ResultStage 1 (load at IOHelper.scala:41) finished in 0,235 s
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2022.02.12 15:48:18 ERROR 22/02/12 15:48:18 INFO DAGScheduler: Job 1 finished: load at IOHelper.scala:41, took 0,243986 s
2022.02.12 15:48:18 ERROR 22/02/12 15:48:19 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:48:18 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:18 ERROR 22/02/12 15:48:19 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:48:18 ERROR 22/02/12 15:48:19 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:48:18 ERROR 22/02/12 15:48:19 INFO FileSourceStrategy: Output Data Schema: struct<Dies ist ein Scala Project: string,  welches bereits alle Apache-Spark (https://spark.apache.org/) Dependencies und Build-Konfigurationen enthält um eine jar Datei zu bauen: string,  welche auf einem Cluster ausgeführt werden kann.: string ... 1 more fields>
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO CodeGenerator: Code generated in 20.346243 ms
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO CodeGenerator: Code generated in 27.500125 ms
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO CodeGenerator: Code generated in 26.986804 ms
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO CodeGenerator: Code generated in 38.36038 ms
2022.02.12 15:48:18 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:48:19 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.178.30:60964 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO SparkContext: Created broadcast 4 from collect at Exercise_3a.scala:22
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO CodeGenerator: Code generated in 11.265679 ms
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO SparkContext: Starting job: collect at Exercise_3a.scala:22
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO DAGScheduler: Registering RDD 17 (collect at Exercise_3a.scala:22) as input to shuffle 0
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO DAGScheduler: Got job 2 (collect at Exercise_3a.scala:22) with 8 output partitions
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO DAGScheduler: Final stage: ResultStage 3 (collect at Exercise_3a.scala:22)
2022.02.12 15:48:19 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
2022.02.12 15:48:19 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at collect at Exercise_3a.scala:22), which has no missing parents
2022.02.12 15:48:19 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 41.2 KiB, free 2.2 GiB)
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 16.4 KiB, free 2.2 GiB)
2022.02.12 15:48:19 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.178.30:60964 (size: 16.4 KiB, free: 2.2 GiB)
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at collect at Exercise_3a.scala:22) (first 15 tasks are for partitions Vector(0, 1))
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7748 bytes)
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7748 bytes)
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO CodeGenerator: Code generated in 8.848291 ms
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:
2022.02.12 15:48:19 ERROR  Header length: 1, schema size: 3
2022.02.12 15:48:19 ERROR CSV file: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 WARN BlockManager: Putting block rdd_13_1 failed due to exception java.lang.NullPointerException: Value at index 2 is null.
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 WARN BlockManager: Putting block rdd_13_0 failed due to exception java.lang.NullPointerException: Value at index 2 is null.
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 WARN BlockManager: Block rdd_13_0 could not be removed as it was not found on disk or in memory
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 WARN BlockManager: Block rdd_13_1 could not be removed as it was not found on disk or in memory
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 4)
2022.02.12 15:48:19 ERROR java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:48:19 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:48:19 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:48:19 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:48:19 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:48:19 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 ERROR Executor: Exception in task 1.0 in stage 2.0 (TID 5)
2022.02.12 15:48:19 ERROR java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:48:19 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:48:19 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:48:19 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:48:19 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:48:19 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 WARN TaskSetManager: Lost task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:48:19 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:48:19 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:48:19 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:48:19 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:48:19 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:48:19 ERROR 
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 ERROR TaskSetManager: Task 0 in stage 2.0 failed 1 times; aborting job
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO TaskSetManager: Lost task 1.0 in stage 2.0 (TID 5) on 192.168.178.30, executor driver: java.lang.NullPointerException (Value at index 2 is null) [duplicate 1]
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO TaskSchedulerImpl: Cancelling stage 2
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage cancelled
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO DAGScheduler: ShuffleMapStage 2 (collect at Exercise_3a.scala:22) failed in 0,245 s due to Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:48:19 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:48:19 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:48:19 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:48:19 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:48:19 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:48:19 ERROR 
2022.02.12 15:48:19 ERROR Driver stacktrace:
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO DAGScheduler: Job 2 failed: collect at Exercise_3a.scala:22, took 0,282211 s
2022.02.12 15:48:19 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:48:19 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:48:19 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:48:19 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:48:19 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:48:19 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:48:19 ERROR 
2022.02.12 15:48:19 ERROR Driver stacktrace:
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2023)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1972)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1971)
2022.02.12 15:48:19 ERROR 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
2022.02.12 15:48:19 ERROR 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
2022.02.12 15:48:19 ERROR 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1971)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:950)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:950)
2022.02.12 15:48:19 ERROR 	at scala.Option.foreach(Option.scala:407)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:950)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2203)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2152)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2141)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2133)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:388)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.collect(RDD.scala:1003)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:304)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.prepareShuffleDependency(ShuffleExchangeExec.scala:199)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.shuffleDependency$lzycompute(ShuffleExchangeExec.scala:87)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.shuffleDependency(ShuffleExchangeExec.scala:81)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.$anonfun$doExecute$1(ShuffleExchangeExec.scala:98)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:95)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:525)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:453)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:452)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:496)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:132)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:720)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:316)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:382)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3625)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:2938)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3616)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3614)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Dataset.collect(Dataset.scala:2938)
2022.02.12 15:48:19 ERROR 	at de.hpi.dbsII_exercises.Exercise_3a.execute(Exercise_3a.scala:22)
2022.02.12 15:48:19 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:25)
2022.02.12 15:48:19 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:5)
2022.02.12 15:48:19 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.12 15:48:19 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.12 15:48:19 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.12 15:48:19 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.12 15:48:19 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.12 15:48:19 ERROR 	at scala.App.main(App.scala:80)
2022.02.12 15:48:19 ERROR 	at scala.App.main$(App.scala:78)
2022.02.12 15:48:19 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:5)
2022.02.12 15:48:19 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.12 15:48:19 ERROR Caused by: java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:48:19 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:48:19 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:48:19 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:48:19 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:48:19 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:48:19 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO SparkContext: Invoking stop() from shutdown hook
2022.02.12 15:48:19 ERROR 22/02/12 15:48:19 INFO SparkUI: Stopped Spark web UI at http://192.168.178.30:4040
2022.02.12 15:48:19 ERROR 22/02/12 15:48:20 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2022.02.12 15:48:19 ERROR 22/02/12 15:48:20 INFO MemoryStore: MemoryStore cleared
2022.02.12 15:48:19 ERROR 22/02/12 15:48:20 INFO BlockManager: BlockManager stopped
2022.02.12 15:48:19 ERROR 22/02/12 15:48:20 INFO BlockManagerMaster: BlockManagerMaster stopped
2022.02.12 15:48:19 ERROR 22/02/12 15:48:20 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2022.02.12 15:48:19 ERROR 22/02/12 15:48:20 INFO SparkContext: Successfully stopped SparkContext
2022.02.12 15:48:19 ERROR 22/02/12 15:48:20 INFO ShutdownHookManager: Shutdown hook called
2022.02.12 15:48:19 ERROR 22/02/12 15:48:20 INFO ShutdownHookManager: Deleting directory /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/spark-7e036f48-22a8-48d3-8609-c2d7c9525a24
2022.02.12 15:48:20 INFO  Closing debug server tcp://0.0.0.0:60952
Feb. 12, 2022 3:48:27 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireError
SEVERE: java.net.SocketException: Broken pipe (Write failed)
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.net.SocketException: Broken pipe (Write failed)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.debug.SocketEndpoint.consume(SocketEndpoint.scala:22)
	at scala.meta.internal.metals.debug.MessageIdAdapter.consume(MessageIdAdapter.scala:43)
	at scala.meta.internal.metals.debug.ServerAdapter.send(ServerAdapter.scala:30)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleClientMessage$1(DebugProxy.scala:138)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToClient$1(DebugProxy.scala:63)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.base/java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)
	at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:69)
	... 21 more

2022.02.12 15:48:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

Feb. 12, 2022 3:48:32 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireStreamClosed
INFO: Connection reset
java.net.SocketException: Connection reset
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:79)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)

2022.02.12 15:48:32 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:48:50 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:48:50 INFO  time: compiled spark-tutorial in 0.28s
2022.02.12 15:48:53 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:48:53 INFO  time: compiled spark-tutorial in 0.15s
2022.02.12 15:48:58 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:48:58 INFO  time: compiled spark-tutorial in 0.12s
2022.02.12 15:49:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:49:02 INFO  time: compiled spark-tutorial in 0.22s
2022.02.12 15:49:07 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:49:07 INFO  time: compiled spark-tutorial in 0.28s
2022.02.12 15:49:10 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:49:11 INFO  time: compiled spark-tutorial in 1.16s
2022.02.12 15:49:23 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:49:23 INFO  time: compiled spark-tutorial in 0.11s
2022.02.12 15:49:25 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:49:27 INFO  time: compiled spark-tutorial in 1.57s
2022.02.12 15:49:28 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 15:49:30 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:49:30 INFO  time: compiled spark-tutorial in 0.18s
2022.02.12 15:49:30 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:49:30 INFO  time: compiled spark-tutorial in 0.22s
2022.02.12 15:49:41 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 15:49:41 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 15:49:43 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 15:49:43 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 15:49:44 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:49:45 INFO  time: compiled spark-tutorial in 1.11s
2022.02.12 15:49:47 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:49:48 INFO  time: compiled spark-tutorial in 1.36s
2022.02.12 15:49:53 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 3m 26.339s)
2022.02.12 15:49:53 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 15:49:54 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 15:49:54 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:49:59 INFO  Trying to attach to remote debuggee VM localhost:61056 .
2022.02.12 15:49:59 INFO  Attaching to debuggee VM succeeded.
2022.02.12 15:50:01 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 15:50:01 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 15:50:01 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 15:50:01 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 15:50:01 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 15:50:01 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 15:50:01 ERROR 22/02/12 15:50:02 INFO SparkContext: Running Spark version 3.0.0
2022.02.12 15:50:01 ERROR 22/02/12 15:50:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022.02.12 15:50:02 ERROR 22/02/12 15:50:02 INFO ResourceUtils: ==============================================================
2022.02.12 15:50:02 ERROR 22/02/12 15:50:02 INFO ResourceUtils: Resources for spark.driver:
2022.02.12 15:50:02 ERROR 
2022.02.12 15:50:02 ERROR 22/02/12 15:50:02 INFO ResourceUtils: ==============================================================
2022.02.12 15:50:02 ERROR 22/02/12 15:50:02 INFO SparkContext: Submitted application: SparkTutorial
2022.02.12 15:50:02 ERROR 22/02/12 15:50:02 INFO SecurityManager: Changing view acls to: Johann
2022.02.12 15:50:02 ERROR 22/02/12 15:50:02 INFO SecurityManager: Changing modify acls to: Johann
2022.02.12 15:50:02 ERROR 22/02/12 15:50:02 INFO SecurityManager: Changing view acls groups to: 
2022.02.12 15:50:02 ERROR 22/02/12 15:50:02 INFO SecurityManager: Changing modify acls groups to: 
2022.02.12 15:50:02 ERROR 22/02/12 15:50:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Johann); groups with view permissions: Set(); users  with modify permissions: Set(Johann); groups with modify permissions: Set()
2022.02.12 15:50:02 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:02 ERROR 22/02/12 15:50:03 INFO Utils: Successfully started service 'sparkDriver' on port 61061.
2022.02.12 15:50:02 ERROR 22/02/12 15:50:03 INFO SparkEnv: Registering MapOutputTracker
2022.02.12 15:50:02 ERROR 22/02/12 15:50:03 INFO SparkEnv: Registering BlockManagerMaster
2022.02.12 15:50:02 ERROR 22/02/12 15:50:03 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022.02.12 15:50:02 ERROR 22/02/12 15:50:03 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022.02.12 15:50:02 ERROR 22/02/12 15:50:03 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2022.02.12 15:50:02 ERROR 22/02/12 15:50:03 INFO DiskBlockManager: Created local directory at /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/blockmgr-d036e8b3-a3a6-4281-8b58-f3a110ceaa95
2022.02.12 15:50:02 ERROR 22/02/12 15:50:03 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
2022.02.12 15:50:03 ERROR 22/02/12 15:50:03 INFO SparkEnv: Registering OutputCommitCoordinator
2022.02.12 15:50:03 ERROR 22/02/12 15:50:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2022.02.12 15:50:03 ERROR 22/02/12 15:50:04 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.178.30:4040
2022.02.12 15:50:03 ERROR 22/02/12 15:50:04 INFO Executor: Starting executor ID driver on host 192.168.178.30
2022.02.12 15:50:03 ERROR 22/02/12 15:50:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61062.
2022.02.12 15:50:03 ERROR 22/02/12 15:50:04 INFO NettyBlockTransferService: Server created on 192.168.178.30:61062
2022.02.12 15:50:03 ERROR 22/02/12 15:50:04 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022.02.12 15:50:03 ERROR 22/02/12 15:50:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.178.30, 61062, None)
2022.02.12 15:50:04 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:03 ERROR 22/02/12 15:50:04 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.178.30:61062 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.178.30, 61062, None)
2022.02.12 15:50:03 ERROR 22/02/12 15:50:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.178.30, 61062, None)
2022.02.12 15:50:04 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:03 ERROR 22/02/12 15:50:04 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.178.30, 61062, None)
2022.02.12 15:50:04 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:05 ERROR 22/02/12 15:50:05 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse').
2022.02.12 15:50:05 ERROR 22/02/12 15:50:05 INFO SharedState: Warehouse path is 'file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse'.
2022.02.12 15:50:06 ERROR 22/02/12 15:50:06 INFO InMemoryFileIndex: It took 263 ms to list leaf files for 1 paths.
2022.02.12 15:50:06 ERROR 22/02/12 15:50:07 INFO InMemoryFileIndex: It took 110 ms to list leaf files for 3 paths.
2022.02.12 15:50:09 ERROR 22/02/12 15:50:09 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:50:09 ERROR 22/02/12 15:50:09 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:50:09 ERROR 22/02/12 15:50:09 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2022.02.12 15:50:09 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:09 ERROR 22/02/12 15:50:09 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:50:09 ERROR 22/02/12 15:50:10 INFO CodeGenerator: Code generated in 220.109201 ms
2022.02.12 15:50:09 ERROR 22/02/12 15:50:10 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:50:09 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:50:11 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.178.30:61062 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO SparkContext: Created broadcast 0 from load at IOHelper.scala:41
2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195847 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO DAGScheduler: Got job 0 (load at IOHelper.scala:41) with 1 output partitions
2022.02.12 15:50:11 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO DAGScheduler: Final stage: ResultStage 0 (load at IOHelper.scala:41)
2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:50:11 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022.02.12 15:50:11 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022.02.12 15:50:11 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.178.30:61062 (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0))
2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:50:11 ERROR 22/02/12 15:50:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2022.02.12 15:50:11 ERROR 22/02/12 15:50:12 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:50:11 ERROR 22/02/12 15:50:12 INFO CodeGenerator: Code generated in 15.436075 ms
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1810 bytes result sent to driver
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 515 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO DAGScheduler: ResultStage 0 (load at IOHelper.scala:41) finished in 0,760 s
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO DAGScheduler: Job 0 finished: load at IOHelper.scala:41, took 0,839354 s
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO CodeGenerator: Code generated in 25.047869 ms
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:50:12 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:50:12 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.178.30:61062 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO SparkContext: Created broadcast 2 from load at IOHelper.scala:41
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195847 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO DAGScheduler: Got job 1 (load at IOHelper.scala:41) with 3 output partitions
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO DAGScheduler: Final stage: ResultStage 1 (load at IOHelper.scala:41)
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:50:12 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:12 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.2 KiB, free 2.2 GiB)
2022.02.12 15:50:12 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
2022.02.12 15:50:12 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.178.30:61062 (size: 7.6 KiB, free: 2.2 GiB)
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 7791 bytes)
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1600 bytes result sent to driver
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1600 bytes result sent to driver
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1648 bytes result sent to driver
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 191 ms on 192.168.178.30 (executor driver) (1/3)
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 194 ms on 192.168.178.30 (executor driver) (2/3)
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 196 ms on 192.168.178.30 (executor driver) (3/3)
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO DAGScheduler: ResultStage 1 (load at IOHelper.scala:41) finished in 0,279 s
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2022.02.12 15:50:12 ERROR 22/02/12 15:50:12 INFO DAGScheduler: Job 1 finished: load at IOHelper.scala:41, took 0,288019 s
2022.02.12 15:50:12 ERROR 22/02/12 15:50:13 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:50:12 ERROR 22/02/12 15:50:13 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:50:12 ERROR 22/02/12 15:50:13 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:50:12 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:12 ERROR 22/02/12 15:50:13 INFO FileSourceStrategy: Output Data Schema: struct<Dies ist ein Scala Project: string,  welches bereits alle Apache-Spark (https://spark.apache.org/) Dependencies und Build-Konfigurationen enthält um eine jar Datei zu bauen: string,  welche auf einem Cluster ausgeführt werden kann.: string ... 1 more fields>
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO CodeGenerator: Code generated in 21.803448 ms
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO CodeGenerator: Code generated in 17.817417 ms
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO CodeGenerator: Code generated in 68.107741 ms
2022.02.12 15:50:13 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:50:13 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.178.30:61062 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO SparkContext: Created broadcast 4 from count at DBSIISparkExerciseMain.scala:24
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO SparkContext: Starting job: count at DBSIISparkExerciseMain.scala:24
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO DAGScheduler: Registering RDD 17 (count at DBSIISparkExerciseMain.scala:24) as input to shuffle 0
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO DAGScheduler: Got job 2 (count at DBSIISparkExerciseMain.scala:24) with 1 output partitions
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO DAGScheduler: Final stage: ResultStage 3 (count at DBSIISparkExerciseMain.scala:24)
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
2022.02.12 15:50:13 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
2022.02.12 15:50:13 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at DBSIISparkExerciseMain.scala:24), which has no missing parents
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 36.6 KiB, free 2.2 GiB)
2022.02.12 15:50:13 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 14.4 KiB, free 2.2 GiB)
2022.02.12 15:50:13 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.178.30:61062 (size: 14.4 KiB, free: 2.2 GiB)
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at DBSIISparkExerciseMain.scala:24) (first 15 tasks are for partitions Vector(0, 1))
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7748 bytes)
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7748 bytes)
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:50:13 ERROR 22/02/12 15:50:13 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO CodeGenerator: Code generated in 19.751219 ms
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:
2022.02.12 15:50:13 ERROR  Header length: 1, schema size: 3
2022.02.12 15:50:13 ERROR CSV file: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 WARN BlockManager: Putting block rdd_13_1 failed due to exception java.lang.NullPointerException: Value at index 2 is null.
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 WARN BlockManager: Putting block rdd_13_0 failed due to exception java.lang.NullPointerException: Value at index 2 is null.
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 WARN BlockManager: Block rdd_13_1 could not be removed as it was not found on disk or in memory
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 WARN BlockManager: Block rdd_13_0 could not be removed as it was not found on disk or in memory
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 ERROR Executor: Exception in task 1.0 in stage 2.0 (TID 5)
2022.02.12 15:50:13 ERROR java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:50:13 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:50:13 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:50:13 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:50:13 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:50:13 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 4)
2022.02.12 15:50:13 ERROR java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:50:13 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:50:13 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:50:13 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:50:13 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:50:13 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 WARN TaskSetManager: Lost task 1.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:50:13 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:50:13 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:50:13 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:50:13 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:50:13 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:50:13 ERROR 
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 ERROR TaskSetManager: Task 1 in stage 2.0 failed 1 times; aborting job
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO TaskSetManager: Lost task 0.0 in stage 2.0 (TID 4) on 192.168.178.30, executor driver: java.lang.NullPointerException (Value at index 2 is null) [duplicate 1]
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO TaskSchedulerImpl: Cancelling stage 2
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage cancelled
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO DAGScheduler: ShuffleMapStage 2 (count at DBSIISparkExerciseMain.scala:24) failed in 0,317 s due to Job aborted due to stage failure: Task 1 in stage 2.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:50:13 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:50:13 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:50:13 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:50:13 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:50:13 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:50:13 ERROR 
2022.02.12 15:50:13 ERROR Driver stacktrace:
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO DAGScheduler: Job 2 failed: count at DBSIISparkExerciseMain.scala:24, took 0,353728 s
2022.02.12 15:50:13 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 2.0 failed 1 times, most recent failure: Lost task 1.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:50:13 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:50:13 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:50:13 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:50:13 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:50:13 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:50:13 ERROR 
2022.02.12 15:50:13 ERROR Driver stacktrace:
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2023)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1972)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1971)
2022.02.12 15:50:13 ERROR 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
2022.02.12 15:50:13 ERROR 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
2022.02.12 15:50:13 ERROR 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1971)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:950)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:950)
2022.02.12 15:50:13 ERROR 	at scala.Option.foreach(Option.scala:407)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:950)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2203)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2152)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2141)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2133)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:388)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.collect(RDD.scala:1003)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:385)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$count$1(Dataset.scala:2979)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$count$1$adapted(Dataset.scala:2978)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3616)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3614)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Dataset.count(Dataset.scala:2978)
2022.02.12 15:50:13 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:24)
2022.02.12 15:50:13 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:5)
2022.02.12 15:50:13 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.12 15:50:13 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.12 15:50:13 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.12 15:50:13 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.12 15:50:13 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.12 15:50:13 ERROR 	at scala.App.main(App.scala:80)
2022.02.12 15:50:13 ERROR 	at scala.App.main$(App.scala:78)
2022.02.12 15:50:13 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:5)
2022.02.12 15:50:13 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.12 15:50:13 ERROR Caused by: java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:50:13 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:50:13 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:50:13 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:50:13 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:50:13 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:50:13 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO SparkContext: Invoking stop() from shutdown hook
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO SparkUI: Stopped Spark web UI at http://192.168.178.30:4040
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO MemoryStore: MemoryStore cleared
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO BlockManager: BlockManager stopped
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO BlockManagerMaster: BlockManagerMaster stopped
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO SparkContext: Successfully stopped SparkContext
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO ShutdownHookManager: Shutdown hook called
2022.02.12 15:50:13 ERROR 22/02/12 15:50:14 INFO ShutdownHookManager: Deleting directory /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/spark-c430bad3-5cf3-4218-af59-7e3470856a41
2022.02.12 15:50:14 INFO  Closing debug server tcp://0.0.0.0:61051
2022.02.12 15:50:20 INFO  time: code lens generation in 1.02s
Feb. 12, 2022 3:50:23 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireError
SEVERE: java.net.SocketException: Broken pipe (Write failed)
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.net.SocketException: Broken pipe (Write failed)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.debug.SocketEndpoint.consume(SocketEndpoint.scala:22)
	at scala.meta.internal.metals.debug.MessageIdAdapter.consume(MessageIdAdapter.scala:43)
	at scala.meta.internal.metals.debug.ServerAdapter.send(ServerAdapter.scala:30)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleClientMessage$1(DebugProxy.scala:138)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToClient$1(DebugProxy.scala:63)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.base/java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)
	at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:69)
	... 21 more

2022.02.12 15:50:24 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

Feb. 12, 2022 3:50:24 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireStreamClosed
INFO: Connection reset
java.net.SocketException: Connection reset
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:79)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)

2022.02.12 15:50:24 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:52:31 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 6m 4.908s)
2022.02.12 15:52:31 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 15:52:31 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 15:52:32 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:52:37 INFO  Trying to attach to remote debuggee VM localhost:61115 .
2022.02.12 15:52:37 INFO  Attaching to debuggee VM succeeded.
2022.02.12 15:52:39 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 15:52:39 ERROR 22/02/12 15:52:39 WARN Utils: Your hostname, SchulzeTastPro-2.local resolves to a loopback address: 127.0.0.1; using 192.168.178.30 instead (on interface en0)
2022.02.12 15:52:39 ERROR 22/02/12 15:52:39 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2022.02.12 15:52:39 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 15:52:39 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 15:52:39 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 15:52:39 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 15:52:39 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 15:52:39 ERROR 22/02/12 15:52:39 INFO SparkContext: Running Spark version 3.0.0
2022.02.12 15:52:39 ERROR 22/02/12 15:52:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022.02.12 15:52:39 ERROR 22/02/12 15:52:40 INFO ResourceUtils: ==============================================================
2022.02.12 15:52:39 ERROR 22/02/12 15:52:40 INFO ResourceUtils: Resources for spark.driver:
2022.02.12 15:52:39 ERROR 
2022.02.12 15:52:39 ERROR 22/02/12 15:52:40 INFO ResourceUtils: ==============================================================
2022.02.12 15:52:39 ERROR 22/02/12 15:52:40 INFO SparkContext: Submitted application: SparkTutorial
2022.02.12 15:52:40 ERROR 22/02/12 15:52:40 INFO SecurityManager: Changing view acls to: Johann
2022.02.12 15:52:40 ERROR 22/02/12 15:52:40 INFO SecurityManager: Changing modify acls to: Johann
2022.02.12 15:52:40 ERROR 22/02/12 15:52:40 INFO SecurityManager: Changing view acls groups to: 
2022.02.12 15:52:40 ERROR 22/02/12 15:52:40 INFO SecurityManager: Changing modify acls groups to: 
2022.02.12 15:52:40 ERROR 22/02/12 15:52:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Johann); groups with view permissions: Set(); users  with modify permissions: Set(Johann); groups with modify permissions: Set()
2022.02.12 15:52:40 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:40 ERROR 22/02/12 15:52:40 INFO Utils: Successfully started service 'sparkDriver' on port 61117.
2022.02.12 15:52:40 ERROR 22/02/12 15:52:40 INFO SparkEnv: Registering MapOutputTracker
2022.02.12 15:52:40 ERROR 22/02/12 15:52:40 INFO SparkEnv: Registering BlockManagerMaster
2022.02.12 15:52:40 ERROR 22/02/12 15:52:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022.02.12 15:52:40 ERROR 22/02/12 15:52:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022.02.12 15:52:40 ERROR 22/02/12 15:52:41 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2022.02.12 15:52:40 ERROR 22/02/12 15:52:41 INFO DiskBlockManager: Created local directory at /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/blockmgr-ecb1b0da-fc09-41dc-89c1-0583c695634b
2022.02.12 15:52:40 ERROR 22/02/12 15:52:41 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
2022.02.12 15:52:40 ERROR 22/02/12 15:52:41 INFO SparkEnv: Registering OutputCommitCoordinator
2022.02.12 15:52:41 ERROR 22/02/12 15:52:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2022.02.12 15:52:41 ERROR 22/02/12 15:52:41 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.178.30:4040
2022.02.12 15:52:41 ERROR 22/02/12 15:52:41 INFO Executor: Starting executor ID driver on host 192.168.178.30
2022.02.12 15:52:41 ERROR 22/02/12 15:52:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61118.
2022.02.12 15:52:41 ERROR 22/02/12 15:52:41 INFO NettyBlockTransferService: Server created on 192.168.178.30:61118
2022.02.12 15:52:41 ERROR 22/02/12 15:52:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022.02.12 15:52:41 ERROR 22/02/12 15:52:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.178.30, 61118, None)
2022.02.12 15:52:41 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:41 ERROR 22/02/12 15:52:41 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.178.30:61118 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.178.30, 61118, None)
2022.02.12 15:52:41 ERROR 22/02/12 15:52:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.178.30, 61118, None)
2022.02.12 15:52:41 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:41 ERROR 22/02/12 15:52:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.178.30, 61118, None)
2022.02.12 15:52:41 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:42 ERROR 22/02/12 15:52:42 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse').
2022.02.12 15:52:42 ERROR 22/02/12 15:52:42 INFO SharedState: Warehouse path is 'file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse'.
2022.02.12 15:52:43 ERROR 22/02/12 15:52:43 INFO InMemoryFileIndex: It took 272 ms to list leaf files for 1 paths.
2022.02.12 15:52:43 ERROR 22/02/12 15:52:44 INFO InMemoryFileIndex: It took 97 ms to list leaf files for 3 paths.
2022.02.12 15:52:46 ERROR 22/02/12 15:52:46 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:52:46 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:46 ERROR 22/02/12 15:52:46 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:52:46 ERROR 22/02/12 15:52:46 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2022.02.12 15:52:46 ERROR 22/02/12 15:52:46 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:52:46 ERROR 22/02/12 15:52:47 INFO CodeGenerator: Code generated in 308.420877 ms
2022.02.12 15:52:46 ERROR 22/02/12 15:52:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:52:46 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:52:48 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.178.30:61118 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO SparkContext: Created broadcast 0 from load at IOHelper.scala:41
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195847 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO DAGScheduler: Got job 0 (load at IOHelper.scala:41) with 1 output partitions
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO DAGScheduler: Final stage: ResultStage 0 (load at IOHelper.scala:41)
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:52:48 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:52:48 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022.02.12 15:52:48 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022.02.12 15:52:48 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.178.30:61118 (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0))
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO CodeGenerator: Code generated in 17.656982 ms
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1810 bytes result sent to driver
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 454 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO DAGScheduler: ResultStage 0 (load at IOHelper.scala:41) finished in 0,636 s
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO DAGScheduler: Job 0 finished: load at IOHelper.scala:41, took 0,695192 s
2022.02.12 15:52:48 ERROR 22/02/12 15:52:48 INFO CodeGenerator: Code generated in 20.614429 ms
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:52:49 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:52:49 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.178.30:61118 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO SparkContext: Created broadcast 2 from load at IOHelper.scala:41
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4195847 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO DAGScheduler: Got job 1 (load at IOHelper.scala:41) with 3 output partitions
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO DAGScheduler: Final stage: ResultStage 1 (load at IOHelper.scala:41)
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:52:49 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:49 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.2 KiB, free 2.2 GiB)
2022.02.12 15:52:49 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.6 KiB, free 2.2 GiB)
2022.02.12 15:52:49 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.178.30:61118 (size: 7.6 KiB, free: 2.2 GiB)
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2))
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 3 tasks
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7759 bytes)
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 7791 bytes)
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1600 bytes result sent to driver
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 160 ms on 192.168.178.30 (executor driver) (1/3)
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1648 bytes result sent to driver
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 167 ms on 192.168.178.30 (executor driver) (2/3)
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1600 bytes result sent to driver
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 175 ms on 192.168.178.30 (executor driver) (3/3)
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO DAGScheduler: ResultStage 1 (load at IOHelper.scala:41) finished in 0,234 s
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO DAGScheduler: Job 1 finished: load at IOHelper.scala:41, took 0,242745 s
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:52:49 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:49 ERROR 22/02/12 15:52:49 INFO FileSourceStrategy: Output Data Schema: struct<Dies ist ein Scala Project: string,  welches bereits alle Apache-Spark (https://spark.apache.org/) Dependencies und Build-Konfigurationen enthält um eine jar Datei zu bauen: string,  welche auf einem Cluster ausgeführt werden kann.: string ... 1 more fields>
2022.02.12 15:52:49 ERROR 22/02/12 15:52:50 INFO CodeGenerator: Code generated in 22.751451 ms
2022.02.12 15:52:49 ERROR 22/02/12 15:52:50 INFO CodeGenerator: Code generated in 16.488631 ms
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO CodeGenerator: Code generated in 58.017519 ms
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:52:50 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:52:50 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.178.30:61118 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO SparkContext: Created broadcast 4 from count at DBSIISparkExerciseMain.scala:24
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO SparkContext: Starting job: count at DBSIISparkExerciseMain.scala:24
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO DAGScheduler: Registering RDD 17 (count at DBSIISparkExerciseMain.scala:24) as input to shuffle 0
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO DAGScheduler: Got job 2 (count at DBSIISparkExerciseMain.scala:24) with 1 output partitions
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO DAGScheduler: Final stage: ResultStage 3 (count at DBSIISparkExerciseMain.scala:24)
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
2022.02.12 15:52:50 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
2022.02.12 15:52:50 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at DBSIISparkExerciseMain.scala:24), which has no missing parents
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 36.6 KiB, free 2.2 GiB)
2022.02.12 15:52:50 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 14.4 KiB, free 2.2 GiB)
2022.02.12 15:52:50 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.178.30:61118 (size: 14.4 KiB, free: 2.2 GiB)
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at DBSIISparkExerciseMain.scala:24) (first 15 tasks are for partitions Vector(0, 1))
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 2 tasks
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7748 bytes)
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7748 bytes)
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Readme.md, range: 0-2474, partition values: [empty row]
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt, range: 0-612, partition values: [empty row]
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO CodeGenerator: Code generated in 18.212061 ms
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:
2022.02.12 15:52:50 ERROR  Header length: 1, schema size: 3
2022.02.12 15:52:50 ERROR CSV file: file:///Users/Johann/Documents/GitHub/spark-tutorial/build.sbt
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 WARN BlockManager: Putting block rdd_13_1 failed due to exception java.lang.NullPointerException: Value at index 2 is null.
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 WARN BlockManager: Putting block rdd_13_0 failed due to exception java.lang.NullPointerException: Value at index 2 is null.
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 WARN BlockManager: Block rdd_13_0 could not be removed as it was not found on disk or in memory
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 WARN BlockManager: Block rdd_13_1 could not be removed as it was not found on disk or in memory
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 4)
2022.02.12 15:52:50 ERROR java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:52:50 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:52:50 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:52:50 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:52:50 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:52:50 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 ERROR Executor: Exception in task 1.0 in stage 2.0 (TID 5)
2022.02.12 15:52:50 ERROR java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:52:50 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:52:50 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:52:50 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:52:50 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:52:50 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 WARN TaskSetManager: Lost task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:52:50 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:52:50 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:52:50 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:52:50 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:52:50 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:52:50 ERROR 
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 ERROR TaskSetManager: Task 0 in stage 2.0 failed 1 times; aborting job
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO TaskSetManager: Lost task 1.0 in stage 2.0 (TID 5) on 192.168.178.30, executor driver: java.lang.NullPointerException (Value at index 2 is null) [duplicate 1]
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO TaskSchedulerImpl: Cancelling stage 2
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage cancelled
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO DAGScheduler: ShuffleMapStage 2 (count at DBSIISparkExerciseMain.scala:24) failed in 0,290 s due to Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:52:50 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:52:50 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:52:50 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:52:50 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:52:50 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:52:50 ERROR 
2022.02.12 15:52:50 ERROR Driver stacktrace:
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO DAGScheduler: Job 2 failed: count at DBSIISparkExerciseMain.scala:24, took 0,320766 s
2022.02.12 15:52:50 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 1 times, most recent failure: Lost task 0.0 in stage 2.0 (TID 4, 192.168.178.30, executor driver): java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:52:50 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:52:50 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:52:50 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:52:50 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:52:50 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:52:50 ERROR 
2022.02.12 15:52:50 ERROR Driver stacktrace:
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2023)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1972)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1971)
2022.02.12 15:52:50 ERROR 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
2022.02.12 15:52:50 ERROR 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
2022.02.12 15:52:50 ERROR 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1971)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:950)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:950)
2022.02.12 15:52:50 ERROR 	at scala.Option.foreach(Option.scala:407)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:950)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2203)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2152)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2141)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2133)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:388)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.collect(RDD.scala:1003)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:385)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$count$1(Dataset.scala:2979)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$count$1$adapted(Dataset.scala:2978)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3616)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3614)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Dataset.count(Dataset.scala:2978)
2022.02.12 15:52:50 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:24)
2022.02.12 15:52:50 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:5)
2022.02.12 15:52:50 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.12 15:52:50 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.12 15:52:50 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.12 15:52:50 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.12 15:52:50 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.12 15:52:50 ERROR 	at scala.App.main(App.scala:80)
2022.02.12 15:52:50 ERROR 	at scala.App.main$(App.scala:78)
2022.02.12 15:52:50 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:5)
2022.02.12 15:52:50 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.12 15:52:50 ERROR Caused by: java.lang.NullPointerException: Value at index 2 is null
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getAnyValAs(Row.scala:521)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getInt(Row.scala:243)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.Row.getInt$(Row.scala:243)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getInt(rows.scala:166)
2022.02.12 15:52:50 ERROR 	at de.hpi.dbsII_exercises.ChangeRecord$.from(ChangeRecord.scala:13)
2022.02.12 15:52:50 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.$anonfun$changeRecords$1(DBSIISparkExerciseMain.scala:22)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:132)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1371)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1298)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1362)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1186)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:360)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:311)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 15:52:50 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 15:52:50 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 15:52:50 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 15:52:50 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO SparkContext: Invoking stop() from shutdown hook
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO SparkUI: Stopped Spark web UI at http://192.168.178.30:4040
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO MemoryStore: MemoryStore cleared
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO BlockManager: BlockManager stopped
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO BlockManagerMaster: BlockManagerMaster stopped
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO SparkContext: Successfully stopped SparkContext
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO ShutdownHookManager: Shutdown hook called
2022.02.12 15:52:50 ERROR 22/02/12 15:52:50 INFO ShutdownHookManager: Deleting directory /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/spark-bc74f448-5230-484f-b3e4-f57b4aaa6acd
2022.02.12 15:52:50 INFO  Closing debug server tcp://0.0.0.0:61107
2022.02.12 15:52:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:52:59 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:53:17 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:53:19 INFO  time: compiled spark-tutorial in 1.14s
2022.02.12 15:53:30 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:53:31 INFO  time: compiled spark-tutorial in 1.38s
2022.02.12 15:53:33 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:53:34 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 15:53:34 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 15:53:35 INFO  time: compiled spark-tutorial in 2.19s
2022.02.12 15:54:02 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 7m 35.361s)
2022.02.12 15:54:02 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 15:54:03 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 15:54:03 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:54:06 INFO  Trying to attach to remote debuggee VM localhost:61158 .
2022.02.12 15:54:06 INFO  Attaching to debuggee VM succeeded.
2022.02.12 15:54:09 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 15:54:09 ERROR 22/02/12 15:54:07 WARN Utils: Your hostname, SchulzeTastPro-2.local resolves to a loopback address: 127.0.0.1; using 192.168.178.30 instead (on interface en0)
2022.02.12 15:54:09 ERROR 22/02/12 15:54:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2022.02.12 15:54:09 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 15:54:09 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 15:54:09 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 15:54:09 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 15:54:09 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 15:54:09 ERROR 22/02/12 15:54:07 INFO SparkContext: Running Spark version 3.0.0
2022.02.12 15:54:09 ERROR 22/02/12 15:54:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022.02.12 15:54:09 ERROR 22/02/12 15:54:08 INFO ResourceUtils: ==============================================================
2022.02.12 15:54:09 ERROR 22/02/12 15:54:08 INFO ResourceUtils: Resources for spark.driver:
2022.02.12 15:54:09 ERROR 
2022.02.12 15:54:09 ERROR 22/02/12 15:54:08 INFO ResourceUtils: ==============================================================
2022.02.12 15:54:09 ERROR 22/02/12 15:54:08 INFO SparkContext: Submitted application: SparkTutorial
2022.02.12 15:54:09 ERROR 22/02/12 15:54:08 INFO SecurityManager: Changing view acls to: Johann
2022.02.12 15:54:09 ERROR 22/02/12 15:54:08 INFO SecurityManager: Changing modify acls to: Johann
2022.02.12 15:54:09 ERROR 22/02/12 15:54:08 INFO SecurityManager: Changing view acls groups to: 
2022.02.12 15:54:09 ERROR 22/02/12 15:54:08 INFO SecurityManager: Changing modify acls groups to: 
2022.02.12 15:54:09 ERROR 22/02/12 15:54:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Johann); groups with view permissions: Set(); users  with modify permissions: Set(Johann); groups with modify permissions: Set()
2022.02.12 15:54:09 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:09 ERROR 22/02/12 15:54:09 INFO Utils: Successfully started service 'sparkDriver' on port 61161.
2022.02.12 15:54:09 ERROR 22/02/12 15:54:09 INFO SparkEnv: Registering MapOutputTracker
2022.02.12 15:54:09 ERROR 22/02/12 15:54:09 INFO SparkEnv: Registering BlockManagerMaster
2022.02.12 15:54:09 ERROR 22/02/12 15:54:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022.02.12 15:54:09 ERROR 22/02/12 15:54:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022.02.12 15:54:09 ERROR 22/02/12 15:54:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2022.02.12 15:54:09 ERROR 22/02/12 15:54:09 INFO DiskBlockManager: Created local directory at /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/blockmgr-c0fe34ae-e35c-4a06-a270-7b5feb0893a4
2022.02.12 15:54:09 ERROR 22/02/12 15:54:10 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
2022.02.12 15:54:09 ERROR 22/02/12 15:54:10 INFO SparkEnv: Registering OutputCommitCoordinator
2022.02.12 15:54:10 ERROR 22/02/12 15:54:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2022.02.12 15:54:10 ERROR 22/02/12 15:54:10 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.178.30:4040
2022.02.12 15:54:10 ERROR 22/02/12 15:54:10 INFO Executor: Starting executor ID driver on host 192.168.178.30
2022.02.12 15:54:10 ERROR 22/02/12 15:54:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61163.
2022.02.12 15:54:10 ERROR 22/02/12 15:54:10 INFO NettyBlockTransferService: Server created on 192.168.178.30:61163
2022.02.12 15:54:10 ERROR 22/02/12 15:54:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022.02.12 15:54:10 ERROR 22/02/12 15:54:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.178.30, 61163, None)
2022.02.12 15:54:10 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:10 ERROR 22/02/12 15:54:10 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.178.30:61163 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.178.30, 61163, None)
2022.02.12 15:54:10 ERROR 22/02/12 15:54:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.178.30, 61163, None)
2022.02.12 15:54:10 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:10 ERROR 22/02/12 15:54:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.178.30, 61163, None)
2022.02.12 15:54:10 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:11 ERROR 22/02/12 15:54:11 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse').
2022.02.12 15:54:11 ERROR 22/02/12 15:54:11 INFO SharedState: Warehouse path is 'file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse'.
2022.02.12 15:54:12 ERROR 22/02/12 15:54:12 INFO InMemoryFileIndex: It took 125 ms to list leaf files for 1 paths.
2022.02.12 15:54:12 ERROR 22/02/12 15:54:12 INFO InMemoryFileIndex: It took 13 ms to list leaf files for 6 paths.
2022.02.12 15:54:15 ERROR 22/02/12 15:54:15 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:54:15 ERROR 22/02/12 15:54:15 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:54:15 ERROR 22/02/12 15:54:15 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2022.02.12 15:54:15 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:15 ERROR 22/02/12 15:54:15 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:54:16 ERROR 22/02/12 15:54:16 INFO CodeGenerator: Code generated in 395.879817 ms
2022.02.12 15:54:16 ERROR 22/02/12 15:54:16 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:54:16 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:16 ERROR 22/02/12 15:54:16 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:54:16 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:16 ERROR 22/02/12 15:54:16 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.178.30:61163 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:54:16 ERROR 22/02/12 15:54:16 INFO SparkContext: Created broadcast 0 from load at IOHelper.scala:41
2022.02.12 15:54:16 ERROR 22/02/12 15:54:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 30064196 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:54:16 ERROR 22/02/12 15:54:17 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:54:16 ERROR 22/02/12 15:54:17 INFO DAGScheduler: Got job 0 (load at IOHelper.scala:41) with 1 output partitions
2022.02.12 15:54:16 ERROR 22/02/12 15:54:17 INFO DAGScheduler: Final stage: ResultStage 0 (load at IOHelper.scala:41)
2022.02.12 15:54:16 ERROR 22/02/12 15:54:17 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:54:16 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:16 ERROR 22/02/12 15:54:17 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:54:16 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:16 ERROR 22/02/12 15:54:17 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:54:16 ERROR 22/02/12 15:54:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022.02.12 15:54:16 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:16 ERROR 22/02/12 15:54:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022.02.12 15:54:16 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:16 ERROR 22/02/12 15:54:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.178.30:61163 (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 15:54:16 ERROR 22/02/12 15:54:17 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:54:16 ERROR 22/02/12 15:54:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0))
2022.02.12 15:54:16 ERROR 22/02/12 15:54:17 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
2022.02.12 15:54:16 ERROR 22/02/12 15:54:17 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7809 bytes)
2022.02.12 15:54:16 ERROR 22/02/12 15:54:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2022.02.12 15:54:17 ERROR 22/02/12 15:54:17 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_1.csv, range: 0-8164356, partition values: [empty row]
2022.02.12 15:54:17 ERROR 22/02/12 15:54:17 INFO CodeGenerator: Code generated in 17.98884 ms
2022.02.12 15:54:17 ERROR 22/02/12 15:54:17 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1615 bytes result sent to driver
2022.02.12 15:54:17 ERROR 22/02/12 15:54:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 473 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 15:54:17 ERROR 22/02/12 15:54:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022.02.12 15:54:17 ERROR 22/02/12 15:54:17 INFO DAGScheduler: ResultStage 0 (load at IOHelper.scala:41) finished in 0,691 s
2022.02.12 15:54:17 ERROR 22/02/12 15:54:17 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:54:17 ERROR 22/02/12 15:54:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2022.02.12 15:54:17 ERROR 22/02/12 15:54:17 INFO DAGScheduler: Job 0 finished: load at IOHelper.scala:41, took 0,765551 s
2022.02.12 15:54:17 ERROR 22/02/12 15:54:17 INFO CodeGenerator: Code generated in 12.979665 ms
2022.02.12 15:54:17 ERROR 22/02/12 15:54:17 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:54:17 ERROR 22/02/12 15:54:17 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:54:17 ERROR 22/02/12 15:54:17 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:54:17 ERROR 22/02/12 15:54:17 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 15:54:17 ERROR 22/02/12 15:54:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:54:17 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:54:17 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.178.30:61163 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO SparkContext: Created broadcast 2 from load at IOHelper.scala:41
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 30064196 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO DAGScheduler: Got job 1 (load at IOHelper.scala:41) with 5 output partitions
2022.02.12 15:54:17 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO DAGScheduler: Final stage: ResultStage 1 (load at IOHelper.scala:41)
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO DAGScheduler: Missing parents: List()
2022.02.12 15:54:17 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.1 KiB, free 2.2 GiB)
2022.02.12 15:54:17 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 2.2 GiB)
2022.02.12 15:54:17 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.178.30:61163 (size: 7.5 KiB, free: 2.2 GiB)
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7809 bytes)
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7809 bytes)
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 7809 bytes)
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, 192.168.178.30, executor driver, partition 3, PROCESS_LOCAL, 7809 bytes)
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_1.csv, range: 0-8164356, partition values: [empty row]
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_0.csv, range: 0-7859637, partition values: [empty row]
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_4.csv, range: 0-7878939, partition values: [empty row]
2022.02.12 15:54:17 ERROR 22/02/12 15:54:18 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_3.csv, range: 0-7712365, partition values: [empty row]
2022.02.12 15:54:20 ERROR 22/02/12 15:54:20 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.178.30:61163 in memory (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 15:54:20 ERROR 22/02/12 15:54:20 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.178.30:61163 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:54:25 ERROR 22/02/12 15:54:25 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_4.csv, range: 0-7878939, partition values: [empty row]
2022.02.12 15:54:25 ERROR 22/02/12 15:54:25 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_0.csv, range: 0-7859637, partition values: [empty row]
2022.02.12 15:54:25 ERROR 22/02/12 15:54:25 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_1.csv, range: 0-8164356, partition values: [empty row]
2022.02.12 15:54:25 ERROR 22/02/12 15:54:25 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_3.csv, range: 0-7712365, partition values: [empty row]
2022.02.12 15:54:31 ERROR 22/02/12 15:54:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1800 bytes result sent to driver
2022.02.12 15:54:31 ERROR 22/02/12 15:54:31 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1800 bytes result sent to driver
2022.02.12 15:54:31 ERROR 22/02/12 15:54:31 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5, 192.168.178.30, executor driver, partition 4, PROCESS_LOCAL, 7809 bytes)
2022.02.12 15:54:31 ERROR 22/02/12 15:54:31 INFO Executor: Running task 4.0 in stage 1.0 (TID 5)
2022.02.12 15:54:31 ERROR 22/02/12 15:54:31 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 13527 ms on 192.168.178.30 (executor driver) (1/5)
2022.02.12 15:54:31 ERROR 22/02/12 15:54:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 13529 ms on 192.168.178.30 (executor driver) (2/5)
2022.02.12 15:54:31 ERROR 22/02/12 15:54:31 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_2.csv, range: 0-7541576, partition values: [empty row]
2022.02.12 15:54:31 ERROR 22/02/12 15:54:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1757 bytes result sent to driver
2022.02.12 15:54:31 ERROR 22/02/12 15:54:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 13549 ms on 192.168.178.30 (executor driver) (3/5)
2022.02.12 15:54:31 ERROR 22/02/12 15:54:31 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1757 bytes result sent to driver
2022.02.12 15:54:31 ERROR 22/02/12 15:54:31 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 13623 ms on 192.168.178.30 (executor driver) (4/5)
2022.02.12 15:54:36 ERROR 22/02/12 15:54:36 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_2.csv, range: 0-7541576, partition values: [empty row]
2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO Executor: Finished task 4.0 in stage 1.0 (TID 5). 1757 bytes result sent to driver
2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 8612 ms on 192.168.178.30 (executor driver) (5/5)
2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO DAGScheduler: ResultStage 1 (load at IOHelper.scala:41) finished in 22,193 s
2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO DAGScheduler: Job 1 finished: load at IOHelper.scala:41, took 22,201588 s
2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO FileSourceStrategy: Output Data Schema: struct<Dataset_ID: string, Timestamp: timestamp, EntityID: int, AttributeName: string, newValue: string ... 3 more fields>
2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO CodeGenerator: Code generated in 18.713709 ms
2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO CodeGenerator: Code generated in 13.632603 ms
2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO CodeGenerator: Code generated in 62.821206 ms
2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 15:54:40 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 15:54:40 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.178.30:61163 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO SparkContext: Created broadcast 4 from count at DBSIISparkExerciseMain.scala:24
2022.02.12 15:54:40 ERROR 22/02/12 15:54:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 15032098 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO SparkContext: Starting job: count at DBSIISparkExerciseMain.scala:24
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO DAGScheduler: Registering RDD 17 (count at DBSIISparkExerciseMain.scala:24) as input to shuffle 0
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO DAGScheduler: Got job 2 (count at DBSIISparkExerciseMain.scala:24) with 1 output partitions
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO DAGScheduler: Final stage: ResultStage 3 (count at DBSIISparkExerciseMain.scala:24)
2022.02.12 15:54:40 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
2022.02.12 15:54:40 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at DBSIISparkExerciseMain.scala:24), which has no missing parents
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 38.1 KiB, free 2.2 GiB)
2022.02.12 15:54:40 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.0 KiB, free 2.2 GiB)
2022.02.12 15:54:40 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.178.30:61163 (size: 15.0 KiB, free: 2.2 GiB)
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at DBSIISparkExerciseMain.scala:24) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 6, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7766 bytes)
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 7, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7766 bytes)
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 8, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 7766 bytes)
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 9, 192.168.178.30, executor driver, partition 3, PROCESS_LOCAL, 7766 bytes)
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO Executor: Running task 2.0 in stage 2.0 (TID 8)
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO Executor: Running task 0.0 in stage 2.0 (TID 6)
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO Executor: Running task 3.0 in stage 2.0 (TID 9)
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO Executor: Running task 1.0 in stage 2.0 (TID 7)
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_4.csv, range: 0-7878939, partition values: [empty row]
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_3.csv, range: 0-7712365, partition values: [empty row]
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_1.csv, range: 0-8164356, partition values: [empty row]
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_0.csv, range: 0-7859637, partition values: [empty row]
2022.02.12 15:54:40 ERROR 22/02/12 15:54:41 INFO CodeGenerator: Code generated in 23.299926 ms
2022.02.12 15:54:41 ERROR 22/02/12 15:54:41 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.178.30:61163 in memory (size: 7.5 KiB, free: 2.2 GiB)
2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO MemoryStore: Block rdd_13_2 stored as values in memory (estimated size 1426.8 KiB, free 2.2 GiB)
2022.02.12 15:54:48 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO BlockManagerInfo: Added rdd_13_2 in memory on 192.168.178.30:61163 (size: 1426.8 KiB, free: 2.2 GiB)
2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 1616.6 KiB, free 2.2 GiB)
2022.02.12 15:54:48 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO BlockManagerInfo: Added rdd_13_0 in memory on 192.168.178.30:61163 (size: 1616.6 KiB, free: 2.2 GiB)
2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO MemoryStore: Block rdd_13_3 stored as values in memory (estimated size 1430.9 KiB, free 2.2 GiB)
2022.02.12 15:54:48 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO BlockManagerInfo: Added rdd_13_3 in memory on 192.168.178.30:61163 (size: 1430.9 KiB, free: 2.2 GiB)
2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO MemoryStore: Block rdd_13_1 stored as values in memory (estimated size 1032.8 KiB, free 2.2 GiB)
2022.02.12 15:54:48 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO BlockManagerInfo: Added rdd_13_1 in memory on 192.168.178.30:61163 (size: 1032.8 KiB, free: 2.2 GiB)
2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO CodeGenerator: Code generated in 7.262893 ms
2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO CodeGenerator: Code generated in 19.394941 ms
2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO Executor: Finished task 3.0 in stage 2.0 (TID 9). 2220 bytes result sent to driver
2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 6). 2220 bytes result sent to driver
2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO Executor: Finished task 1.0 in stage 2.0 (TID 7). 2220 bytes result sent to driver
2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO Executor: Finished task 2.0 in stage 2.0 (TID 8). 2220 bytes result sent to driver
2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 10, 192.168.178.30, executor driver, partition 4, PROCESS_LOCAL, 7766 bytes)
2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 9) in 7149 ms on 192.168.178.30 (executor driver) (1/5)
2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 7) in 7150 ms on 192.168.178.30 (executor driver) (2/5)
2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 6) in 7153 ms on 192.168.178.30 (executor driver) (3/5)
2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 8) in 7150 ms on 192.168.178.30 (executor driver) (4/5)
2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO Executor: Running task 4.0 in stage 2.0 (TID 10)
2022.02.12 15:54:48 ERROR 22/02/12 15:54:48 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_2.csv, range: 0-7541576, partition values: [empty row]
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO MemoryStore: Block rdd_13_4 stored as values in memory (estimated size 855.6 KiB, free 2.2 GiB)
2022.02.12 15:54:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO BlockManagerInfo: Added rdd_13_4 in memory on 192.168.178.30:61163 (size: 855.6 KiB, free: 2.2 GiB)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO Executor: Finished task 4.0 in stage 2.0 (TID 10). 2177 bytes result sent to driver
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 10) in 4355 ms on 192.168.178.30 (executor driver) (5/5)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO DAGScheduler: ShuffleMapStage 2 (count at DBSIISparkExerciseMain.scala:24) finished in 11,558 s
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO DAGScheduler: looking for newly runnable stages
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO DAGScheduler: running: Set()
2022.02.12 15:54:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO DAGScheduler: waiting: Set(ResultStage 3)
2022.02.12 15:54:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO DAGScheduler: failed: Set()
2022.02.12 15:54:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at count at DBSIISparkExerciseMain.scala:24), which has no missing parents
2022.02.12 15:54:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 10.1 KiB, free 2.2 GiB)
2022.02.12 15:54:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 2.2 GiB)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.178.30:61163 (size: 5.0 KiB, free: 2.2 GiB)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at count at DBSIISparkExerciseMain.scala:24) (first 15 tasks are for partitions Vector(0))
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 11, 192.168.178.30, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO Executor: Running task 0.0 in stage 3.0 (TID 11)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO ShuffleBlockFetcherIterator: Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO Executor: Finished task 0.0 in stage 3.0 (TID 11). 2648 bytes result sent to driver
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 11) in 71 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO DAGScheduler: ResultStage 3 (count at DBSIISparkExerciseMain.scala:24) finished in 0,090 s
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO DAGScheduler: Job 2 finished: count at DBSIISparkExerciseMain.scala:24, took 11,741548 s
2022.02.12 15:54:52 ERROR 22/02/12 15:54:52 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.178.30:61163 in memory (size: 5.0 KiB, free: 2.2 GiB)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO CodeGenerator: Code generated in 19.448334 ms
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO CodeGenerator: Code generated in 34.909313 ms
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO CodeGenerator: Code generated in 29.150693 ms
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO CodeGenerator: Code generated in 16.185448 ms
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO SparkContext: Starting job: collect at Exercise_3a.scala:22
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO DAGScheduler: Registering RDD 24 (collect at Exercise_3a.scala:22) as input to shuffle 1
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO DAGScheduler: Got job 3 (collect at Exercise_3a.scala:22) with 8 output partitions
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO DAGScheduler: Final stage: ResultStage 5 (collect at Exercise_3a.scala:22)
2022.02.12 15:54:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[24] at collect at Exercise_3a.scala:22), which has no missing parents
2022.02.12 15:54:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 42.8 KiB, free 2.2 GiB)
2022.02.12 15:54:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 16.9 KiB, free 2.2 GiB)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.178.30:61163 (size: 16.9 KiB, free: 2.2 GiB)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[24] at collect at Exercise_3a.scala:22) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 12, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7766 bytes)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 13, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7766 bytes)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 14, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 7766 bytes)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 15, 192.168.178.30, executor driver, partition 3, PROCESS_LOCAL, 7766 bytes)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO Executor: Running task 1.0 in stage 4.0 (TID 13)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO Executor: Running task 3.0 in stage 4.0 (TID 15)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO Executor: Running task 2.0 in stage 4.0 (TID 14)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO Executor: Running task 0.0 in stage 4.0 (TID 12)
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO BlockManager: Found block rdd_13_2 locally
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO BlockManager: Found block rdd_13_1 locally
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO BlockManager: Found block rdd_13_3 locally
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO BlockManager: Found block rdd_13_0 locally
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO CodeGenerator: Code generated in 38.659893 ms
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO CodeGenerator: Code generated in 21.666336 ms
2022.02.12 15:54:52 ERROR 22/02/12 15:54:53 INFO CodeGenerator: Code generated in 11.552261 ms
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.178.30:61163 in memory (size: 15.0 KiB, free: 2.2 GiB)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.178.30:61163 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO Executor: Finished task 2.0 in stage 4.0 (TID 14). 2465 bytes result sent to driver
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 16, 192.168.178.30, executor driver, partition 4, PROCESS_LOCAL, 7766 bytes)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 14) in 485 ms on 192.168.178.30 (executor driver) (1/5)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO Executor: Running task 4.0 in stage 4.0 (TID 16)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO Executor: Finished task 3.0 in stage 4.0 (TID 15). 2465 bytes result sent to driver
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 15) in 487 ms on 192.168.178.30 (executor driver) (2/5)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO BlockManager: Found block rdd_13_4 locally
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO Executor: Finished task 0.0 in stage 4.0 (TID 12). 2465 bytes result sent to driver
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 12) in 515 ms on 192.168.178.30 (executor driver) (3/5)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO Executor: Finished task 1.0 in stage 4.0 (TID 13). 2465 bytes result sent to driver
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 13) in 518 ms on 192.168.178.30 (executor driver) (4/5)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO Executor: Finished task 4.0 in stage 4.0 (TID 16). 2422 bytes result sent to driver
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 16) in 127 ms on 192.168.178.30 (executor driver) (5/5)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO DAGScheduler: ShuffleMapStage 4 (collect at Exercise_3a.scala:22) finished in 0,636 s
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO DAGScheduler: looking for newly runnable stages
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO DAGScheduler: running: Set()
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO DAGScheduler: waiting: Set(ResultStage 5)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO DAGScheduler: failed: Set()
2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at collect at Exercise_3a.scala:22), which has no missing parents
2022.02.12 15:54:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:53 ERROR 22/02/12 15:54:53 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 47.3 KiB, free 2.2 GiB)
2022.02.12 15:54:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 18.7 KiB, free 2.2 GiB)
2022.02.12 15:54:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.178.30:61163 (size: 18.7 KiB, free: 2.2 GiB)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at collect at Exercise_3a.scala:22) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO TaskSchedulerImpl: Adding task set 5.0 with 8 tasks
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 17, 192.168.178.30, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 18, 192.168.178.30, executor driver, partition 1, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 19, 192.168.178.30, executor driver, partition 2, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 20, 192.168.178.30, executor driver, partition 3, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO Executor: Running task 2.0 in stage 5.0 (TID 19)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO Executor: Running task 3.0 in stage 5.0 (TID 20)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO Executor: Running task 1.0 in stage 5.0 (TID 18)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO Executor: Running task 0.0 in stage 5.0 (TID 17)
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO ShuffleBlockFetcherIterator: Getting 3 (333.0 B) non-empty blocks including 3 (333.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO ShuffleBlockFetcherIterator: Getting 5 (466.0 B) non-empty blocks including 5 (466.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO ShuffleBlockFetcherIterator: Getting 4 (406.0 B) non-empty blocks including 4 (406.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO ShuffleBlockFetcherIterator: Getting 3 (331.0 B) non-empty blocks including 3 (331.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
2022.02.12 15:54:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:53 ERROR 22/02/12 15:54:54 INFO Executor: Finished task 3.0 in stage 5.0 (TID 20). 4171 bytes result sent to driver
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO Executor: Finished task 2.0 in stage 5.0 (TID 19). 4116 bytes result sent to driver
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO Executor: Finished task 0.0 in stage 5.0 (TID 17). 4116 bytes result sent to driver
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO Executor: Finished task 1.0 in stage 5.0 (TID 18). 4122 bytes result sent to driver
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 21, 192.168.178.30, executor driver, partition 4, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 22, 192.168.178.30, executor driver, partition 5, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 23, 192.168.178.30, executor driver, partition 6, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 24, 192.168.178.30, executor driver, partition 7, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO Executor: Running task 4.0 in stage 5.0 (TID 21)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO Executor: Running task 5.0 in stage 5.0 (TID 22)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO Executor: Running task 6.0 in stage 5.0 (TID 23)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 20) in 688 ms on 192.168.178.30 (executor driver) (1/8)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO Executor: Running task 7.0 in stage 5.0 (TID 24)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 17) in 696 ms on 192.168.178.30 (executor driver) (2/8)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 19) in 696 ms on 192.168.178.30 (executor driver) (3/8)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO ShuffleBlockFetcherIterator: Getting 2 (177.0 B) non-empty blocks including 2 (177.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO ShuffleBlockFetcherIterator: Getting 4 (386.0 B) non-empty blocks including 4 (386.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 18) in 705 ms on 192.168.178.30 (executor driver) (4/8)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO ShuffleBlockFetcherIterator: Getting 4 (354.0 B) non-empty blocks including 4 (354.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO ShuffleBlockFetcherIterator: Getting 5 (491.0 B) non-empty blocks including 5 (491.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO Executor: Finished task 4.0 in stage 5.0 (TID 21). 3877 bytes result sent to driver
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO Executor: Finished task 5.0 in stage 5.0 (TID 22). 4122 bytes result sent to driver
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 21) in 47 ms on 192.168.178.30 (executor driver) (5/8)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 22) in 46 ms on 192.168.178.30 (executor driver) (6/8)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO Executor: Finished task 7.0 in stage 5.0 (TID 24). 4171 bytes result sent to driver
2022.02.12 15:54:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 24) in 54 ms on 192.168.178.30 (executor driver) (7/8)
2022.02.12 15:54:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO Executor: Finished task 6.0 in stage 5.0 (TID 23). 4024 bytes result sent to driver
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 23) in 57 ms on 192.168.178.30 (executor driver) (8/8)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO DAGScheduler: ResultStage 5 (collect at Exercise_3a.scala:22) finished in 0,844 s
2022.02.12 15:54:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO DAGScheduler: Job 3 finished: collect at Exercise_3a.scala:22, took 1,506109 s
2022.02.12 15:54:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO SparkContext: Starting job: collect at Exercise_3a.scala:22
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO DAGScheduler: Registering RDD 30 (collect at Exercise_3a.scala:22) as input to shuffle 2
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO DAGScheduler: Got job 4 (collect at Exercise_3a.scala:22) with 8 output partitions
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO DAGScheduler: Final stage: ResultStage 8 (collect at Exercise_3a.scala:22)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[30] at collect at Exercise_3a.scala:22), which has no missing parents
2022.02.12 15:54:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 48.2 KiB, free 2.2 GiB)
2022.02.12 15:54:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 2.2 GiB)
2022.02.12 15:54:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.178.30:61163 (size: 19.2 KiB, free: 2.2 GiB)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[30] at collect at Exercise_3a.scala:22) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSchedulerImpl: Adding task set 7.0 with 8 tasks
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 25, 192.168.178.30, executor driver, partition 0, NODE_LOCAL, 7314 bytes)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 26, 192.168.178.30, executor driver, partition 1, NODE_LOCAL, 7314 bytes)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 27, 192.168.178.30, executor driver, partition 2, NODE_LOCAL, 7314 bytes)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 28, 192.168.178.30, executor driver, partition 3, NODE_LOCAL, 7314 bytes)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO Executor: Running task 1.0 in stage 7.0 (TID 26)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO Executor: Running task 3.0 in stage 7.0 (TID 28)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO Executor: Running task 2.0 in stage 7.0 (TID 27)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:54 INFO Executor: Running task 0.0 in stage 7.0 (TID 25)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.178.30:61163 in memory (size: 18.7 KiB, free: 2.2 GiB)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 192.168.178.30:61163 in memory (size: 16.9 KiB, free: 2.2 GiB)
2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Getting 4 (406.0 B) non-empty blocks including 4 (406.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Getting 3 (331.0 B) non-empty blocks including 3 (331.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Getting 3 (333.0 B) non-empty blocks including 3 (333.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Getting 5 (466.0 B) non-empty blocks including 5 (466.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO Executor: Finished task 2.0 in stage 7.0 (TID 27). 3797 bytes result sent to driver
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 29, 192.168.178.30, executor driver, partition 4, NODE_LOCAL, 7314 bytes)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO Executor: Running task 4.0 in stage 7.0 (TID 29)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 27) in 622 ms on 192.168.178.30 (executor driver) (1/8)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO Executor: Finished task 1.0 in stage 7.0 (TID 26). 3797 bytes result sent to driver
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 30, 192.168.178.30, executor driver, partition 5, NODE_LOCAL, 7314 bytes)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO Executor: Finished task 3.0 in stage 7.0 (TID 28). 3797 bytes result sent to driver
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 26) in 627 ms on 192.168.178.30 (executor driver) (2/8)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO Executor: Running task 5.0 in stage 7.0 (TID 30)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 31, 192.168.178.30, executor driver, partition 6, NODE_LOCAL, 7314 bytes)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 28) in 627 ms on 192.168.178.30 (executor driver) (3/8)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO Executor: Running task 6.0 in stage 7.0 (TID 31)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Getting 2 (177.0 B) non-empty blocks including 2 (177.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO Executor: Finished task 0.0 in stage 7.0 (TID 25). 3797 bytes result sent to driver
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 32, 192.168.178.30, executor driver, partition 7, NODE_LOCAL, 7314 bytes)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO Executor: Running task 7.0 in stage 7.0 (TID 32)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 25) in 654 ms on 192.168.178.30 (executor driver) (4/8)
2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO Executor: Finished task 4.0 in stage 7.0 (TID 29). 3797 bytes result sent to driver
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 29) in 42 ms on 192.168.178.30 (executor driver) (5/8)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Getting 4 (354.0 B) non-empty blocks including 4 (354.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 26 ms
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Getting 5 (491.0 B) non-empty blocks including 5 (491.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Getting 4 (386.0 B) non-empty blocks including 4 (386.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 40 ms
2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO Executor: Finished task 6.0 in stage 7.0 (TID 31). 3797 bytes result sent to driver
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 31) in 83 ms on 192.168.178.30 (executor driver) (6/8)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO Executor: Finished task 5.0 in stage 7.0 (TID 30). 3797 bytes result sent to driver
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 30) in 94 ms on 192.168.178.30 (executor driver) (7/8)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO Executor: Finished task 7.0 in stage 7.0 (TID 32). 3797 bytes result sent to driver
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 32) in 75 ms on 192.168.178.30 (executor driver) (8/8)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO DAGScheduler: ShuffleMapStage 7 (collect at Exercise_3a.scala:22) finished in 0,770 s
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO DAGScheduler: looking for newly runnable stages
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO DAGScheduler: running: Set()
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO DAGScheduler: waiting: Set(ResultStage 8)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO DAGScheduler: failed: Set()
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[33] at collect at Exercise_3a.scala:22), which has no missing parents
2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 45.3 KiB, free 2.2 GiB)
2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 2.2 GiB)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.178.30:61163 (size: 17.9 KiB, free: 2.2 GiB)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 8 (MapPartitionsRDD[33] at collect at Exercise_3a.scala:22) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSchedulerImpl: Adding task set 8.0 with 8 tasks
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 33, 192.168.178.30, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 34, 192.168.178.30, executor driver, partition 1, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 35, 192.168.178.30, executor driver, partition 2, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 36, 192.168.178.30, executor driver, partition 3, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO Executor: Running task 3.0 in stage 8.0 (TID 36)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO Executor: Running task 2.0 in stage 8.0 (TID 35)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO Executor: Running task 1.0 in stage 8.0 (TID 34)
2022.02.12 15:54:54 ERROR 22/02/12 15:54:55 INFO Executor: Running task 0.0 in stage 8.0 (TID 33)
2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:55 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Getting 6 (497.0 B) non-empty blocks including 6 (497.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:55 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:55 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Getting 5 (451.0 B) non-empty blocks including 5 (451.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:55 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:55 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Getting 4 (371.0 B) non-empty blocks including 4 (371.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:55 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:55 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Getting 4 (374.0 B) non-empty blocks including 4 (374.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:55 ERROR 22/02/12 15:54:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:55 ERROR 22/02/12 15:54:55 INFO CodeGenerator: Code generated in 19.820581 ms
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO Executor: Finished task 0.0 in stage 8.0 (TID 33). 4634 bytes result sent to driver
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO Executor: Finished task 3.0 in stage 8.0 (TID 36). 4629 bytes result sent to driver
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 37, 192.168.178.30, executor driver, partition 4, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO Executor: Running task 4.0 in stage 8.0 (TID 37)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 38, 192.168.178.30, executor driver, partition 5, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 33) in 351 ms on 192.168.178.30 (executor driver) (1/8)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 36) in 349 ms on 192.168.178.30 (executor driver) (2/8)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO Executor: Running task 5.0 in stage 8.0 (TID 38)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO Executor: Finished task 2.0 in stage 8.0 (TID 35). 4627 bytes result sent to driver
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 39, 192.168.178.30, executor driver, partition 6, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 35) in 355 ms on 192.168.178.30 (executor driver) (3/8)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO Executor: Running task 6.0 in stage 8.0 (TID 39)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO Executor: Finished task 1.0 in stage 8.0 (TID 34). 4667 bytes result sent to driver
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO ShuffleBlockFetcherIterator: Getting 5 (434.0 B) non-empty blocks including 5 (434.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO ShuffleBlockFetcherIterator: Getting 4 (374.0 B) non-empty blocks including 4 (374.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 40, 192.168.178.30, executor driver, partition 7, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 34) in 367 ms on 192.168.178.30 (executor driver) (4/8)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO Executor: Running task 7.0 in stage 8.0 (TID 40)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO ShuffleBlockFetcherIterator: Getting 5 (434.0 B) non-empty blocks including 5 (434.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO ShuffleBlockFetcherIterator: Getting 6 (497.0 B) non-empty blocks including 6 (497.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO Executor: Finished task 6.0 in stage 8.0 (TID 39). 4633 bytes result sent to driver
2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO Executor: Finished task 5.0 in stage 8.0 (TID 38). 4631 bytes result sent to driver
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO Executor: Finished task 4.0 in stage 8.0 (TID 37). 4628 bytes result sent to driver
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 39) in 53 ms on 192.168.178.30 (executor driver) (5/8)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 38) in 57 ms on 192.168.178.30 (executor driver) (6/8)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 37) in 68 ms on 192.168.178.30 (executor driver) (7/8)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO Executor: Finished task 7.0 in stage 8.0 (TID 40). 4630 bytes result sent to driver
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 40) in 60 ms on 192.168.178.30 (executor driver) (8/8)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO DAGScheduler: ResultStage 8 (collect at Exercise_3a.scala:22) finished in 0,451 s
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO DAGScheduler: Job 4 finished: collect at Exercise_3a.scala:22, took 1,242517 s
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO CodeGenerator: Code generated in 19.964618 ms
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO CodeGenerator: Code generated in 30.305404 ms
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO CodeGenerator: Code generated in 43.14072 ms
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO SparkContext: Starting job: collect at Exercise_3b.scala:19
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO DAGScheduler: Registering RDD 37 (collect at Exercise_3b.scala:19) as input to shuffle 3
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO DAGScheduler: Got job 5 (collect at Exercise_3b.scala:19) with 8 output partitions
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO DAGScheduler: Final stage: ResultStage 10 (collect at Exercise_3b.scala:19)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[37] at collect at Exercise_3b.scala:19), which has no missing parents
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 48.7 KiB, free 2.2 GiB)
2022.02.12 15:54:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:56 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 19.6 KiB, free 2.2 GiB)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.178.30:61163 (size: 19.6 KiB, free: 2.2 GiB)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[37] at collect at Exercise_3b.scala:19) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSchedulerImpl: Adding task set 9.0 with 5 tasks
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 41, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7766 bytes)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 42, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7766 bytes)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 43, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 7766 bytes)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 44, 192.168.178.30, executor driver, partition 3, PROCESS_LOCAL, 7766 bytes)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO Executor: Running task 1.0 in stage 9.0 (TID 42)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO Executor: Running task 3.0 in stage 9.0 (TID 44)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO Executor: Running task 2.0 in stage 9.0 (TID 43)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO Executor: Running task 0.0 in stage 9.0 (TID 41)
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO BlockManager: Found block rdd_13_1 locally
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO BlockManager: Found block rdd_13_2 locally
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO BlockManager: Found block rdd_13_3 locally
2022.02.12 15:54:55 ERROR 22/02/12 15:54:56 INFO BlockManager: Found block rdd_13_0 locally
2022.02.12 15:54:56 ERROR 22/02/12 15:54:56 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 192.168.178.30:61163 in memory (size: 17.9 KiB, free: 2.2 GiB)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:56 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.178.30:61163 in memory (size: 19.2 KiB, free: 2.2 GiB)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:56 INFO CodeGenerator: Code generated in 23.997958 ms
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO CodeGenerator: Code generated in 177.482362 ms
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO Executor: Finished task 1.0 in stage 9.0 (TID 42). 2465 bytes result sent to driver
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO Executor: Finished task 0.0 in stage 9.0 (TID 41). 2465 bytes result sent to driver
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 45, 192.168.178.30, executor driver, partition 4, PROCESS_LOCAL, 7766 bytes)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO Executor: Finished task 2.0 in stage 9.0 (TID 43). 2465 bytes result sent to driver
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO Executor: Running task 4.0 in stage 9.0 (TID 45)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 42) in 945 ms on 192.168.178.30 (executor driver) (1/5)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO Executor: Finished task 3.0 in stage 9.0 (TID 44). 2465 bytes result sent to driver
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 41) in 951 ms on 192.168.178.30 (executor driver) (2/5)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO BlockManager: Found block rdd_13_4 locally
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 43) in 963 ms on 192.168.178.30 (executor driver) (3/5)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 44) in 962 ms on 192.168.178.30 (executor driver) (4/5)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO Executor: Finished task 4.0 in stage 9.0 (TID 45). 2465 bytes result sent to driver
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 45) in 115 ms on 192.168.178.30 (executor driver) (5/5)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO DAGScheduler: ShuffleMapStage 9 (collect at Exercise_3b.scala:19) finished in 1,083 s
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO DAGScheduler: looking for newly runnable stages
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO DAGScheduler: running: Set()
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO DAGScheduler: waiting: Set(ResultStage 10)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO DAGScheduler: failed: Set()
2022.02.12 15:54:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[40] at collect at Exercise_3b.scala:19), which has no missing parents
2022.02.12 15:54:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 55.9 KiB, free 2.2 GiB)
2022.02.12 15:54:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 21.5 KiB, free 2.2 GiB)
2022.02.12 15:54:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.178.30:61163 (size: 21.5 KiB, free: 2.2 GiB)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1200
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 10 (MapPartitionsRDD[40] at collect at Exercise_3b.scala:19) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO TaskSchedulerImpl: Adding task set 10.0 with 8 tasks
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 46, 192.168.178.30, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 47, 192.168.178.30, executor driver, partition 1, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 48, 192.168.178.30, executor driver, partition 2, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 49, 192.168.178.30, executor driver, partition 3, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO Executor: Running task 0.0 in stage 10.0 (TID 46)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO Executor: Running task 1.0 in stage 10.0 (TID 47)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO Executor: Running task 2.0 in stage 10.0 (TID 48)
2022.02.12 15:54:56 ERROR 22/02/12 15:54:57 INFO Executor: Running task 3.0 in stage 10.0 (TID 49)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO ShuffleBlockFetcherIterator: Getting 5 (518.0 B) non-empty blocks including 5 (518.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO ShuffleBlockFetcherIterator: Getting 3 (375.0 B) non-empty blocks including 3 (375.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO ShuffleBlockFetcherIterator: Getting 4 (461.0 B) non-empty blocks including 4 (461.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO ShuffleBlockFetcherIterator: Getting 3 (364.0 B) non-empty blocks including 3 (364.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO Executor: Finished task 3.0 in stage 10.0 (TID 49). 3784 bytes result sent to driver
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO Executor: Finished task 1.0 in stage 10.0 (TID 47). 3762 bytes result sent to driver
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO Executor: Finished task 0.0 in stage 10.0 (TID 46). 3732 bytes result sent to driver
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 50, 192.168.178.30, executor driver, partition 4, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO Executor: Running task 4.0 in stage 10.0 (TID 50)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 51, 192.168.178.30, executor driver, partition 5, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 49) in 303 ms on 192.168.178.30 (executor driver) (1/8)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 47) in 305 ms on 192.168.178.30 (executor driver) (2/8)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 52, 192.168.178.30, executor driver, partition 6, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 46) in 308 ms on 192.168.178.30 (executor driver) (3/8)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO Executor: Running task 5.0 in stage 10.0 (TID 51)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO Executor: Running task 6.0 in stage 10.0 (TID 52)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO Executor: Finished task 2.0 in stage 10.0 (TID 48). 3734 bytes result sent to driver
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 53, 192.168.178.30, executor driver, partition 7, NODE_LOCAL, 7325 bytes)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 48) in 313 ms on 192.168.178.30 (executor driver) (4/8)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO ShuffleBlockFetcherIterator: Getting 4 (430.0 B) non-empty blocks including 4 (430.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO Executor: Running task 7.0 in stage 10.0 (TID 53)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO ShuffleBlockFetcherIterator: Getting 4 (388.0 B) non-empty blocks including 4 (388.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO ShuffleBlockFetcherIterator: Getting 2 (194.0 B) non-empty blocks including 2 (194.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO Executor: Finished task 5.0 in stage 10.0 (TID 51). 3757 bytes result sent to driver
2022.02.12 15:54:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 51) in 30 ms on 192.168.178.30 (executor driver) (5/8)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO Executor: Finished task 4.0 in stage 10.0 (TID 50). 3638 bytes result sent to driver
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO Executor: Finished task 6.0 in stage 10.0 (TID 52). 3716 bytes result sent to driver
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 50) in 33 ms on 192.168.178.30 (executor driver) (6/8)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 52) in 31 ms on 192.168.178.30 (executor driver) (7/8)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO ShuffleBlockFetcherIterator: Getting 5 (540.0 B) non-empty blocks including 5 (540.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 15:54:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO Executor: Finished task 7.0 in stage 10.0 (TID 53). 3775 bytes result sent to driver
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 53) in 59 ms on 192.168.178.30 (executor driver) (8/8)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO DAGScheduler: ResultStage 10 (collect at Exercise_3b.scala:19) finished in 0,384 s
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO DAGScheduler: Job 5 finished: collect at Exercise_3b.scala:19, took 1,484100 s
2022.02.12 15:54:57 ERROR 22/02/12 15:54:57 INFO CodeGenerator: Code generated in 15.675431 ms
2022.02.12 15:54:57 ERROR Exception in thread "main" scala.NotImplementedError: an implementation is missing
2022.02.12 15:54:57 ERROR 	at scala.Predef$.$qmark$qmark$qmark(Predef.scala:288)
2022.02.12 15:54:57 ERROR 	at de.hpi.dbsII_exercises.Exercise_3c.execute(Exercise_3c.scala:27)
2022.02.12 15:54:57 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:27)
2022.02.12 15:54:57 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:5)
2022.02.12 15:54:57 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.12 15:54:57 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.12 15:54:57 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.12 15:54:57 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.12 15:54:57 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.12 15:54:57 ERROR 	at scala.App.main(App.scala:80)
2022.02.12 15:54:57 ERROR 	at scala.App.main$(App.scala:78)
2022.02.12 15:54:57 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:5)
2022.02.12 15:54:57 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.12 15:54:57 ERROR 22/02/12 15:54:58 INFO SparkContext: Invoking stop() from shutdown hook
2022.02.12 15:54:57 ERROR 22/02/12 15:54:58 INFO SparkUI: Stopped Spark web UI at http://192.168.178.30:4040
2022.02.12 15:54:57 ERROR 22/02/12 15:54:58 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2022.02.12 15:54:57 ERROR 22/02/12 15:54:58 INFO MemoryStore: MemoryStore cleared
2022.02.12 15:54:57 ERROR 22/02/12 15:54:58 INFO BlockManager: BlockManager stopped
2022.02.12 15:54:57 ERROR 22/02/12 15:54:58 INFO BlockManagerMaster: BlockManagerMaster stopped
2022.02.12 15:54:57 ERROR 22/02/12 15:54:58 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2022.02.12 15:54:57 ERROR 22/02/12 15:54:58 INFO SparkContext: Successfully stopped SparkContext
2022.02.12 15:54:57 ERROR 22/02/12 15:54:58 INFO ShutdownHookManager: Shutdown hook called
2022.02.12 15:54:57 ERROR 22/02/12 15:54:58 INFO ShutdownHookManager: Deleting directory /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/spark-b8ee127a-8d98-4146-8142-e8daba09ca68
2022.02.12 15:54:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 15:54:58 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 15:54:57 INFO  Closing debug server tcp://0.0.0.0:61152
2022.02.12 15:57:01 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:57:01 INFO  time: compiled spark-tutorial in 0.28s
2022.02.12 15:57:04 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:57:04 INFO  time: compiled spark-tutorial in 0.43s
2022.02.12 15:57:07 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:57:07 INFO  time: compiled spark-tutorial in 0.25s
2022.02.12 15:57:09 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 15:57:10 INFO  time: compiled spark-tutorial in 1.37s
2022.02.12 16:00:44 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 14m 18.108s)
2022.02.12 16:00:44 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 16:00:46 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 16:00:46 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:00:49 INFO  Trying to attach to remote debuggee VM localhost:61266 .
2022.02.12 16:00:49 INFO  Attaching to debuggee VM succeeded.
2022.02.12 16:00:51 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 16:00:51 ERROR 22/02/12 16:00:51 WARN Utils: Your hostname, SchulzeTastPro-2.local resolves to a loopback address: 127.0.0.1; using 192.168.178.30 instead (on interface en0)
2022.02.12 16:00:51 ERROR 22/02/12 16:00:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
2022.02.12 16:00:51 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 16:00:51 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 16:00:51 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 16:00:51 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 16:00:51 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 16:00:51 ERROR 22/02/12 16:00:51 INFO SparkContext: Running Spark version 3.0.0
2022.02.12 16:00:51 ERROR 22/02/12 16:00:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2022.02.12 16:00:51 ERROR 22/02/12 16:00:52 INFO ResourceUtils: ==============================================================
2022.02.12 16:00:51 ERROR 22/02/12 16:00:52 INFO ResourceUtils: Resources for spark.driver:
2022.02.12 16:00:51 ERROR 
2022.02.12 16:00:51 ERROR 22/02/12 16:00:52 INFO ResourceUtils: ==============================================================
2022.02.12 16:00:51 ERROR 22/02/12 16:00:52 INFO SparkContext: Submitted application: SparkTutorial
2022.02.12 16:00:51 ERROR 22/02/12 16:00:52 INFO SecurityManager: Changing view acls to: Johann
2022.02.12 16:00:51 ERROR 22/02/12 16:00:52 INFO SecurityManager: Changing modify acls to: Johann
2022.02.12 16:00:51 ERROR 22/02/12 16:00:52 INFO SecurityManager: Changing view acls groups to: 
2022.02.12 16:00:51 ERROR 22/02/12 16:00:52 INFO SecurityManager: Changing modify acls groups to: 
2022.02.12 16:00:51 ERROR 22/02/12 16:00:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Johann); groups with view permissions: Set(); users  with modify permissions: Set(Johann); groups with modify permissions: Set()
2022.02.12 16:00:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:00:52 ERROR 22/02/12 16:00:52 INFO Utils: Successfully started service 'sparkDriver' on port 61270.
2022.02.12 16:00:52 ERROR 22/02/12 16:00:52 INFO SparkEnv: Registering MapOutputTracker
2022.02.12 16:00:52 ERROR 22/02/12 16:00:53 INFO SparkEnv: Registering BlockManagerMaster
2022.02.12 16:00:52 ERROR 22/02/12 16:00:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022.02.12 16:00:52 ERROR 22/02/12 16:00:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
2022.02.12 16:00:52 ERROR 22/02/12 16:00:53 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
2022.02.12 16:00:52 ERROR 22/02/12 16:00:53 INFO DiskBlockManager: Created local directory at /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/blockmgr-ce97ded4-2fcb-491a-a53c-bcd9381df931
2022.02.12 16:00:52 ERROR 22/02/12 16:00:53 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
2022.02.12 16:00:52 ERROR 22/02/12 16:00:53 INFO SparkEnv: Registering OutputCommitCoordinator
2022.02.12 16:00:52 ERROR 22/02/12 16:00:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
2022.02.12 16:00:52 ERROR 22/02/12 16:00:53 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.178.30:4040
2022.02.12 16:00:52 ERROR 22/02/12 16:00:53 INFO Executor: Starting executor ID driver on host 192.168.178.30
2022.02.12 16:00:52 ERROR 22/02/12 16:00:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61271.
2022.02.12 16:00:52 ERROR 22/02/12 16:00:53 INFO NettyBlockTransferService: Server created on 192.168.178.30:61271
2022.02.12 16:00:52 ERROR 22/02/12 16:00:53 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022.02.12 16:00:53 ERROR 22/02/12 16:00:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.178.30, 61271, None)
2022.02.12 16:00:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:00:53 ERROR 22/02/12 16:00:53 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.178.30:61271 with 2.2 GiB RAM, BlockManagerId(driver, 192.168.178.30, 61271, None)
2022.02.12 16:00:53 ERROR 22/02/12 16:00:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.178.30, 61271, None)
2022.02.12 16:00:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:00:53 ERROR 22/02/12 16:00:53 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.178.30, 61271, None)
2022.02.12 16:00:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:00:53 ERROR 22/02/12 16:00:54 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse').
2022.02.12 16:00:53 ERROR 22/02/12 16:00:54 INFO SharedState: Warehouse path is 'file:/Users/Johann/Documents/GitHub/spark-tutorial/spark-warehouse'.
2022.02.12 16:00:56 ERROR 22/02/12 16:00:56 INFO InMemoryFileIndex: It took 147 ms to list leaf files for 1 paths.
2022.02.12 16:00:56 ERROR 22/02/12 16:00:56 INFO InMemoryFileIndex: It took 14 ms to list leaf files for 6 paths.
2022.02.12 16:00:59 ERROR 22/02/12 16:00:59 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 16:00:59 ERROR 22/02/12 16:00:59 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 16:00:59 ERROR 22/02/12 16:00:59 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
2022.02.12 16:00:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:00:59 ERROR 22/02/12 16:00:59 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 16:01:00 ERROR 22/02/12 16:01:00 INFO CodeGenerator: Code generated in 346.195524 ms
2022.02.12 16:01:00 ERROR 22/02/12 16:01:00 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 16:01:00 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:00 ERROR 22/02/12 16:01:01 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 16:01:00 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:00 ERROR 22/02/12 16:01:01 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 192.168.178.30:61271 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:00 ERROR 22/02/12 16:01:01 INFO SparkContext: Created broadcast 0 from load at IOHelper.scala:41
2022.02.12 16:01:00 ERROR 22/02/12 16:01:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 30064196 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 16:01:00 ERROR 22/02/12 16:01:01 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 16:01:00 ERROR 22/02/12 16:01:01 INFO DAGScheduler: Got job 0 (load at IOHelper.scala:41) with 1 output partitions
2022.02.12 16:01:00 ERROR 22/02/12 16:01:01 INFO DAGScheduler: Final stage: ResultStage 0 (load at IOHelper.scala:41)
2022.02.12 16:01:00 ERROR 22/02/12 16:01:01 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 16:01:00 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:00 ERROR 22/02/12 16:01:01 INFO DAGScheduler: Missing parents: List()
2022.02.12 16:01:00 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:00 ERROR 22/02/12 16:01:01 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 16:01:01 ERROR 22/02/12 16:01:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022.02.12 16:01:01 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:01 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:01 ERROR 22/02/12 16:01:01 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022.02.12 16:01:01 ERROR 22/02/12 16:01:01 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 192.168.178.30:61271 (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 16:01:01 ERROR 22/02/12 16:01:01 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1200
2022.02.12 16:01:01 ERROR 22/02/12 16:01:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0))
2022.02.12 16:01:02 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:04 ERROR 22/02/12 16:01:01 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
2022.02.12 16:01:04 ERROR 22/02/12 16:01:02 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7809 bytes)
2022.02.12 16:01:04 ERROR 22/02/12 16:01:02 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
2022.02.12 16:01:04 ERROR 22/02/12 16:01:02 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_1.csv, range: 0-8164356, partition values: [empty row]
2022.02.12 16:01:04 ERROR 22/02/12 16:01:02 INFO CodeGenerator: Code generated in 21.77435 ms
2022.02.12 16:01:04 ERROR 22/02/12 16:01:02 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1658 bytes result sent to driver
2022.02.12 16:01:04 ERROR 22/02/12 16:01:02 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 758 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 16:01:04 ERROR 22/02/12 16:01:02 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022.02.12 16:01:04 ERROR 22/02/12 16:01:02 INFO DAGScheduler: ResultStage 0 (load at IOHelper.scala:41) finished in 1,087 s
2022.02.12 16:01:04 ERROR 22/02/12 16:01:02 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 16:01:04 ERROR 22/02/12 16:01:02 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
2022.02.12 16:01:04 ERROR 22/02/12 16:01:02 INFO DAGScheduler: Job 0 finished: load at IOHelper.scala:41, took 1,201790 s
2022.02.12 16:01:04 ERROR 22/02/12 16:01:02 INFO CodeGenerator: Code generated in 18.510105 ms
2022.02.12 16:01:04 ERROR 22/02/12 16:01:02 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 16:01:04 ERROR 22/02/12 16:01:02 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 16:01:04 ERROR 22/02/12 16:01:02 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 16:01:04 ERROR 22/02/12 16:01:02 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 16:01:04 ERROR 22/02/12 16:01:02 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 16:01:04 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 192.168.178.30:61271 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO SparkContext: Created broadcast 2 from load at IOHelper.scala:41
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 30064196 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO DAGScheduler: Got job 1 (load at IOHelper.scala:41) with 5 output partitions
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO DAGScheduler: Final stage: ResultStage 1 (load at IOHelper.scala:41)
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 16:01:04 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:04 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO DAGScheduler: Missing parents: List()
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.1 KiB, free 2.2 GiB)
2022.02.12 16:01:04 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 2.2 GiB)
2022.02.12 16:01:04 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 192.168.178.30:61271 (size: 7.5 KiB, free: 2.2 GiB)
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1200
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7809 bytes)
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7809 bytes)
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 7809 bytes)
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, 192.168.178.30, executor driver, partition 3, PROCESS_LOCAL, 7809 bytes)
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_3.csv, range: 0-7712365, partition values: [empty row]
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_4.csv, range: 0-7878939, partition values: [empty row]
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_0.csv, range: 0-7859637, partition values: [empty row]
2022.02.12 16:01:04 ERROR 22/02/12 16:01:04 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_1.csv, range: 0-8164356, partition values: [empty row]
2022.02.12 16:01:07 ERROR 22/02/12 16:01:07 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 192.168.178.30:61271 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:07 ERROR 22/02/12 16:01:07 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 192.168.178.30:61271 in memory (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 16:01:13 ERROR 22/02/12 16:01:13 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_1.csv, range: 0-8164356, partition values: [empty row]
2022.02.12 16:01:13 ERROR 22/02/12 16:01:13 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_4.csv, range: 0-7878939, partition values: [empty row]
2022.02.12 16:01:13 ERROR 22/02/12 16:01:13 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_3.csv, range: 0-7712365, partition values: [empty row]
2022.02.12 16:01:13 ERROR 22/02/12 16:01:13 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_0.csv, range: 0-7859637, partition values: [empty row]
2022.02.12 16:01:20 ERROR 22/02/12 16:01:20 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 1800 bytes result sent to driver
2022.02.12 16:01:20 ERROR 22/02/12 16:01:20 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 1800 bytes result sent to driver
2022.02.12 16:01:20 ERROR 22/02/12 16:01:20 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1800 bytes result sent to driver
2022.02.12 16:01:20 ERROR 22/02/12 16:01:20 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 1800 bytes result sent to driver
2022.02.12 16:01:20 ERROR 22/02/12 16:01:20 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 5, 192.168.178.30, executor driver, partition 4, PROCESS_LOCAL, 7809 bytes)
2022.02.12 16:01:20 ERROR 22/02/12 16:01:20 INFO Executor: Running task 4.0 in stage 1.0 (TID 5)
2022.02.12 16:01:20 ERROR 22/02/12 16:01:20 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 15675 ms on 192.168.178.30 (executor driver) (1/5)
2022.02.12 16:01:20 ERROR 22/02/12 16:01:20 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 15672 ms on 192.168.178.30 (executor driver) (2/5)
2022.02.12 16:01:20 ERROR 22/02/12 16:01:20 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 15676 ms on 192.168.178.30 (executor driver) (3/5)
2022.02.12 16:01:20 ERROR 22/02/12 16:01:20 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 15676 ms on 192.168.178.30 (executor driver) (4/5)
2022.02.12 16:01:20 ERROR 22/02/12 16:01:20 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_2.csv, range: 0-7541576, partition values: [empty row]
2022.02.12 16:01:27 ERROR 22/02/12 16:01:27 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_2.csv, range: 0-7541576, partition values: [empty row]
2022.02.12 16:01:32 ERROR 22/02/12 16:01:32 INFO Executor: Finished task 4.0 in stage 1.0 (TID 5). 1757 bytes result sent to driver
2022.02.12 16:01:32 ERROR 22/02/12 16:01:32 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 5) in 12297 ms on 192.168.178.30 (executor driver) (5/5)
2022.02.12 16:01:32 ERROR 22/02/12 16:01:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022.02.12 16:01:32 ERROR 22/02/12 16:01:32 INFO DAGScheduler: ResultStage 1 (load at IOHelper.scala:41) finished in 28,057 s
2022.02.12 16:01:32 ERROR 22/02/12 16:01:32 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 16:01:32 ERROR 22/02/12 16:01:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
2022.02.12 16:01:32 ERROR 22/02/12 16:01:32 INFO DAGScheduler: Job 1 finished: load at IOHelper.scala:41, took 28,067750 s
2022.02.12 16:01:32 ERROR 22/02/12 16:01:32 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 16:01:32 ERROR 22/02/12 16:01:32 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 16:01:32 ERROR 22/02/12 16:01:32 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 16:01:32 ERROR 22/02/12 16:01:32 INFO FileSourceStrategy: Output Data Schema: struct<Dataset_ID: string, Timestamp: timestamp, EntityID: int, AttributeName: string, newValue: string ... 3 more fields>
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO CodeGenerator: Code generated in 19.982224 ms
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO CodeGenerator: Code generated in 15.853745 ms
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO CodeGenerator: Code generated in 63.106797 ms
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 16:01:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 16:01:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 192.168.178.30:61271 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO SparkContext: Created broadcast 4 from count at DBSIISparkExerciseMain.scala:24
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 15032098 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO SparkContext: Starting job: count at DBSIISparkExerciseMain.scala:24
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO DAGScheduler: Registering RDD 17 (count at DBSIISparkExerciseMain.scala:24) as input to shuffle 0
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO DAGScheduler: Got job 2 (count at DBSIISparkExerciseMain.scala:24) with 1 output partitions
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO DAGScheduler: Final stage: ResultStage 3 (count at DBSIISparkExerciseMain.scala:24)
2022.02.12 16:01:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
2022.02.12 16:01:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at count at DBSIISparkExerciseMain.scala:24), which has no missing parents
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 38.1 KiB, free 2.2 GiB)
2022.02.12 16:01:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 15.0 KiB, free 2.2 GiB)
2022.02.12 16:01:33 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 192.168.178.30:61271 (size: 15.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1200
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at count at DBSIISparkExerciseMain.scala:24) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 6, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7766 bytes)
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 7, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7766 bytes)
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 8, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 7766 bytes)
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 9, 192.168.178.30, executor driver, partition 3, PROCESS_LOCAL, 7766 bytes)
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO Executor: Running task 1.0 in stage 2.0 (TID 7)
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO Executor: Running task 3.0 in stage 2.0 (TID 9)
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO Executor: Running task 0.0 in stage 2.0 (TID 6)
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO Executor: Running task 2.0 in stage 2.0 (TID 8)
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_1.csv, range: 0-8164356, partition values: [empty row]
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_0.csv, range: 0-7859637, partition values: [empty row]
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_3.csv, range: 0-7712365, partition values: [empty row]
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_4.csv, range: 0-7878939, partition values: [empty row]
2022.02.12 16:01:32 ERROR 22/02/12 16:01:33 INFO CodeGenerator: Code generated in 17.698412 ms
2022.02.12 16:01:34 ERROR 22/02/12 16:01:34 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 192.168.178.30:61271 in memory (size: 7.5 KiB, free: 2.2 GiB)
2022.02.12 16:01:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:01:39 INFO  time: compiled spark-tutorial in 1.9s
2022.02.12 16:01:40 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:01:40 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:01:40 INFO  time: compiled spark-tutorial in 0.36s
2022.02.12 16:01:42 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:01:42 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:01:44 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO MemoryStore: Block rdd_13_2 stored as values in memory (estimated size 1426.8 KiB, free 2.2 GiB)
2022.02.12 16:01:44 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO BlockManagerInfo: Added rdd_13_2 in memory on 192.168.178.30:61271 (size: 1426.8 KiB, free: 2.2 GiB)
2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO MemoryStore: Block rdd_13_1 stored as values in memory (estimated size 1032.8 KiB, free 2.2 GiB)
2022.02.12 16:01:44 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO BlockManagerInfo: Added rdd_13_1 in memory on 192.168.178.30:61271 (size: 1032.8 KiB, free: 2.2 GiB)
2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO CodeGenerator: Code generated in 11.483185 ms
2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 1616.6 KiB, free 2.2 GiB)
2022.02.12 16:01:44 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO BlockManagerInfo: Added rdd_13_0 in memory on 192.168.178.30:61271 (size: 1616.6 KiB, free: 2.2 GiB)
2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO CodeGenerator: Code generated in 64.358295 ms
2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO MemoryStore: Block rdd_13_3 stored as values in memory (estimated size 1430.9 KiB, free 2.2 GiB)
2022.02.12 16:01:44 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO Executor: Finished task 1.0 in stage 2.0 (TID 7). 2220 bytes result sent to driver
2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO Executor: Finished task 0.0 in stage 2.0 (TID 6). 2220 bytes result sent to driver
2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO Executor: Finished task 2.0 in stage 2.0 (TID 8). 2220 bytes result sent to driver
2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 10, 192.168.178.30, executor driver, partition 4, PROCESS_LOCAL, 7766 bytes)
2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 7) in 11332 ms on 192.168.178.30 (executor driver) (1/5)
2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 8) in 11332 ms on 192.168.178.30 (executor driver) (2/5)
2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 6) in 11335 ms on 192.168.178.30 (executor driver) (3/5)
2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO Executor: Running task 4.0 in stage 2.0 (TID 10)
2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO BlockManagerInfo: Added rdd_13_3 in memory on 192.168.178.30:61271 (size: 1430.9 KiB, free: 2.2 GiB)
2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/Test_Input_Spark/part_2.csv, range: 0-7541576, partition values: [empty row]
2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO Executor: Finished task 3.0 in stage 2.0 (TID 9). 2220 bytes result sent to driver
2022.02.12 16:01:44 ERROR 22/02/12 16:01:44 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 9) in 11373 ms on 192.168.178.30 (executor driver) (4/5)
2022.02.12 16:01:44 INFO  time: compiled spark-tutorial in 0.59s
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO MemoryStore: Block rdd_13_4 stored as values in memory (estimated size 855.6 KiB, free 2.2 GiB)
2022.02.12 16:01:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO BlockManagerInfo: Added rdd_13_4 in memory on 192.168.178.30:61271 (size: 855.6 KiB, free: 2.2 GiB)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO Executor: Finished task 4.0 in stage 2.0 (TID 10). 2177 bytes result sent to driver
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 10) in 7818 ms on 192.168.178.30 (executor driver) (5/5)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO DAGScheduler: ShuffleMapStage 2 (count at DBSIISparkExerciseMain.scala:24) finished in 19,202 s
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO DAGScheduler: looking for newly runnable stages
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO DAGScheduler: running: Set()
2022.02.12 16:01:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO DAGScheduler: waiting: Set(ResultStage 3)
2022.02.12 16:01:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO DAGScheduler: failed: Set()
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at count at DBSIISparkExerciseMain.scala:24), which has no missing parents
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 10.1 KiB, free 2.2 GiB)
2022.02.12 16:01:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 2.2 GiB)
2022.02.12 16:01:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 192.168.178.30:61271 (size: 5.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1200
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at count at DBSIISparkExerciseMain.scala:24) (first 15 tasks are for partitions Vector(0))
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 11, 192.168.178.30, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO Executor: Running task 0.0 in stage 3.0 (TID 11)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO ShuffleBlockFetcherIterator: Getting 5 (300.0 B) non-empty blocks including 5 (300.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO Executor: Finished task 0.0 in stage 3.0 (TID 11). 2648 bytes result sent to driver
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 11) in 103 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO DAGScheduler: ResultStage 3 (count at DBSIISparkExerciseMain.scala:24) finished in 0,121 s
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO DAGScheduler: Job 2 finished: count at DBSIISparkExerciseMain.scala:24, took 19,399703 s
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO CodeGenerator: Code generated in 36.216877 ms
2022.02.12 16:01:52 ERROR 22/02/12 16:01:52 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO CodeGenerator: Code generated in 64.400513 ms
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO CodeGenerator: Code generated in 33.122048 ms
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO CodeGenerator: Code generated in 20.29417 ms
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO SparkContext: Starting job: collect at Exercise_3a.scala:22
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO DAGScheduler: Registering RDD 24 (collect at Exercise_3a.scala:22) as input to shuffle 1
2022.02.12 16:01:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO DAGScheduler: Got job 3 (collect at Exercise_3a.scala:22) with 8 output partitions
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO DAGScheduler: Final stage: ResultStage 5 (collect at Exercise_3a.scala:22)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[24] at collect at Exercise_3a.scala:22), which has no missing parents
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 42.8 KiB, free 2.2 GiB)
2022.02.12 16:01:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 16.9 KiB, free 2.2 GiB)
2022.02.12 16:01:52 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 192.168.178.30:61271 (size: 16.9 KiB, free: 2.2 GiB)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1200
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[24] at collect at Exercise_3a.scala:22) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 12, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7766 bytes)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 13, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7766 bytes)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 14, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 7766 bytes)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 15, 192.168.178.30, executor driver, partition 3, PROCESS_LOCAL, 7766 bytes)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO Executor: Running task 1.0 in stage 4.0 (TID 13)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO Executor: Running task 2.0 in stage 4.0 (TID 14)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO Executor: Running task 3.0 in stage 4.0 (TID 15)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO Executor: Running task 0.0 in stage 4.0 (TID 12)
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO BlockManager: Found block rdd_13_3 locally
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO BlockManager: Found block rdd_13_1 locally
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO BlockManager: Found block rdd_13_0 locally
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO BlockManager: Found block rdd_13_2 locally
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO CodeGenerator: Code generated in 29.989495 ms
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO CodeGenerator: Code generated in 15.026826 ms
2022.02.12 16:01:52 ERROR 22/02/12 16:01:53 INFO CodeGenerator: Code generated in 9.290665 ms
2022.02.12 16:01:53 ERROR 22/02/12 16:01:53 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 192.168.178.30:61271 in memory (size: 5.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 192.168.178.30:61271 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 192.168.178.30:61271 in memory (size: 15.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO Executor: Finished task 0.0 in stage 4.0 (TID 12). 2465 bytes result sent to driver
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 16, 192.168.178.30, executor driver, partition 4, PROCESS_LOCAL, 7766 bytes)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO Executor: Finished task 1.0 in stage 4.0 (TID 13). 2465 bytes result sent to driver
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 12) in 796 ms on 192.168.178.30 (executor driver) (1/5)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 13) in 796 ms on 192.168.178.30 (executor driver) (2/5)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO Executor: Running task 4.0 in stage 4.0 (TID 16)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO Executor: Finished task 3.0 in stage 4.0 (TID 15). 2465 bytes result sent to driver
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 15) in 813 ms on 192.168.178.30 (executor driver) (3/5)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO Executor: Finished task 2.0 in stage 4.0 (TID 14). 2465 bytes result sent to driver
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO BlockManager: Found block rdd_13_4 locally
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 14) in 817 ms on 192.168.178.30 (executor driver) (4/5)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO Executor: Finished task 4.0 in stage 4.0 (TID 16). 2422 bytes result sent to driver
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 16) in 91 ms on 192.168.178.30 (executor driver) (5/5)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO DAGScheduler: ShuffleMapStage 4 (collect at Exercise_3a.scala:22) finished in 0,915 s
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO DAGScheduler: looking for newly runnable stages
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO DAGScheduler: running: Set()
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO DAGScheduler: waiting: Set(ResultStage 5)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO DAGScheduler: failed: Set()
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at collect at Exercise_3a.scala:22), which has no missing parents
2022.02.12 16:01:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 47.3 KiB, free 2.2 GiB)
2022.02.12 16:01:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 18.7 KiB, free 2.2 GiB)
2022.02.12 16:01:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 192.168.178.30:61271 (size: 18.7 KiB, free: 2.2 GiB)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1200
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at collect at Exercise_3a.scala:22) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSchedulerImpl: Adding task set 5.0 with 8 tasks
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 17, 192.168.178.30, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 18, 192.168.178.30, executor driver, partition 1, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 19, 192.168.178.30, executor driver, partition 2, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 20, 192.168.178.30, executor driver, partition 3, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO Executor: Running task 3.0 in stage 5.0 (TID 20)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO Executor: Running task 1.0 in stage 5.0 (TID 18)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO Executor: Running task 2.0 in stage 5.0 (TID 19)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO Executor: Running task 0.0 in stage 5.0 (TID 17)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO ShuffleBlockFetcherIterator: Getting 3 (333.0 B) non-empty blocks including 3 (333.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO ShuffleBlockFetcherIterator: Getting 5 (466.0 B) non-empty blocks including 5 (466.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO ShuffleBlockFetcherIterator: Getting 3 (331.0 B) non-empty blocks including 3 (331.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO ShuffleBlockFetcherIterator: Getting 4 (406.0 B) non-empty blocks including 4 (406.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
2022.02.12 16:01:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO Executor: Finished task 0.0 in stage 5.0 (TID 17). 4116 bytes result sent to driver
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO Executor: Finished task 3.0 in stage 5.0 (TID 20). 4214 bytes result sent to driver
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO Executor: Finished task 1.0 in stage 5.0 (TID 18). 4165 bytes result sent to driver
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 21, 192.168.178.30, executor driver, partition 4, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO Executor: Running task 4.0 in stage 5.0 (TID 21)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 22, 192.168.178.30, executor driver, partition 5, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 17) in 518 ms on 192.168.178.30 (executor driver) (1/8)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 23, 192.168.178.30, executor driver, partition 6, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 20) in 519 ms on 192.168.178.30 (executor driver) (2/8)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 18) in 520 ms on 192.168.178.30 (executor driver) (3/8)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO Executor: Running task 6.0 in stage 5.0 (TID 23)
2022.02.12 16:01:53 ERROR 22/02/12 16:01:54 INFO Executor: Running task 5.0 in stage 5.0 (TID 22)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO ShuffleBlockFetcherIterator: Getting 2 (177.0 B) non-empty blocks including 2 (177.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO ShuffleBlockFetcherIterator: Getting 4 (386.0 B) non-empty blocks including 4 (386.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO Executor: Finished task 2.0 in stage 5.0 (TID 19). 4073 bytes result sent to driver
2022.02.12 16:01:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 24, 192.168.178.30, executor driver, partition 7, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 19) in 541 ms on 192.168.178.30 (executor driver) (4/8)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO ShuffleBlockFetcherIterator: Getting 4 (354.0 B) non-empty blocks including 4 (354.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO Executor: Running task 7.0 in stage 5.0 (TID 24)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO Executor: Finished task 4.0 in stage 5.0 (TID 21). 3877 bytes result sent to driver
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 21) in 32 ms on 192.168.178.30 (executor driver) (5/8)
2022.02.12 16:01:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO Executor: Finished task 6.0 in stage 5.0 (TID 23). 4024 bytes result sent to driver
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 23) in 50 ms on 192.168.178.30 (executor driver) (6/8)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO ShuffleBlockFetcherIterator: Getting 5 (491.0 B) non-empty blocks including 5 (491.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
2022.02.12 16:01:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO Executor: Finished task 5.0 in stage 5.0 (TID 22). 4122 bytes result sent to driver
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 22) in 71 ms on 192.168.178.30 (executor driver) (7/8)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO Executor: Finished task 7.0 in stage 5.0 (TID 24). 4171 bytes result sent to driver
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 24) in 64 ms on 192.168.178.30 (executor driver) (8/8)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO DAGScheduler: ResultStage 5 (collect at Exercise_3a.scala:22) finished in 0,643 s
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO DAGScheduler: Job 3 finished: collect at Exercise_3a.scala:22, took 1,586810 s
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO SparkContext: Starting job: collect at Exercise_3a.scala:22
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO DAGScheduler: Registering RDD 30 (collect at Exercise_3a.scala:22) as input to shuffle 2
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO DAGScheduler: Got job 4 (collect at Exercise_3a.scala:22) with 8 output partitions
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO DAGScheduler: Final stage: ResultStage 8 (collect at Exercise_3a.scala:22)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
2022.02.12 16:01:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[30] at collect at Exercise_3a.scala:22), which has no missing parents
2022.02.12 16:01:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 48.2 KiB, free 2.2 GiB)
2022.02.12 16:01:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 19.2 KiB, free 2.2 GiB)
2022.02.12 16:01:54 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 192.168.178.30:61271 (size: 19.2 KiB, free: 2.2 GiB)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1200
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[30] at collect at Exercise_3a.scala:22) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO TaskSchedulerImpl: Adding task set 7.0 with 8 tasks
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 25, 192.168.178.30, executor driver, partition 0, NODE_LOCAL, 7314 bytes)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 26, 192.168.178.30, executor driver, partition 1, NODE_LOCAL, 7314 bytes)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 27, 192.168.178.30, executor driver, partition 2, NODE_LOCAL, 7314 bytes)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 28, 192.168.178.30, executor driver, partition 3, NODE_LOCAL, 7314 bytes)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO Executor: Running task 1.0 in stage 7.0 (TID 26)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO Executor: Running task 3.0 in stage 7.0 (TID 28)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO Executor: Running task 0.0 in stage 7.0 (TID 25)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:54 INFO Executor: Running task 2.0 in stage 7.0 (TID 27)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:55 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 192.168.178.30:61271 in memory (size: 16.9 KiB, free: 2.2 GiB)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:55 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 192.168.178.30:61271 in memory (size: 18.7 KiB, free: 2.2 GiB)
2022.02.12 16:01:54 ERROR 22/02/12 16:01:55 INFO ShuffleBlockFetcherIterator: Getting 4 (406.0 B) non-empty blocks including 4 (406.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:54 ERROR 22/02/12 16:01:55 INFO ShuffleBlockFetcherIterator: Getting 3 (333.0 B) non-empty blocks including 3 (333.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO ShuffleBlockFetcherIterator: Getting 5 (466.0 B) non-empty blocks including 5 (466.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO ShuffleBlockFetcherIterator: Getting 3 (331.0 B) non-empty blocks including 3 (331.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO Executor: Finished task 2.0 in stage 7.0 (TID 27). 3797 bytes result sent to driver
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 29, 192.168.178.30, executor driver, partition 4, NODE_LOCAL, 7314 bytes)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 27) in 836 ms on 192.168.178.30 (executor driver) (1/8)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO Executor: Running task 4.0 in stage 7.0 (TID 29)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO Executor: Finished task 1.0 in stage 7.0 (TID 26). 3797 bytes result sent to driver
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 30, 192.168.178.30, executor driver, partition 5, NODE_LOCAL, 7314 bytes)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 26) in 840 ms on 192.168.178.30 (executor driver) (2/8)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO Executor: Running task 5.0 in stage 7.0 (TID 30)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO ShuffleBlockFetcherIterator: Getting 2 (177.0 B) non-empty blocks including 2 (177.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO ShuffleBlockFetcherIterator: Getting 4 (386.0 B) non-empty blocks including 4 (386.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO Executor: Finished task 0.0 in stage 7.0 (TID 25). 3797 bytes result sent to driver
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 31, 192.168.178.30, executor driver, partition 6, NODE_LOCAL, 7314 bytes)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 25) in 865 ms on 192.168.178.30 (executor driver) (3/8)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO Executor: Finished task 3.0 in stage 7.0 (TID 28). 3797 bytes result sent to driver
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO Executor: Running task 6.0 in stage 7.0 (TID 31)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 32, 192.168.178.30, executor driver, partition 7, NODE_LOCAL, 7314 bytes)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 28) in 864 ms on 192.168.178.30 (executor driver) (4/8)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO Executor: Finished task 4.0 in stage 7.0 (TID 29). 3797 bytes result sent to driver
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO Executor: Running task 7.0 in stage 7.0 (TID 32)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 29) in 31 ms on 192.168.178.30 (executor driver) (5/8)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO ShuffleBlockFetcherIterator: Getting 4 (354.0 B) non-empty blocks including 4 (354.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO ShuffleBlockFetcherIterator: Getting 5 (491.0 B) non-empty blocks including 5 (491.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO Executor: Finished task 6.0 in stage 7.0 (TID 31). 3797 bytes result sent to driver
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO Executor: Finished task 5.0 in stage 7.0 (TID 30). 3797 bytes result sent to driver
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 31) in 61 ms on 192.168.178.30 (executor driver) (6/8)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 30) in 85 ms on 192.168.178.30 (executor driver) (7/8)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO Executor: Finished task 7.0 in stage 7.0 (TID 32). 3797 bytes result sent to driver
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 32) in 70 ms on 192.168.178.30 (executor driver) (8/8)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO DAGScheduler: ShuffleMapStage 7 (collect at Exercise_3a.scala:22) finished in 0,984 s
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO DAGScheduler: looking for newly runnable stages
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO DAGScheduler: running: Set()
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO DAGScheduler: waiting: Set(ResultStage 8)
2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO DAGScheduler: failed: Set()
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[33] at collect at Exercise_3a.scala:22), which has no missing parents
2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 45.3 KiB, free 2.2 GiB)
2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 17.9 KiB, free 2.2 GiB)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 192.168.178.30:61271 (size: 17.9 KiB, free: 2.2 GiB)
2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1200
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 8 (MapPartitionsRDD[33] at collect at Exercise_3a.scala:22) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSchedulerImpl: Adding task set 8.0 with 8 tasks
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 33, 192.168.178.30, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 34, 192.168.178.30, executor driver, partition 1, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 35, 192.168.178.30, executor driver, partition 2, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 36, 192.168.178.30, executor driver, partition 3, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO Executor: Running task 1.0 in stage 8.0 (TID 34)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO Executor: Running task 2.0 in stage 8.0 (TID 35)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO Executor: Running task 3.0 in stage 8.0 (TID 36)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:55 INFO Executor: Running task 0.0 in stage 8.0 (TID 33)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO ShuffleBlockFetcherIterator: Getting 4 (371.0 B) non-empty blocks including 4 (371.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO ShuffleBlockFetcherIterator: Getting 5 (451.0 B) non-empty blocks including 5 (451.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO ShuffleBlockFetcherIterator: Getting 6 (497.0 B) non-empty blocks including 6 (497.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO ShuffleBlockFetcherIterator: Getting 4 (374.0 B) non-empty blocks including 4 (374.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO CodeGenerator: Code generated in 15.495345 ms
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO Executor: Finished task 0.0 in stage 8.0 (TID 33). 4634 bytes result sent to driver
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO Executor: Finished task 2.0 in stage 8.0 (TID 35). 4627 bytes result sent to driver
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO Executor: Finished task 3.0 in stage 8.0 (TID 36). 4629 bytes result sent to driver
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 37, 192.168.178.30, executor driver, partition 4, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO Executor: Running task 4.0 in stage 8.0 (TID 37)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 38, 192.168.178.30, executor driver, partition 5, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 33) in 516 ms on 192.168.178.30 (executor driver) (1/8)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 35) in 515 ms on 192.168.178.30 (executor driver) (2/8)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO Executor: Running task 5.0 in stage 8.0 (TID 38)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 39, 192.168.178.30, executor driver, partition 6, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 36) in 516 ms on 192.168.178.30 (executor driver) (3/8)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO Executor: Running task 6.0 in stage 8.0 (TID 39)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO Executor: Finished task 1.0 in stage 8.0 (TID 34). 4667 bytes result sent to driver
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 40, 192.168.178.30, executor driver, partition 7, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 34) in 524 ms on 192.168.178.30 (executor driver) (4/8)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO ShuffleBlockFetcherIterator: Getting 5 (434.0 B) non-empty blocks including 5 (434.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO Executor: Running task 7.0 in stage 8.0 (TID 40)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO ShuffleBlockFetcherIterator: Getting 4 (374.0 B) non-empty blocks including 4 (374.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO ShuffleBlockFetcherIterator: Getting 5 (434.0 B) non-empty blocks including 5 (434.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO ShuffleBlockFetcherIterator: Getting 6 (497.0 B) non-empty blocks including 6 (497.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO Executor: Finished task 4.0 in stage 8.0 (TID 37). 4628 bytes result sent to driver
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO Executor: Finished task 6.0 in stage 8.0 (TID 39). 4633 bytes result sent to driver
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 39) in 26 ms on 192.168.178.30 (executor driver) (5/8)
2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO Executor: Finished task 5.0 in stage 8.0 (TID 38). 4631 bytes result sent to driver
2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO Executor: Finished task 7.0 in stage 8.0 (TID 40). 4630 bytes result sent to driver
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 40) in 39 ms on 192.168.178.30 (executor driver) (6/8)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 38) in 49 ms on 192.168.178.30 (executor driver) (7/8)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 37) in 52 ms on 192.168.178.30 (executor driver) (8/8)
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO DAGScheduler: ResultStage 8 (collect at Exercise_3a.scala:22) finished in 0,588 s
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO DAGScheduler: Job 4 finished: collect at Exercise_3a.scala:22, took 1,595197 s
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO CodeGenerator: Code generated in 11.785189 ms
2022.02.12 16:01:55 ERROR 22/02/12 16:01:56 INFO CodeGenerator: Code generated in 37.090546 ms
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO CodeGenerator: Code generated in 53.119952 ms
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO SparkContext: Starting job: collect at Exercise_3b.scala:19
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO DAGScheduler: Registering RDD 37 (collect at Exercise_3b.scala:19) as input to shuffle 3
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO DAGScheduler: Got job 5 (collect at Exercise_3b.scala:19) with 8 output partitions
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO DAGScheduler: Final stage: ResultStage 10 (collect at Exercise_3b.scala:19)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
2022.02.12 16:01:56 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:56 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[37] at collect at Exercise_3b.scala:19), which has no missing parents
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 48.7 KiB, free 2.2 GiB)
2022.02.12 16:01:56 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 19.6 KiB, free 2.2 GiB)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 192.168.178.30:61271 (size: 19.6 KiB, free: 2.2 GiB)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1200
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[37] at collect at Exercise_3b.scala:19) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO TaskSchedulerImpl: Adding task set 9.0 with 5 tasks
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 41, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7766 bytes)
2022.02.12 16:01:56 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 42, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7766 bytes)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 43, 192.168.178.30, executor driver, partition 2, PROCESS_LOCAL, 7766 bytes)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 44, 192.168.178.30, executor driver, partition 3, PROCESS_LOCAL, 7766 bytes)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO Executor: Running task 0.0 in stage 9.0 (TID 41)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO Executor: Running task 2.0 in stage 9.0 (TID 43)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO Executor: Running task 3.0 in stage 9.0 (TID 44)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:56 INFO Executor: Running task 1.0 in stage 9.0 (TID 42)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO BlockManager: Found block rdd_13_2 locally
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO BlockManager: Found block rdd_13_3 locally
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO BlockManager: Found block rdd_13_0 locally
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO BlockManager: Found block rdd_13_1 locally
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 192.168.178.30:61271 in memory (size: 19.2 KiB, free: 2.2 GiB)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 192.168.178.30:61271 in memory (size: 17.9 KiB, free: 2.2 GiB)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO CodeGenerator: Code generated in 11.567647 ms
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO CodeGenerator: Code generated in 137.729252 ms
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO Executor: Finished task 0.0 in stage 9.0 (TID 41). 2465 bytes result sent to driver
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO Executor: Finished task 3.0 in stage 9.0 (TID 44). 2465 bytes result sent to driver
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 45, 192.168.178.30, executor driver, partition 4, PROCESS_LOCAL, 7766 bytes)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO Executor: Finished task 1.0 in stage 9.0 (TID 42). 2465 bytes result sent to driver
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO Executor: Running task 4.0 in stage 9.0 (TID 45)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 44) in 705 ms on 192.168.178.30 (executor driver) (1/5)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 42) in 707 ms on 192.168.178.30 (executor driver) (2/5)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 41) in 707 ms on 192.168.178.30 (executor driver) (3/5)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO BlockManager: Found block rdd_13_4 locally
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO Executor: Finished task 2.0 in stage 9.0 (TID 43). 2465 bytes result sent to driver
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 43) in 717 ms on 192.168.178.30 (executor driver) (4/5)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO Executor: Finished task 4.0 in stage 9.0 (TID 45). 2465 bytes result sent to driver
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 45) in 69 ms on 192.168.178.30 (executor driver) (5/5)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
2022.02.12 16:01:56 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:56 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:56 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO DAGScheduler: ShuffleMapStage 9 (collect at Exercise_3b.scala:19) finished in 0,798 s
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO DAGScheduler: looking for newly runnable stages
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO DAGScheduler: running: Set()
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO DAGScheduler: waiting: Set(ResultStage 10)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO DAGScheduler: failed: Set()
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[40] at collect at Exercise_3b.scala:19), which has no missing parents
2022.02.12 16:01:56 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 55.9 KiB, free 2.2 GiB)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 21.5 KiB, free 2.2 GiB)
2022.02.12 16:01:56 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 192.168.178.30:61271 (size: 21.5 KiB, free: 2.2 GiB)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1200
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO DAGScheduler: Submitting 8 missing tasks from ResultStage 10 (MapPartitionsRDD[40] at collect at Exercise_3b.scala:19) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO TaskSchedulerImpl: Adding task set 10.0 with 8 tasks
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 46, 192.168.178.30, executor driver, partition 0, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 47, 192.168.178.30, executor driver, partition 1, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 48, 192.168.178.30, executor driver, partition 2, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 49, 192.168.178.30, executor driver, partition 3, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO Executor: Running task 3.0 in stage 10.0 (TID 49)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO Executor: Running task 1.0 in stage 10.0 (TID 47)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO Executor: Running task 2.0 in stage 10.0 (TID 48)
2022.02.12 16:01:56 ERROR 22/02/12 16:01:57 INFO Executor: Running task 0.0 in stage 10.0 (TID 46)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO ShuffleBlockFetcherIterator: Getting 3 (364.0 B) non-empty blocks including 3 (364.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO ShuffleBlockFetcherIterator: Getting 5 (518.0 B) non-empty blocks including 5 (518.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO ShuffleBlockFetcherIterator: Getting 4 (461.0 B) non-empty blocks including 4 (461.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO ShuffleBlockFetcherIterator: Getting 3 (375.0 B) non-empty blocks including 3 (375.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Finished task 0.0 in stage 10.0 (TID 46). 3732 bytes result sent to driver
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Finished task 2.0 in stage 10.0 (TID 48). 3734 bytes result sent to driver
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Finished task 1.0 in stage 10.0 (TID 47). 3762 bytes result sent to driver
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Finished task 3.0 in stage 10.0 (TID 49). 3784 bytes result sent to driver
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 50, 192.168.178.30, executor driver, partition 4, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 51, 192.168.178.30, executor driver, partition 5, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Running task 4.0 in stage 10.0 (TID 50)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Running task 5.0 in stage 10.0 (TID 51)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO ShuffleBlockFetcherIterator: Getting 4 (430.0 B) non-empty blocks including 4 (430.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 52, 192.168.178.30, executor driver, partition 6, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 53, 192.168.178.30, executor driver, partition 7, NODE_LOCAL, 7325 bytes)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 46) in 476 ms on 192.168.178.30 (executor driver) (1/8)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO ShuffleBlockFetcherIterator: Getting 2 (194.0 B) non-empty blocks including 2 (194.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 49) in 475 ms on 192.168.178.30 (executor driver) (2/8)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 48) in 476 ms on 192.168.178.30 (executor driver) (3/8)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Running task 6.0 in stage 10.0 (TID 52)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 47) in 478 ms on 192.168.178.30 (executor driver) (4/8)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Running task 7.0 in stage 10.0 (TID 53)
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO ShuffleBlockFetcherIterator: Getting 4 (388.0 B) non-empty blocks including 4 (388.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO ShuffleBlockFetcherIterator: Getting 5 (540.0 B) non-empty blocks including 5 (540.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Finished task 6.0 in stage 10.0 (TID 52). 3716 bytes result sent to driver
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 52) in 35 ms on 192.168.178.30 (executor driver) (5/8)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Finished task 7.0 in stage 10.0 (TID 53). 3775 bytes result sent to driver
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 53) in 30 ms on 192.168.178.30 (executor driver) (6/8)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Finished task 4.0 in stage 10.0 (TID 50). 3638 bytes result sent to driver
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Finished task 5.0 in stage 10.0 (TID 51). 3757 bytes result sent to driver
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 50) in 57 ms on 192.168.178.30 (executor driver) (7/8)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 51) in 57 ms on 192.168.178.30 (executor driver) (8/8)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: ResultStage 10 (collect at Exercise_3b.scala:19) finished in 0,558 s
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Job 5 finished: collect at Exercise_3b.scala:19, took 1,377589 s
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO CodeGenerator: Code generated in 13.421771 ms
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO InMemoryFileIndex: It took 1 ms to list leaf files for 1 paths.
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO InMemoryFileIndex: It took 4 ms to list leaf files for 2 paths.
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#357, None)) > 0)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 192.168.178.30:61271 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO SparkContext: Created broadcast 13 from load at IOHelper.scala:41
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Got job 6 (load at IOHelper.scala:41) with 1 output partitions
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Final stage: ResultStage 11 (load at IOHelper.scala:41)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Missing parents: List()
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[44] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 192.168.178.30:61271 (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1200
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[44] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0))
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 54, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7768 bytes)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Running task 0.0 in stage 11.0 (TID 54)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/data/exercise1.csv, range: 0-570, partition values: [empty row]
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Finished task 0.0 in stage 11.0 (TID 54). 1532 bytes result sent to driver
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 54) in 11 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: ResultStage 11 (load at IOHelper.scala:41) finished in 0,021 s
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Job 6 finished: load at IOHelper.scala:41, took 0,027534 s
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 192.168.178.30:61271 in memory (size: 21.5 KiB, free: 2.2 GiB)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 192.168.178.30:61271 in memory (size: 19.6 KiB, free: 2.2 GiB)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 192.168.178.30:61271 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO SparkContext: Created broadcast 15 from load at IOHelper.scala:41
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Got job 7 (load at IOHelper.scala:41) with 2 output partitions
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Final stage: ResultStage 12 (load at IOHelper.scala:41)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Missing parents: List()
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[50] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 15.0 KiB, free 2.2 GiB)
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 2.2 GiB)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 192.168.178.30:61271 (size: 7.5 KiB, free: 2.2 GiB)
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1200
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 12 (MapPartitionsRDD[50] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0, 1))
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSchedulerImpl: Adding task set 12.0 with 2 tasks
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 55, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7768 bytes)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 56, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7768 bytes)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Running task 1.0 in stage 12.0 (TID 56)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Running task 0.0 in stage 12.0 (TID 55)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/data/exercise1.csv, range: 0-570, partition values: [empty row]
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/data/exercise1.csv, range: 0-570, partition values: [empty row]
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Finished task 1.0 in stage 12.0 (TID 56). 1590 bytes result sent to driver
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 56) in 18 ms on 192.168.178.30 (executor driver) (1/2)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO Executor: Finished task 0.0 in stage 12.0 (TID 55). 1590 bytes result sent to driver
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 55) in 20 ms on 192.168.178.30 (executor driver) (2/2)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: ResultStage 12 (load at IOHelper.scala:41) finished in 0,049 s
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO DAGScheduler: Job 7 finished: load at IOHelper.scala:41, took 0,084061 s
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string>
2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:58 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 192.168.178.30:61271 in memory (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 192.168.178.30:61271 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO SparkContext: Created broadcast 17 from collect at ResultChecker.scala:13
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO SparkContext: Starting job: collect at ResultChecker.scala:13
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Got job 8 (collect at ResultChecker.scala:13) with 1 output partitions
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Final stage: ResultStage 13 (collect at ResultChecker.scala:13)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Missing parents: List()
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[53] at collect at ResultChecker.scala:13), which has no missing parents
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 8.8 KiB, free 2.2 GiB)
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.8 KiB, free 2.2 GiB)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 192.168.178.30:61271 (size: 4.8 KiB, free: 2.2 GiB)
2022.02.12 16:01:58 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1200
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[53] at collect at ResultChecker.scala:13) (first 15 tasks are for partitions Vector(0))
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 57, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7768 bytes)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO Executor: Running task 0.0 in stage 13.0 (TID 57)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/data/exercise1.csv, range: 0-570, partition values: [empty row]
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO Executor: Finished task 0.0 in stage 13.0 (TID 57). 2260 bytes result sent to driver
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 57) in 29 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO DAGScheduler: ResultStage 13 (collect at ResultChecker.scala:13) finished in 0,036 s
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Job 8 finished: collect at ResultChecker.scala:13, took 0,044703 s
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
2022.02.12 16:01:58 ERROR 22/02/12 16:01:59 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 2 paths.
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 192.168.178.30:61271 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 192.168.178.30:61271 in memory (size: 7.5 KiB, free: 2.2 GiB)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 192.168.178.30:61271 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#379, None)) > 0)
2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 192.168.178.30:61271 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO SparkContext: Created broadcast 19 from load at IOHelper.scala:41
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Got job 9 (load at IOHelper.scala:41) with 1 output partitions
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Final stage: ResultStage 14 (load at IOHelper.scala:41)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Missing parents: List()
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[57] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 10.7 KiB, free 2.2 GiB)
2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 5.3 KiB, free 2.2 GiB)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 192.168.178.30:61271 (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1200
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[57] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0))
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 58, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7768 bytes)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO Executor: Running task 0.0 in stage 14.0 (TID 58)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/data/exercise2.csv, range: 0-723, partition values: [empty row]
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO Executor: Finished task 0.0 in stage 14.0 (TID 58). 1532 bytes result sent to driver
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 58) in 11 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: ResultStage 14 (load at IOHelper.scala:41) finished in 0,059 s
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Job 9 finished: load at IOHelper.scala:41, took 0,085467 s
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 192.168.178.30:61271 in memory (size: 4.8 KiB, free: 2.2 GiB)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 192.168.178.30:61271 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO SparkContext: Created broadcast 21 from load at IOHelper.scala:41
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO SparkContext: Starting job: load at IOHelper.scala:41
2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Got job 10 (load at IOHelper.scala:41) with 2 output partitions
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Final stage: ResultStage 15 (load at IOHelper.scala:41)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Missing parents: List()
2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[63] at load at IOHelper.scala:41), which has no missing parents
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 15.0 KiB, free 2.2 GiB)
2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 2.2 GiB)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 192.168.178.30:61271 (size: 7.5 KiB, free: 2.2 GiB)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1200
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 15 (MapPartitionsRDD[63] at load at IOHelper.scala:41) (first 15 tasks are for partitions Vector(0, 1))
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO TaskSchedulerImpl: Adding task set 15.0 with 2 tasks
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 59, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7768 bytes)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 60, 192.168.178.30, executor driver, partition 1, PROCESS_LOCAL, 7768 bytes)
2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO Executor: Running task 1.0 in stage 15.0 (TID 60)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO Executor: Running task 0.0 in stage 15.0 (TID 59)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/data/exercise2.csv, range: 0-723, partition values: [empty row]
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/data/exercise2.csv, range: 0-723, partition values: [empty row]
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO Executor: Finished task 1.0 in stage 15.0 (TID 60). 1646 bytes result sent to driver
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 60) in 19 ms on 192.168.178.30 (executor driver) (1/2)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO Executor: Finished task 0.0 in stage 15.0 (TID 59). 1646 bytes result sent to driver
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 59) in 22 ms on 192.168.178.30 (executor driver) (2/2)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: ResultStage 15 (load at IOHelper.scala:41) finished in 0,037 s
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO DAGScheduler: Job 10 finished: load at IOHelper.scala:41, took 0,045699 s
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 192.168.178.30:61271 in memory (size: 5.3 KiB, free: 2.2 GiB)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 192.168.178.30:61271 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileSourceStrategy: Pruning directories with: 
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileSourceStrategy: Pushed Filters: 
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileSourceStrategy: Post-Scan Filters: 
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileSourceStrategy: Output Data Schema: struct<_c0: string, _c1: int>
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 171.2 KiB, free 2.2 GiB)
2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 192.168.178.30:61271 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 24.0 KiB, free 2.2 GiB)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 192.168.178.30:61271 (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO SparkContext: Created broadcast 23 from collect at ResultChecker.scala:21
2022.02.12 16:01:59 ERROR 22/02/12 16:01:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2022.02.12 16:01:59 ERROR 22/02/12 16:02:00 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 192.168.178.30:61271 in memory (size: 24.0 KiB, free: 2.2 GiB)
2022.02.12 16:01:59 ERROR 22/02/12 16:02:00 INFO SparkContext: Starting job: collect at ResultChecker.scala:21
2022.02.12 16:01:59 ERROR 22/02/12 16:02:00 INFO DAGScheduler: Got job 11 (collect at ResultChecker.scala:21) with 1 output partitions
2022.02.12 16:01:59 ERROR 22/02/12 16:02:00 INFO DAGScheduler: Final stage: ResultStage 16 (collect at ResultChecker.scala:21)
2022.02.12 16:01:59 ERROR 22/02/12 16:02:00 INFO DAGScheduler: Parents of final stage: List()
2022.02.12 16:01:59 ERROR 22/02/12 16:02:00 INFO DAGScheduler: Missing parents: List()
2022.02.12 16:01:59 ERROR 22/02/12 16:02:00 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[66] at collect at ResultChecker.scala:21), which has no missing parents
2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR 22/02/12 16:02:00 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 8.9 KiB, free 2.2 GiB)
2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR 22/02/12 16:02:00 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 4.9 KiB, free 2.2 GiB)
2022.02.12 16:01:59 ERROR 22/02/12 16:02:00 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 192.168.178.30:61271 (size: 4.9 KiB, free: 2.2 GiB)
2022.02.12 16:01:59 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:01:59 ERROR 22/02/12 16:02:00 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1200
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[66] at collect at ResultChecker.scala:21) (first 15 tasks are for partitions Vector(0))
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 61, 192.168.178.30, executor driver, partition 0, PROCESS_LOCAL, 7768 bytes)
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO Executor: Running task 0.0 in stage 16.0 (TID 61)
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 192.168.178.30:61271 in memory (size: 7.5 KiB, free: 2.2 GiB)
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO FileScanRDD: Reading File path: file:///Users/Johann/Documents/GitHub/spark-tutorial/data/exercise2.csv, range: 0-723, partition values: [empty row]
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO CodeGenerator: Code generated in 8.49389 ms
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO Executor: Finished task 0.0 in stage 16.0 (TID 61). 2492 bytes result sent to driver
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 61) in 23 ms on 192.168.178.30 (executor driver) (1/1)
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO DAGScheduler: ResultStage 16 (collect at ResultChecker.scala:21) finished in 0,280 s
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO DAGScheduler: Job 11 is finished. Cancelling potential speculative or zombie tasks for this job
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO TaskSchedulerImpl: Killing all running tasks in stage 16: Stage finished
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO DAGScheduler: Job 11 finished: collect at ResultChecker.scala:21, took 0,283850 s
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO CodeGenerator: Code generated in 8.746477 ms
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO SparkContext: Invoking stop() from shutdown hook
2022.02.12 16:02:00 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO SparkUI: Stopped Spark web UI at http://192.168.178.30:4040
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO MemoryStore: MemoryStore cleared
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO BlockManager: BlockManager stopped
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO BlockManagerMaster: BlockManagerMaster stopped
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO SparkContext: Successfully stopped SparkContext
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO ShutdownHookManager: Shutdown hook called
2022.02.12 16:02:00 ERROR 22/02/12 16:02:00 INFO ShutdownHookManager: Deleting directory /private/var/folders/b8/1fvxl6lx177dgms2svrcc93m0000gp/T/spark-3ab44030-8751-4d99-9538-ee710e33de2d
2022.02.12 16:02:00 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:02:00 INFO  Closing debug server tcp://0.0.0.0:61260
2022.02.12 16:02:10 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:02:10 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:02:14 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:02:14 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:02:15 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:02:15 INFO  time: compiled spark-tutorial in 0.24s
2022.02.12 16:02:31 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:02:31 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:02:33 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:02:33 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:02:33 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:02:33 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:02:34 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:02:34 INFO  time: compiled spark-tutorial in 0.23s
2022.02.12 16:02:35 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:02:35 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:02:36 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:02:36 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:02:36 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:02:37 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:02:37 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.12 16:02:38 INFO  time: compiled spark-tutorial in 1.97s
2022.02.12 16:02:38 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:02:39 INFO  time: compiled spark-tutorial in 0.52s
2022.02.12 16:02:39 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:02:41 INFO  time: compiled spark-tutorial in 0.73s
2022.02.12 16:03:03 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 16m 37.1s)
2022.02.12 16:03:03 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 16:03:05 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 16:03:05 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:03:08 INFO  Trying to attach to remote debuggee VM localhost:61353 .
2022.02.12 16:03:08 INFO  Attaching to debuggee VM succeeded.
2022.02.12 16:03:10 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 16:03:10 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 16:03:10 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 16:03:10 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 16:03:10 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 16:03:10 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 16:03:48 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:03:48 INFO  Closing debug server tcp://0.0.0.0:61347
2022.02.12 16:04:10 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:04:11 INFO  time: compiled spark-tutorial in 1.13s
2022.02.12 16:04:18 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:04:20 INFO  time: compiled spark-tutorial in 1.37s
2022.02.12 16:04:21 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:04:22 INFO  time: compiled spark-tutorial in 1.4s
2022.02.12 16:04:26 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:04:28 INFO  time: compiled spark-tutorial in 1.25s
2022.02.12 16:04:31 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:04:33 INFO  time: compiled spark-tutorial in 1.58s
2022.02.12 16:04:35 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:04:36 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:04:36 INFO  time: compiled spark-tutorial in 1.65s
2022.02.12 16:05:50 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:05:51 INFO  time: compiled spark-tutorial in 1.61s
2022.02.12 16:05:52 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:05:53 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:05:53 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:05:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:05:54 INFO  time: compiled spark-tutorial in 1.68s
2022.02.12 16:05:54 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:05:54 INFO  time: compiled spark-tutorial in 0.52s
2022.02.12 16:05:57 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:05:59 INFO  time: compiled spark-tutorial in 1.55s
2022.02.12 16:06:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:06:02 INFO  time: compiled spark-tutorial in 0.12s
2022.02.12 16:06:03 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:06:03 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:06:04 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:06:05 INFO  time: compiled spark-tutorial in 1.2s
2022.02.12 16:06:14 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 19m 47.424s)
2022.02.12 16:06:14 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 16:06:14 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 16:06:15 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:06:18 INFO  Trying to attach to remote debuggee VM localhost:61474 .
2022.02.12 16:06:18 INFO  Attaching to debuggee VM succeeded.
2022.02.12 16:06:20 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 16:06:20 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 16:06:20 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 16:06:20 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 16:06:20 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 16:06:20 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 16:06:50 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:06:53 INFO  time: compiled spark-tutorial in 2.77s
2022.02.12 16:06:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:06:55 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:06:55 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:06:56 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:06:56 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:06:57 INFO  time: compiled spark-tutorial in 2.05s
2022.02.12 16:07:06 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:07:07 INFO  time: compiled spark-tutorial in 1.53s
2022.02.12 16:07:16 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:07:16 INFO  Closing debug server tcp://0.0.0.0:61468
2022.02.12 16:08:46 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:08:47 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:08:48 INFO  time: compiled spark-tutorial in 1.55s
2022.02.12 16:08:48 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:08:48 INFO  time: compiled spark-tutorial in 83ms
2022.02.12 16:09:07 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:09:07 INFO  time: compiled spark-tutorial in 0.17s
2022.02.12 16:09:10 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:09:10 INFO  time: compiled spark-tutorial in 0.18s
2022.02.12 16:09:11 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala:21:26: stale bloop error: not found: value attributeName
      .groupBy("tableId",attributeName)
                         ^^^^^^^^^^^^^
2022.02.12 16:09:11 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala:21:26: stale bloop error: not found: value attributeName
      .groupBy("tableId",attributeName)
                         ^^^^^^^^^^^^^
2022.02.12 16:09:12 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala:21:26: stale bloop error: not found: value attributeName
      .groupBy("tableId",attributeName)
                         ^^^^^^^^^^^^^
2022.02.12 16:09:12 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:09:12 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala:21:40: stale bloop error: unclosed string literal
      .groupBy("tableId",attributeName")
                                       ^
2022.02.12 16:09:12 INFO  time: compiled spark-tutorial in 96ms
2022.02.12 16:09:13 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala:21:40: stale bloop error: unclosed string literal
      .groupBy("tableId",attributeName")
                                       ^
2022.02.12 16:09:13 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala:21:40: stale bloop error: unclosed string literal
      .groupBy("tableId",attributeName")
                                       ^
2022.02.12 16:09:14 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:09:16 INFO  time: compiled spark-tutorial in 1.55s
2022.02.12 16:11:21 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 24m 54.694s)
2022.02.12 16:11:21 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 16:11:21 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 16:11:22 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:11:26 INFO  Trying to attach to remote debuggee VM localhost:61615 .
2022.02.12 16:11:26 INFO  Attaching to debuggee VM succeeded.
2022.02.12 16:11:28 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 16:11:28 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 16:11:28 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 16:11:28 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 16:11:28 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 16:11:28 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 16:12:10 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 11.0 failed 1 times, most recent failure: Lost task 3.0 in stage 11.0 (TID 50, 192.168.178.30, executor driver): java.lang.ClassCastException: class java.lang.String cannot be cast to class java.lang.Long (java.lang.String and java.lang.Long are in module java.base of loader 'bootstrap')
2022.02.12 16:12:10 ERROR 	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.Row.getLong(Row.scala:251)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.Row.getLong$(Row.scala:251)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getLong(rows.scala:166)
2022.02.12 16:12:10 ERROR 	at de.hpi.dbsII_exercises.Exercise_3b.$anonfun$execute$1(Exercise_3b.scala:23)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.mapelements_doConsume_0$(Unknown Source)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeysOutput_0$(Unknown Source)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:340)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:872)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:872)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 16:12:10 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 16:12:10 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 16:12:10 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 16:12:10 ERROR 
2022.02.12 16:12:10 ERROR Driver stacktrace:
2022.02.12 16:12:10 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2023)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1972)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1971)
2022.02.12 16:12:10 ERROR 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
2022.02.12 16:12:10 ERROR 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
2022.02.12 16:12:10 ERROR 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1971)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:950)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:950)
2022.02.12 16:12:10 ERROR 	at scala.Option.foreach(Option.scala:407)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:950)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2203)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2152)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2141)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2133)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1004)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:388)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.rdd.RDD.collect(RDD.scala:1003)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:385)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3625)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:2938)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3616)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3614)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.Dataset.collect(Dataset.scala:2938)
2022.02.12 16:12:10 ERROR 	at de.hpi.dbsII_exercises.Exercise_3b.execute(Exercise_3b.scala:23)
2022.02.12 16:12:10 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:31)
2022.02.12 16:12:10 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:7)
2022.02.12 16:12:10 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.12 16:12:10 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.12 16:12:10 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.12 16:12:10 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.12 16:12:10 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.12 16:12:10 ERROR 	at scala.App.main(App.scala:80)
2022.02.12 16:12:10 ERROR 	at scala.App.main$(App.scala:78)
2022.02.12 16:12:10 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:7)
2022.02.12 16:12:10 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.12 16:12:10 ERROR Caused by: java.lang.ClassCastException: class java.lang.String cannot be cast to class java.lang.Long (java.lang.String and java.lang.Long are in module java.base of loader 'bootstrap')
2022.02.12 16:12:10 ERROR 	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.Row.getLong(Row.scala:251)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.Row.getLong$(Row.scala:251)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getLong(rows.scala:166)
2022.02.12 16:12:10 ERROR 	at de.hpi.dbsII_exercises.Exercise_3b.$anonfun$execute$1(Exercise_3b.scala:23)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.mapelements_doConsume_0$(Unknown Source)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeysOutput_0$(Unknown Source)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:340)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:872)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:872)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.12 16:12:10 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.12 16:12:10 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.12 16:12:10 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.12 16:12:10 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.12 16:12:11 INFO  Closing debug server tcp://0.0.0.0:61607
2022.02.12 16:12:14 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:13:25 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:13:27 INFO  time: compiled spark-tutorial in 1.28s
2022.02.12 16:15:19 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:15:20 INFO  time: compiled spark-tutorial in 1.39s
2022.02.12 16:15:23 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:15:24 INFO  time: compiled spark-tutorial in 1.13s
2022.02.12 16:15:27 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:15:27 INFO  time: compiled spark-tutorial in 0.22s
2022.02.12 16:15:32 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:15:32 INFO  time: compiled spark-tutorial in 0.25s
2022.02.12 16:15:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:15:37 INFO  time: compiled spark-tutorial in 0.3s
Feb. 12, 2022 4:15:59 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4470
2022.02.12 16:16:05 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:16:06 INFO  time: compiled spark-tutorial in 1.12s
2022.02.12 16:16:07 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:16:07 INFO  time: compiled spark-tutorial in 0.25s
2022.02.12 16:16:10 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:16:10 INFO  time: compiled spark-tutorial in 0.11s
2022.02.12 16:16:13 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:16:14 INFO  time: compiled spark-tutorial in 1.32s
2022.02.12 16:16:25 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 29m 58.557s)
2022.02.12 16:16:25 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 16:16:25 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 16:16:26 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:16:30 INFO  Trying to attach to remote debuggee VM localhost:61742 .
2022.02.12 16:16:30 INFO  Attaching to debuggee VM succeeded.
2022.02.12 16:16:31 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 16:16:31 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 16:16:31 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 16:16:31 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 16:16:31 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 16:16:31 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 16:16:35 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:16:38 INFO  time: compiled spark-tutorial in 3.4s
2022.02.12 16:16:38 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:16:39 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:16:39 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected')
                     ^
2022.02.12 16:16:39 INFO  time: compiled spark-tutorial in 0.24s
2022.02.12 16:16:41 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected')
                     ^
2022.02.12 16:16:41 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected')
                     ^
2022.02.12 16:16:41 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:16:41 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected')
                     ^
2022.02.12 16:16:41 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected')
                     ^
2022.02.12 16:16:41 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:16:41 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected')
                     ^
2022.02.12 16:16:41 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected')
                     ^
2022.02.12 16:16:41 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:16:42 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected')
                     ^
2022.02.12 16:16:43 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:16:43 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected')
                     ^
2022.02.12 16:16:43 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected')
                     ^
2022.02.12 16:16:43 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + )
                     ^
2022.02.12 16:16:43 INFO  time: compiled spark-tutorial in 0.24s
2022.02.12 16:16:43 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + )
                     ^
2022.02.12 16:16:42 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + )
                     ^
2022.02.12 16:16:43 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + )
                     ^
2022.02.12 16:16:43 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + )
                     ^
2022.02.12 16:16:43 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + )
                     ^
2022.02.12 16:16:43 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + )
                     ^
2022.02.12 16:16:42 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:16:44 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + )
                     ^
2022.02.12 16:16:44 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:16:44 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + expec)
                     ^
2022.02.12 16:16:44 INFO  time: compiled spark-tutorial in 0.25s
2022.02.12 16:16:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + expec)
                     ^
2022.02.12 16:16:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + expec)
                     ^
2022.02.12 16:16:45 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:16:46 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + expec)
                     ^
2022.02.12 16:16:46 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:16:46 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + expected)
                     ^
2022.02.12 16:16:46 INFO  time: compiled spark-tutorial in 0.21s
2022.02.12 16:16:49 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + expected)
                     ^
2022.02.12 16:16:49 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + expected)
                     ^
2022.02.12 16:16:49 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:16:49 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + expected)
                     ^
2022.02.12 16:16:50 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + expected)
                     ^
2022.02.12 16:16:49 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:16:51 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed character literal (or use " for string literal "expected")
    println('expected' + expected)
                     ^
2022.02.12 16:16:51 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:16:51 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed string literal
    println('expected" + expected)
                     ^
2022.02.12 16:16:51 INFO  time: compiled spark-tutorial in 0.15s
Feb. 12, 2022 4:16:54 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4638
2022.02.12 16:16:54 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed string literal
    println('expected" + expected)
                     ^
2022.02.12 16:16:54 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed string literal
    println('expected" + expected)
                     ^
2022.02.12 16:16:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:16:54 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed string literal
    println('expected" + expected)
                     ^
2022.02.12 16:16:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:16:54 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala:25:22: stale bloop error: unclosed string literal
    println('expected" + expected)
                     ^
2022.02.12 16:16:55 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:16:56 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:16:58 INFO  time: compiled spark-tutorial in 2.86s
2022.02.12 16:17:00 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:17:04 INFO  time: compiled spark-tutorial in 4.38s
Feb. 12, 2022 4:17:04 NACHM. scala.meta.internal.pc.CompilerAccess retryWithCleanCompiler
INFO: compiler crashed due to an error in the Scala compiler, retrying with new compiler instance.
2022.02.12 16:17:09 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:17:10 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:17:11 INFO  time: compiled spark-tutorial in 1.94s
2022.02.12 16:17:13 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:17:16 INFO  time: compiled spark-tutorial in 2.55s
2022.02.12 16:17:17 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:17:17 INFO  time: compiled spark-tutorial in 0.57s
2022.02.12 16:17:21 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:17:22 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:17:22 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:17:32 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:17:40 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:17:40 INFO  Closing debug server tcp://0.0.0.0:61736
2022.02.12 16:18:15 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:18:16 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:16 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:15 INFO  time: compiled spark-tutorial in 0.47s
2022.02.12 16:18:16 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:17 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:17 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:18:17 INFO  time: compiled spark-tutorial in 0.18s
2022.02.12 16:18:18 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:18 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:18 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:18:19 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:18 INFO  time: compiled spark-tutorial in 0.43s
2022.02.12 16:18:20 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:20 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:21 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:18:21 INFO  time: compiled spark-tutorial in 0.37s
2022.02.12 16:18:23 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:23 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:23 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:18:23 INFO  time: compiled spark-tutorial in 0.38s
2022.02.12 16:18:25 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:25 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:26 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:18:26 INFO  time: compiled spark-tutorial in 0.14s
2022.02.12 16:18:30 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:30 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:30 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:18:31 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:30 INFO  time: compiled spark-tutorial in 0.67s
2022.02.12 16:18:32 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:32 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:32 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:33 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:33 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:33 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:18:34 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:34 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:33 INFO  time: compiled spark-tutorial in 0.38s
2022.02.12 16:18:35 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:18:35 INFO  time: compiled spark-tutorial in 0.34s
2022.02.12 16:18:41 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:42 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:18:42 INFO  time: compiled spark-tutorial in 0.36s
2022.02.12 16:18:45 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:46 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:46 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:46 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:46 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:46 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:46 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:47 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:48 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:48 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:18:48 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:18:48 INFO  time: compiled spark-tutorial in 0.4s
2022.02.12 16:19:15 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:17 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:17 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:21 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:21 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:24 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:24 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:24 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:24 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:24 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:24 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:24 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:25 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:19:25 INFO  time: compiled spark-tutorial in 0.34s
2022.02.12 16:19:25 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:26 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:26 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:26 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:19:26 INFO  time: compiled spark-tutorial in 0.41s
2022.02.12 16:19:26 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:27 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:27 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:28 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:28 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:19:28 INFO  time: compiled spark-tutorial in 0.35s
2022.02.12 16:19:28 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:28 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:29 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:19:29 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:29 INFO  time: compiled spark-tutorial in 0.38s
2022.02.12 16:19:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:19:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:00 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:20:00 INFO  time: compiled spark-tutorial in 0.43s
2022.02.12 16:20:01 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:02 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:07 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:09 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:09 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:09 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:09 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:10 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:20:10 INFO  time: compiled spark-tutorial in 0.45s
2022.02.12 16:20:16 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:16 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:16 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:17 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:20:17 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:17 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:17 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:17 INFO  time: compiled spark-tutorial in 0.64s
2022.02.12 16:20:17 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:18 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:17 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:17 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:19 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:19 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:19 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:19 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:20:19 INFO  time: compiled spark-tutorial in 0.4s
2022.02.12 16:20:22 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:22 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:22 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:23 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:20:23 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:20:23 INFO  time: compiled spark-tutorial in 0.49s
2022.02.12 16:20:35 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 34m 8.425s)
2022.02.12 16:20:35 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:20:35 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:20:35 INFO  time: compiled spark-tutorial in 0.38s
2022.02.12 16:20:35 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:20:35 INFO  time: compiled spark-tutorial in 0.35s
Feb. 12, 2022 4:20:36 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
java.util.concurrent.CompletionException: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:29)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:26)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.$anonfun$applyOrElse$4(BuildServerConnection.scala:282)
	at scala.Option.getOrElse(Option.scala:189)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:280)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:268)
	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:417)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	... 4 more

2022.02.12 16:21:09 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 34m 42.573s)
2022.02.12 16:21:09 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:09 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:09 INFO  time: compiled spark-tutorial in 0.37s
2022.02.12 16:21:09 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:09 INFO  time: compiled spark-tutorial in 0.32s
Feb. 12, 2022 4:21:10 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
java.util.concurrent.CompletionException: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:29)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:26)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.$anonfun$applyOrElse$4(BuildServerConnection.scala:282)
	at scala.Option.getOrElse(Option.scala:189)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:280)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:268)
	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:417)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	... 4 more

2022.02.12 16:21:12 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 34m 45.788s)
2022.02.12 16:21:12 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:12 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:12 INFO  time: compiled spark-tutorial in 0.36s
2022.02.12 16:21:12 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:12 INFO  time: compiled spark-tutorial in 0.33s
Feb. 12, 2022 4:21:13 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
java.util.concurrent.CompletionException: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:29)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:26)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.$anonfun$applyOrElse$4(BuildServerConnection.scala:282)
	at scala.Option.getOrElse(Option.scala:189)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:280)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:268)
	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:417)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	... 4 more

2022.02.12 16:21:18 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 34m 51.274s)
2022.02.12 16:21:18 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:18 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:18 INFO  time: compiled spark-tutorial in 0.33s
2022.02.12 16:21:18 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:18 INFO  time: compiled spark-tutorial in 0.49s
Feb. 12, 2022 4:21:18 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
java.util.concurrent.CompletionException: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:29)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:26)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.$anonfun$applyOrElse$4(BuildServerConnection.scala:282)
	at scala.Option.getOrElse(Option.scala:189)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:280)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:268)
	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:417)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	... 4 more

2022.02.12 16:21:22 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:21:22 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:21:24 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 34m 57.897s)
2022.02.12 16:21:24 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:24 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:24 INFO  time: compiled spark-tutorial in 0.33s
2022.02.12 16:21:24 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:24 INFO  time: compiled spark-tutorial in 0.32s
Feb. 12, 2022 4:21:25 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
java.util.concurrent.CompletionException: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:29)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:26)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.$anonfun$applyOrElse$4(BuildServerConnection.scala:282)
	at scala.Option.getOrElse(Option.scala:189)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:280)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:268)
	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:417)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	... 4 more

2022.02.12 16:21:29 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:21:29 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3b.scala
2022.02.12 16:21:30 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:30 INFO  time: compiled spark-tutorial in 0.57s
2022.02.12 16:21:33 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 35m 7.103s)
2022.02.12 16:21:33 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:33 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:33 INFO  time: compiled spark-tutorial in 0.37s
2022.02.12 16:21:33 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:33 INFO  time: compiled spark-tutorial in 0.33s
Feb. 12, 2022 4:21:34 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
java.util.concurrent.CompletionException: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:29)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:26)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.$anonfun$applyOrElse$4(BuildServerConnection.scala:282)
	at scala.Option.getOrElse(Option.scala:189)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:280)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:268)
	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:417)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	... 4 more

2022.02.12 16:21:54 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 35m 27.841s)
2022.02.12 16:21:54 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:54 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:54 INFO  time: compiled spark-tutorial in 0.36s
2022.02.12 16:21:54 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:21:54 INFO  time: compiled spark-tutorial in 0.32s
Feb. 12, 2022 4:21:55 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
java.util.concurrent.CompletionException: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:29)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:26)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.$anonfun$applyOrElse$4(BuildServerConnection.scala:282)
	at scala.Option.getOrElse(Option.scala:189)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:280)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:268)
	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:417)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	... 4 more

2022.02.12 16:22:17 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 35m 50.812s)
2022.02.12 16:22:17 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:22:17 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:22:17 INFO  time: compiled spark-tutorial in 0.36s
2022.02.12 16:22:17 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:22:17 INFO  time: compiled spark-tutorial in 0.32s
Feb. 12, 2022 4:22:18 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
java.util.concurrent.CompletionException: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:29)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:26)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.$anonfun$applyOrElse$4(BuildServerConnection.scala:282)
	at scala.Option.getOrElse(Option.scala:189)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:280)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:268)
	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:417)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	... 4 more

2022.02.12 16:22:32 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:22:32 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:22:32 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:22:32 INFO  time: compiled spark-tutorial in 0.42s
2022.02.12 16:22:34 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:22:47 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:22:55 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:22:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:22:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:22:58 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:22:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.12 16:23:00 INFO  time: compiled spark-tutorial in 2.56s
2022.02.12 16:23:33 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:23:33 INFO  time: compiled spark-tutorial in 0.17s
2022.02.12 16:23:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:23:38 INFO  time: compiled spark-tutorial in 1.57s
2022.02.12 16:23:39 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:23:41 INFO  time: compiled spark-tutorial in 1.41s
2022.02.12 16:23:48 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:23:50 INFO  time: compiled spark-tutorial in 1.75s
2022.02.12 16:23:52 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 37m 25.519s)
2022.02.12 16:23:52 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 16:23:53 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 16:23:53 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:23:57 INFO  Trying to attach to remote debuggee VM localhost:62064 .
2022.02.12 16:23:57 INFO  Attaching to debuggee VM succeeded.
2022.02.12 16:23:59 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 16:23:59 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 16:23:59 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 16:23:59 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 16:23:59 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 16:23:59 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 16:24:53 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:24:53 INFO  Closing debug server tcp://0.0.0.0:62057
2022.02.12 16:27:11 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:27:11 INFO  time: compiled spark-tutorial in 0.3s
2022.02.12 16:27:14 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:27:14 INFO  time: compiled spark-tutorial in 0.15s
2022.02.12 16:27:23 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:27:23 INFO  time: compiled spark-tutorial in 0.17s
2022.02.12 16:27:26 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:27:26 INFO  time: compiled spark-tutorial in 0.24s
2022.02.12 16:27:38 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:27:38 INFO  time: compiled spark-tutorial in 0.25s
2022.02.12 16:27:39 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:27:42 INFO  time: compiled spark-tutorial in 3.34s
2022.02.12 16:27:42 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:27:42 INFO  time: compiled spark-tutorial in 0.12s
2022.02.12 16:27:50 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:27:50 INFO  time: compiled spark-tutorial in 0.18s
2022.02.12 16:27:52 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:27:52 INFO  time: compiled spark-tutorial in 0.14s
2022.02.12 16:28:44 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:28:44 INFO  time: compiled spark-tutorial in 0.26s
2022.02.12 16:28:48 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:28:48 INFO  time: compiled spark-tutorial in 0.25s
2022.02.12 16:29:21 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:29:21 INFO  time: compiled spark-tutorial in 0.4s
2022.02.12 16:29:23 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:29:23 INFO  time: compiled spark-tutorial in 0.17s
2022.02.12 16:29:25 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:29:25 INFO  time: compiled spark-tutorial in 0.21s
2022.02.12 16:29:28 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:29:28 INFO  time: compiled spark-tutorial in 0.22s
2022.02.12 16:29:30 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:29:30 INFO  time: compiled spark-tutorial in 0.3s
2022.02.12 16:29:32 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:29:32 INFO  time: compiled spark-tutorial in 0.23s
2022.02.12 16:29:40 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:29:40 INFO  time: compiled spark-tutorial in 0.2s
2022.02.12 16:29:43 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:29:43 INFO  time: compiled spark-tutorial in 0.2s
2022.02.12 16:29:45 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:29:45 INFO  time: compiled spark-tutorial in 0.1s
2022.02.12 16:29:50 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:29:50 INFO  time: compiled spark-tutorial in 0.25s
2022.02.12 16:29:52 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:29:52 INFO  time: compiled spark-tutorial in 0.21s
Feb. 12, 2022 4:30:24 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5517
2022.02.12 16:31:37 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:31:37 INFO  time: compiled spark-tutorial in 0.27s
Feb. 12, 2022 4:31:43 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5570
2022.02.12 16:31:53 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:31:53 INFO  time: compiled spark-tutorial in 0.27s
2022.02.12 16:32:07 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:32:07 INFO  time: compiled spark-tutorial in 0.26s
2022.02.12 16:32:09 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:32:09 INFO  time: compiled spark-tutorial in 96ms
2022.02.12 16:32:23 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:32:23 INFO  time: compiled spark-tutorial in 0.24s
2022.02.12 16:36:07 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:36:07 INFO  time: compiled spark-tutorial in 0.28s
2022.02.12 16:36:09 INFO  compiling spark-tutorial (2 scala sources)
2022.02.12 16:36:11 INFO  time: compiled spark-tutorial in 1.95s
2022.02.12 16:36:30 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 50m 3.635s)
2022.02.12 16:36:30 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 16:36:30 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 16:36:31 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:36:34 INFO  Trying to attach to remote debuggee VM localhost:62387 .
2022.02.12 16:36:34 INFO  Attaching to debuggee VM succeeded.
2022.02.12 16:36:36 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 16:36:36 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 16:36:36 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 16:36:36 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 16:36:36 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 16:36:36 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 16:37:25 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:37:25 INFO  Closing debug server tcp://0.0.0.0:62383
2022.02.12 16:37:54 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:37:54 INFO  time: compiled spark-tutorial in 0.12s
2022.02.12 16:37:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:37:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:37:58 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:37:58 INFO  time: compiled spark-tutorial in 0.11s
2022.02.12 16:37:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:38:00 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:38:01 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:38:02 INFO  time: compiled spark-tutorial in 1.47s
2022.02.12 16:38:03 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:38:06 INFO  time: compiled spark-tutorial in 2.6s
2022.02.12 16:39:09 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:39:09 INFO  time: compiled spark-tutorial in 0.94s
2022.02.12 16:39:12 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:39:13 INFO  time: compiled spark-tutorial in 1.06s
2022.02.12 16:39:13 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:39:13 INFO  time: compiled spark-tutorial in 0.38s
2022.02.12 16:39:15 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:39:17 INFO  time: compiled spark-tutorial in 1.61s
2022.02.12 16:39:20 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:39:20 INFO  time: compiled spark-tutorial in 0.16s
2022.02.12 16:39:24 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:39:24 INFO  time: compiled spark-tutorial in 0.15s
2022.02.12 16:39:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:39:38 INFO  time: compiled spark-tutorial in 1.25s
2022.02.12 16:39:46 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:39:48 INFO  time: compiled spark-tutorial in 1.58s
2022.02.12 16:39:50 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:39:52 INFO  time: compiled spark-tutorial in 1.44s
2022.02.12 16:39:58 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:39:58 INFO  time: compiled spark-tutorial in 0.28s
2022.02.12 16:40:23 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:40:37 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:40:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:40:37 INFO  time: compiled spark-tutorial in 0.12s
Feb. 12, 2022 4:40:39 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5977
2022.02.12 16:40:39 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:40:39 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:40:39 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:40:40 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:40:40 INFO  time: compiled spark-tutorial in 0.19s
2022.02.12 16:40:47 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:40:47 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:40:47 INFO  time: compiled spark-tutorial in 0.13s
2022.02.12 16:40:52 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:40:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:40:55 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:40:55 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:40:55 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:40:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:40:55 INFO  time: compiled spark-tutorial in 0.16s
2022.02.12 16:40:56 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:40:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:40:58 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:40:58 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:40:58 INFO  time: compiled spark-tutorial in 0.24s
2022.02.12 16:40:58 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:40:58 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:40:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:02 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:13 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:14 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:15 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:15 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:17 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:17 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:21 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:21 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:22 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:23 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:23 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:24 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:25 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:25 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:26 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:26 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:41:26 INFO  time: compiled spark-tutorial in 96ms
2022.02.12 16:41:28 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:28 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:29 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:41:29 INFO  time: compiled spark-tutorial in 0.26s
2022.02.12 16:41:33 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:33 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:33 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:41:33 INFO  time: compiled spark-tutorial in 0.1s
2022.02.12 16:41:39 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:58 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:41:58 INFO  time: compiled spark-tutorial in 93ms
2022.02.12 16:41:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:41:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:42:00 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:42:00 INFO  time: compiled spark-tutorial in 81ms
2022.02.12 16:42:05 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:42:12 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:42:12 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:42:13 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:42:13 INFO  time: compiled spark-tutorial in 0.19s
2022.02.12 16:42:53 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:42:56 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:42:56 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:42:57 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:42:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:42:58 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:42:58 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:42:58 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.12 16:42:59 INFO  time: compiled spark-tutorial in 1.53s
2022.02.12 16:43:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:43:03 INFO  time: compiled spark-tutorial in 1.38s
2022.02.12 16:43:18 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 42h 56m 51.392s)
2022.02.12 16:43:18 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 16:43:19 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 16:43:19 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:43:22 INFO  Trying to attach to remote debuggee VM localhost:62619 .
2022.02.12 16:43:22 INFO  Attaching to debuggee VM succeeded.
2022.02.12 16:43:24 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 16:43:24 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 16:43:24 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 16:43:24 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 16:43:24 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 16:43:24 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 16:43:32 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:43:34 INFO  time: compiled spark-tutorial in 2.18s
2022.02.12 16:44:17 ERROR Exception in thread "main" org.apache.spark.sql.AnalysisException: cannot resolve '`newValues`['size']' due to data type mismatch: argument 2 requires integral type, however, ''size'' is of string type.;;
2022.02.12 16:44:17 ERROR 'Filter (newValues#458[size] > 1)
2022.02.12 16:44:17 ERROR +- Aggregate [tableId#33, attributeName#36, entityId#35, timestamp#34], [tableId#33, attributeName#36, entityId#35, timestamp#34, collect_list(newValue#37, 0, 0) AS newValues#458]
2022.02.12 16:44:17 ERROR    +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).tableID, true, false) AS tableID#33, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, TimestampType, fromJavaTimestamp, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).timestamp, true, false) AS timestamp#34, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).entityID AS entityID#35, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).attributeName, true, false) AS attributeName#36, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).newValue, true, false) AS newValue#37]
2022.02.12 16:44:17 ERROR       +- MapElements de.hpi.dbsII_exercises.DBSIISparkExerciseMain$$$Lambda$2392/0x00000008010a3040@2df7766b, interface org.apache.spark.sql.Row, [StructField(Dataset_ID,StringType,true), StructField(Timestamp,TimestampType,true), StructField(EntityID,IntegerType,true), StructField(AttributeName,StringType,true), StructField(newValue,StringType,true)], obj#32: de.hpi.dbsII_exercises.ChangeRecord
2022.02.12 16:44:17 ERROR          +- DeserializeToObject createexternalrow(Dataset_ID#16.toString, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, ObjectType(class java.sql.Timestamp), toJavaTimestamp, Timestamp#17, true, false), EntityID#18, AttributeName#19.toString, newValue#20.toString, StructField(Dataset_ID,StringType,true), StructField(Timestamp,TimestampType,true), StructField(EntityID,IntegerType,true), StructField(AttributeName,StringType,true), StructField(newValue,StringType,true)), obj#31: org.apache.spark.sql.Row
2022.02.12 16:44:17 ERROR             +- Relation[Dataset_ID#16,Timestamp#17,EntityID#18,AttributeName#19,newValue#20] csv
2022.02.12 16:44:17 ERROR 
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:149)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:140)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$2(TreeNode.scala:333)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:333)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$1(TreeNode.scala:330)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:399)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:237)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:397)
2022.02.12 16:44:17 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:350)
2022.02.12 16:44:17 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:330)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsUp$1(QueryPlan.scala:106)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:118)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)
2022.02.12 16:44:17 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:118)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:129)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:139)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:237)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:139)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:106)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:140)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:92)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:177)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:92)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:89)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:130)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:156)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:153)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:68)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:133)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:133)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:68)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:66)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:58)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:211)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:217)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.Dataset$.apply(Dataset.scala:76)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.Dataset.withTypedPlan(Dataset.scala:3649)
2022.02.12 16:44:17 ERROR 	at org.apache.spark.sql.Dataset.filter(Dataset.scala:1590)
2022.02.12 16:44:17 ERROR 	at de.hpi.dbsII_exercises.Exercise_3c.execute(Exercise_3c.scala:30)
2022.02.12 16:44:17 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:32)
2022.02.12 16:44:17 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:7)
2022.02.12 16:44:17 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.12 16:44:17 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.12 16:44:17 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.12 16:44:17 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.12 16:44:17 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.12 16:44:17 ERROR 	at scala.App.main(App.scala:80)
2022.02.12 16:44:17 ERROR 	at scala.App.main$(App.scala:78)
2022.02.12 16:44:17 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:7)
2022.02.12 16:44:17 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.12 16:44:17 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:44:17 INFO  Closing debug server tcp://0.0.0.0:62610
2022.02.12 16:44:20 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:46:06 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:46:06 INFO  time: compiled spark-tutorial in 0.21s
2022.02.12 16:46:12 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:46:12 INFO  time: compiled spark-tutorial in 0.22s
2022.02.12 16:46:28 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:46:28 INFO  time: compiled spark-tutorial in 80ms
2022.02.12 16:46:53 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:46:53 INFO  time: compiled spark-tutorial in 84ms
2022.02.12 16:46:55 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:46:56 INFO  time: compiled spark-tutorial in 1.24s
2022.02.12 16:47:07 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:47:07 INFO  time: compiled spark-tutorial in 0.11s
2022.02.12 16:47:09 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:47:09 INFO  time: compiled spark-tutorial in 0.11s
2022.02.12 16:47:10 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:47:10 INFO  time: compiled spark-tutorial in 0.11s
2022.02.12 16:47:21 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:47:21 INFO  time: compiled spark-tutorial in 0.13s
2022.02.12 16:47:23 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:47:23 INFO  time: compiled spark-tutorial in 89ms
2022.02.12 16:47:25 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:47:25 INFO  time: compiled spark-tutorial in 0.1s
2022.02.12 16:47:28 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:47:28 INFO  time: compiled spark-tutorial in 96ms
2022.02.12 16:47:31 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:47:31 INFO  time: compiled spark-tutorial in 96ms
2022.02.12 16:47:36 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:47:36 INFO  time: compiled spark-tutorial in 83ms
2022.02.12 16:47:40 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:47:40 INFO  time: compiled spark-tutorial in 0.12s
2022.02.12 16:47:43 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:47:43 INFO  time: compiled spark-tutorial in 83ms
2022.02.12 16:47:46 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:47:46 INFO  time: compiled spark-tutorial in 94ms
2022.02.12 16:47:51 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:47:51 INFO  time: compiled spark-tutorial in 85ms
2022.02.12 16:47:54 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:47:54 INFO  time: compiled spark-tutorial in 0.16s
2022.02.12 16:48:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:48:02 INFO  time: compiled spark-tutorial in 0.13s
2022.02.12 16:48:21 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:48:21 INFO  time: compiled spark-tutorial in 0.23s
2022.02.12 16:48:26 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:48:26 INFO  time: compiled spark-tutorial in 0.23s
2022.02.12 16:48:47 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:48:47 INFO  time: compiled spark-tutorial in 0.2s
2022.02.12 16:48:50 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:48:50 INFO  time: compiled spark-tutorial in 0.29s
2022.02.12 16:48:53 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:48:53 INFO  time: compiled spark-tutorial in 0.28s
2022.02.12 16:49:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:49:02 INFO  time: compiled spark-tutorial in 0.19s
2022.02.12 16:49:04 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:49:04 INFO  time: compiled spark-tutorial in 81ms
2022.02.12 16:49:06 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:49:06 INFO  time: compiled spark-tutorial in 0.23s
2022.02.12 16:49:23 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:49:23 INFO  time: compiled spark-tutorial in 0.12s
2022.02.12 16:49:29 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:49:29 INFO  time: compiled spark-tutorial in 90ms
2022.02.12 16:49:47 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:49:47 INFO  time: compiled spark-tutorial in 93ms
2022.02.12 16:50:43 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:50:43 INFO  time: compiled spark-tutorial in 0.13s
2022.02.12 16:50:45 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:50:45 INFO  time: compiled spark-tutorial in 86ms
2022.02.12 16:50:46 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:50:46 INFO  time: compiled spark-tutorial in 0.14s
2022.02.12 16:51:07 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:51:07 INFO  time: compiled spark-tutorial in 0.39s
2022.02.12 16:51:20 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:51:20 INFO  time: compiled spark-tutorial in 0.11s
2022.02.12 16:52:52 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:52:53 INFO  time: compiled spark-tutorial in 1.32s
2022.02.12 16:52:59 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 43h 6m 32.635s)
2022.02.12 16:52:59 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.12 16:53:01 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.12 16:53:01 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:53:04 INFO  Trying to attach to remote debuggee VM localhost:62948 .
2022.02.12 16:53:04 INFO  Attaching to debuggee VM succeeded.
2022.02.12 16:53:05 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.12 16:53:05 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.12 16:53:05 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.12 16:53:05 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.12 16:53:05 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.12 16:53:05 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.12 16:53:53 ERROR Exception in thread "main" org.apache.spark.sql.AnalysisException: cannot resolve '`newValues`['size']' due to data type mismatch: argument 2 requires integral type, however, ''size'' is of string type.;;
2022.02.12 16:53:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:53:53 ERROR 'Filter (newValues#458[size] > 1)
2022.02.12 16:53:53 ERROR +- Aggregate [tableId#33, attributeName#36, entityId#35, timestamp#34], [tableId#33, attributeName#36, entityId#35, timestamp#34, collect_list(newValue#37, 0, 0) AS newValues#458]
2022.02.12 16:53:53 ERROR    +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).tableID, true, false) AS tableID#33, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, TimestampType, fromJavaTimestamp, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).timestamp, true, false) AS timestamp#34, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).entityID AS entityID#35, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).attributeName, true, false) AS attributeName#36, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).newValue, true, false) AS newValue#37]
2022.02.12 16:53:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:53:53 ERROR       +- MapElements de.hpi.dbsII_exercises.DBSIISparkExerciseMain$$$Lambda$2384/0x000000080108c040@5ae22651, interface org.apache.spark.sql.Row, [StructField(Dataset_ID,StringType,true), StructField(Timestamp,TimestampType,true), StructField(EntityID,IntegerType,true), StructField(AttributeName,StringType,true), StructField(newValue,StringType,true)], obj#32: de.hpi.dbsII_exercises.ChangeRecord
2022.02.12 16:53:53 ERROR          +- DeserializeToObject createexternalrow(Dataset_ID#16.toString, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, ObjectType(class java.sql.Timestamp), toJavaTimestamp, Timestamp#17, true, false), EntityID#18, AttributeName#19.toString, newValue#20.toString, StructField(Dataset_ID,StringType,true), StructField(Timestamp,TimestampType,true), StructField(EntityID,IntegerType,true), StructField(AttributeName,StringType,true), StructField(newValue,StringType,true)), obj#31: org.apache.spark.sql.Row
2022.02.12 16:53:53 ERROR             +- Relation[Dataset_ID#16,Timestamp#17,EntityID#18,AttributeName#19,newValue#20] csv
2022.02.12 16:53:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:53:53 ERROR 
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:149)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:140)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$2(TreeNode.scala:333)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:333)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$1(TreeNode.scala:330)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:399)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:237)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:397)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:350)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:330)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsUp$1(QueryPlan.scala:106)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:118)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:118)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:129)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:139)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:237)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:139)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:106)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:140)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:92)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:177)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:92)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:89)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:130)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:156)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:153)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:68)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:133)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:133)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:68)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:66)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:58)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:211)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:217)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.Dataset$.apply(Dataset.scala:76)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.Dataset.withTypedPlan(Dataset.scala:3649)
2022.02.12 16:53:53 ERROR 	at org.apache.spark.sql.Dataset.filter(Dataset.scala:1590)
2022.02.12 16:53:53 ERROR 	at de.hpi.dbsII_exercises.Exercise_3c.execute(Exercise_3c.scala:30)
2022.02.12 16:53:53 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:32)
2022.02.12 16:53:53 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:7)
2022.02.12 16:53:53 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.12 16:53:53 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.12 16:53:53 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.12 16:53:53 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.12 16:53:53 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.12 16:53:53 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.12 16:53:53 ERROR 	at scala.App.main(App.scala:80)
2022.02.12 16:53:53 ERROR 	at scala.App.main$(App.scala:78)
2022.02.12 16:53:53 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:7)
2022.02.12 16:53:53 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.12 16:53:53 INFO  Closing debug server tcp://0.0.0.0:62940
Feb. 12, 2022 4:53:54 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireError
SEVERE: java.net.SocketException: Broken pipe (Write failed)
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.net.SocketException: Broken pipe (Write failed)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.debug.SocketEndpoint.consume(SocketEndpoint.scala:22)
	at scala.meta.internal.metals.debug.MessageIdAdapter.consume(MessageIdAdapter.scala:43)
	at scala.meta.internal.metals.debug.ServerAdapter.send(ServerAdapter.scala:30)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleClientMessage$1(DebugProxy.scala:138)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToClient$1(DebugProxy.scala:63)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.base/java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)
	at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:69)
	... 21 more

Feb. 12, 2022 4:53:55 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireStreamClosed
INFO: Connection reset
java.net.SocketException: Connection reset
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:79)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)

2022.02.12 16:53:55 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.12 16:54:12 INFO  compiling spark-tutorial (1 scala source)
2022.02.12 16:54:13 INFO  time: compiled spark-tutorial in 1.67s
2022.02.13 10:29:10 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:29:12 INFO  time: compiled spark-tutorial in 1.93s
2022.02.13 10:29:16 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 60h 42m 49.584s)
2022.02.13 10:29:16 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.13 10:29:16 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.13 10:29:17 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.13 10:29:21 INFO  Trying to attach to remote debuggee VM localhost:54701 .
2022.02.13 10:29:21 INFO  Attaching to debuggee VM succeeded.
2022.02.13 10:29:22 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.13 10:29:22 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.13 10:29:22 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.13 10:29:22 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.13 10:29:22 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.13 10:29:22 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.13 10:30:00 ERROR Exception in thread "main" org.apache.spark.sql.AnalysisException: cannot resolve '`newValues`['length']' due to data type mismatch: argument 2 requires integral type, however, ''length'' is of string type.;;
2022.02.13 10:30:00 ERROR 'Filter (newValues#373[length] > 1)
2022.02.13 10:30:00 ERROR +- Aggregate [tableId#33, attributeName#36, entityId#35, timestamp#34], [tableId#33, attributeName#36, entityId#35, timestamp#34, collect_list(newValue#37, 0, 0) AS newValues#373]
2022.02.13 10:30:00 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.13 10:30:00 ERROR    +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).tableID, true, false) AS tableID#33, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, TimestampType, fromJavaTimestamp, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).timestamp, true, false) AS timestamp#34, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).entityID AS entityID#35, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).attributeName, true, false) AS attributeName#36, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).newValue, true, false) AS newValue#37]
2022.02.13 10:30:00 ERROR       +- MapElements de.hpi.dbsII_exercises.DBSIISparkExerciseMain$$$Lambda$2370/0x0000000801073040@20843604, interface org.apache.spark.sql.Row, [StructField(Dataset_ID,StringType,true), StructField(Timestamp,TimestampType,true), StructField(EntityID,IntegerType,true), StructField(AttributeName,StringType,true), StructField(newValue,StringType,true)], obj#32: de.hpi.dbsII_exercises.ChangeRecord
2022.02.13 10:30:00 ERROR          +- DeserializeToObject createexternalrow(Dataset_ID#16.toString, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, ObjectType(class java.sql.Timestamp), toJavaTimestamp, Timestamp#17, true, false), EntityID#18, AttributeName#19.toString, newValue#20.toString, StructField(Dataset_ID,StringType,true), StructField(Timestamp,TimestampType,true), StructField(EntityID,IntegerType,true), StructField(AttributeName,StringType,true), StructField(newValue,StringType,true)), obj#31: org.apache.spark.sql.Row
2022.02.13 10:30:00 ERROR             +- Relation[Dataset_ID#16,Timestamp#17,EntityID#18,AttributeName#19,newValue#20] csv
2022.02.13 10:30:00 ERROR 
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:149)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:140)
2022.02.13 10:30:00 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$2(TreeNode.scala:333)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:333)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$1(TreeNode.scala:330)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:399)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:237)
2022.02.13 10:30:00 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:397)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:350)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:330)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsUp$1(QueryPlan.scala:106)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:118)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:118)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:129)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:139)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:237)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:139)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:106)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:140)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:92)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:177)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:92)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:89)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:130)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:156)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:153)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:68)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:133)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:133)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:68)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:66)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:58)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:211)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:217)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.Dataset$.apply(Dataset.scala:76)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.Dataset.withTypedPlan(Dataset.scala:3649)
2022.02.13 10:30:00 ERROR 	at org.apache.spark.sql.Dataset.filter(Dataset.scala:1590)
2022.02.13 10:30:00 ERROR 	at de.hpi.dbsII_exercises.Exercise_3c.execute(Exercise_3c.scala:30)
2022.02.13 10:30:00 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:32)
2022.02.13 10:30:00 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:7)
2022.02.13 10:30:00 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.13 10:30:00 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.13 10:30:00 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.13 10:30:00 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.13 10:30:00 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.13 10:30:00 ERROR 	at scala.App.main(App.scala:80)
2022.02.13 10:30:00 ERROR 	at scala.App.main$(App.scala:78)
2022.02.13 10:30:00 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:7)
2022.02.13 10:30:00 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.13 10:30:00 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.13 10:30:00 INFO  Closing debug server tcp://0.0.0.0:54697
Feb. 13, 2022 10:30:02 VORM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireStreamClosed
INFO: Connection reset
java.net.SocketException: Connection reset
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:79)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)

2022.02.13 10:30:02 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.13 10:34:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:34:03 INFO  time: compiled spark-tutorial in 1.14s
2022.02.13 10:34:08 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:34:09 INFO  time: compiled spark-tutorial in 1.21s
2022.02.13 10:34:26 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 60h 47m 59.703s)
2022.02.13 10:34:28 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.13 10:34:28 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.13 10:34:28 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.13 10:34:32 INFO  Trying to attach to remote debuggee VM localhost:54982 .
2022.02.13 10:34:32 INFO  Attaching to debuggee VM succeeded.
2022.02.13 10:34:33 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.13 10:34:33 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.13 10:34:33 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.13 10:34:33 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.13 10:34:33 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.13 10:34:33 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.13 10:34:40 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:34:44 INFO  time: compiled spark-tutorial in 3.64s
2022.02.13 10:34:45 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:34:45 INFO  time: compiled spark-tutorial in 0.21s
2022.02.13 10:34:48 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:34:50 INFO  time: compiled spark-tutorial in 1.55s
2022.02.13 10:36:21 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.13 10:36:21 INFO  Closing debug server tcp://0.0.0.0:54977
2022.02.13 10:51:21 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:51:21 INFO  time: compiled spark-tutorial in 0.31s
2022.02.13 10:51:23 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:51:23 INFO  time: compiled spark-tutorial in 0.14s
2022.02.13 10:51:43 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:51:43 INFO  time: compiled spark-tutorial in 0.14s
2022.02.13 10:51:45 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:51:45 INFO  time: compiled spark-tutorial in 0.16s
2022.02.13 10:51:48 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:51:48 INFO  time: compiled spark-tutorial in 0.16s
Feb. 13, 2022 10:51:55 VORM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7297
2022.02.13 10:51:56 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:51:57 INFO  time: compiled spark-tutorial in 1.19s
2022.02.13 10:51:59 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:51:59 INFO  time: compiled spark-tutorial in 1s
2022.02.13 10:52:05 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:52:05 INFO  time: compiled spark-tutorial in 0.18s
2022.02.13 10:52:31 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:52:31 INFO  time: compiled spark-tutorial in 0.17s
2022.02.13 10:52:33 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:52:33 INFO  time: compiled spark-tutorial in 0.15s
2022.02.13 10:53:59 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:53:59 INFO  time: compiled spark-tutorial in 0.15s
2022.02.13 10:54:06 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 10:54:07 INFO  time: compiled spark-tutorial in 1.33s
2022.02.13 10:54:19 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 61h 7m 52.758s)
2022.02.13 10:54:19 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.13 10:54:19 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.13 10:54:20 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.13 10:54:24 INFO  Trying to attach to remote debuggee VM localhost:55949 .
2022.02.13 10:54:24 INFO  Attaching to debuggee VM succeeded.
2022.02.13 10:54:25 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.13 10:54:25 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.13 10:54:25 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.13 10:54:25 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.13 10:54:25 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.13 10:54:25 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.13 10:55:05 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.13 10:55:05 INFO  Closing debug server tcp://0.0.0.0:55940
2022.02.13 11:11:24 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 11:11:26 INFO  time: compiled spark-tutorial in 1.31s
2022.02.13 11:11:33 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 61h 25m 6.656s)
2022.02.13 11:11:33 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.13 11:11:34 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.13 11:11:34 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.13 11:11:37 INFO  Trying to attach to remote debuggee VM localhost:56576 .
2022.02.13 11:11:37 INFO  Attaching to debuggee VM succeeded.
2022.02.13 11:11:37 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.13 11:11:37 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.13 11:11:37 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.13 11:11:37 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.13 11:11:37 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.13 11:11:38 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.13 11:12:13 ERROR Exception in thread "main" org.apache.spark.sql.AnalysisException: cannot resolve '`newValues`['length']' due to data type mismatch: argument 2 requires integral type, however, ''length'' is of string type.;;
2022.02.13 11:12:13 ERROR 'Filter (newValues#176[length] > 1)
2022.02.13 11:12:13 ERROR +- Aggregate [tableId#33, attributeName#36, entityId#35, timestamp#34], [tableId#33, attributeName#36, entityId#35, timestamp#34, collect_list(newValue#37, 0, 0) AS newValues#176]
2022.02.13 11:12:13 ERROR    +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).tableID, true, false) AS tableID#33, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, TimestampType, fromJavaTimestamp, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).timestamp, true, false) AS timestamp#34, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).entityID AS entityID#35, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).attributeName, true, false) AS attributeName#36, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).newValue, true, false) AS newValue#37]
2022.02.13 11:12:13 ERROR       +- MapElements de.hpi.dbsII_exercises.DBSIISparkExerciseMain$$$Lambda$2380/0x000000080109b040@4c231f62, interface org.apache.spark.sql.Row, [StructField(Dataset_ID,StringType,true), StructField(Timestamp,TimestampType,true), StructField(EntityID,IntegerType,true), StructField(AttributeName,StringType,true), StructField(newValue,StringType,true)], obj#32: de.hpi.dbsII_exercises.ChangeRecord
2022.02.13 11:12:13 ERROR          +- DeserializeToObject createexternalrow(Dataset_ID#16.toString, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, ObjectType(class java.sql.Timestamp), toJavaTimestamp, Timestamp#17, true, false), EntityID#18, AttributeName#19.toString, newValue#20.toString, StructField(Dataset_ID,StringType,true), StructField(Timestamp,TimestampType,true), StructField(EntityID,IntegerType,true), StructField(AttributeName,StringType,true), StructField(newValue,StringType,true)), obj#31: org.apache.spark.sql.Row
2022.02.13 11:12:13 ERROR             +- Relation[Dataset_ID#16,Timestamp#17,EntityID#18,AttributeName#19,newValue#20] csv
2022.02.13 11:12:13 ERROR 
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:149)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:140)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$2(TreeNode.scala:333)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:333)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$1(TreeNode.scala:330)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:399)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:237)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:397)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:350)
2022.02.13 11:12:13 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:330)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsUp$1(QueryPlan.scala:106)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:118)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:118)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:129)
2022.02.13 11:12:13 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:139)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:237)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:139)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:106)
2022.02.13 11:12:13 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:140)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:92)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:177)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:92)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:89)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:130)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:156)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:153)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:68)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:133)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:133)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:68)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:66)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:58)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:211)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:217)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.Dataset$.apply(Dataset.scala:76)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.Dataset.withTypedPlan(Dataset.scala:3649)
2022.02.13 11:12:13 ERROR 	at org.apache.spark.sql.Dataset.filter(Dataset.scala:1590)
2022.02.13 11:12:13 ERROR 	at de.hpi.dbsII_exercises.Exercise_3c.execute(Exercise_3c.scala:30)
2022.02.13 11:12:13 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:32)
2022.02.13 11:12:13 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:7)
2022.02.13 11:12:13 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.13 11:12:13 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.13 11:12:13 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.13 11:12:13 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.13 11:12:13 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.13 11:12:13 ERROR 	at scala.App.main(App.scala:80)
2022.02.13 11:12:13 ERROR 	at scala.App.main$(App.scala:78)
2022.02.13 11:12:13 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:7)
2022.02.13 11:12:13 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.13 11:12:13 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.13 11:12:13 INFO  Closing debug server tcp://0.0.0.0:56569
Feb. 13, 2022 11:12:14 VORM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireError
SEVERE: java.net.SocketException: Broken pipe (Write failed)
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.net.SocketException: Broken pipe (Write failed)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.debug.SocketEndpoint.consume(SocketEndpoint.scala:22)
	at scala.meta.internal.metals.debug.MessageIdAdapter.consume(MessageIdAdapter.scala:43)
	at scala.meta.internal.metals.debug.ServerAdapter.send(ServerAdapter.scala:30)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleClientMessage$1(DebugProxy.scala:138)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToClient$1(DebugProxy.scala:63)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.base/java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)
	at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:69)
	... 21 more

Feb. 13, 2022 11:12:14 VORM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireError
SEVERE: java.net.SocketException: Broken pipe (Write failed)
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.net.SocketException: Broken pipe (Write failed)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.debug.SocketEndpoint.consume(SocketEndpoint.scala:22)
	at scala.meta.internal.metals.debug.MessageIdAdapter.consume(MessageIdAdapter.scala:43)
	at scala.meta.internal.metals.debug.ServerAdapter.send(ServerAdapter.scala:30)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleClientMessage$1(DebugProxy.scala:138)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToClient$1(DebugProxy.scala:63)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.base/java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)
	at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:69)
	... 21 more

Feb. 13, 2022 11:12:15 VORM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireStreamClosed
INFO: Connection reset
java.net.SocketException: Connection reset
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:79)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)

2022.02.13 11:12:15 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.13 11:21:11 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 11:21:13 INFO  time: compiled spark-tutorial in 2.04s
2022.02.13 11:21:13 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 11:21:13 INFO  time: compiled spark-tutorial in 0.14s
2022.02.13 11:21:19 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 11:21:19 INFO  time: compiled spark-tutorial in 0.13s
2022.02.13 11:21:25 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 11:21:25 INFO  time: compiled spark-tutorial in 0.14s
2022.02.13 11:21:30 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 11:21:30 INFO  time: compiled spark-tutorial in 0.14s
2022.02.13 11:21:31 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 11:21:31 INFO  time: compiled spark-tutorial in 0.12s
2022.02.13 11:21:35 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 11:21:35 INFO  time: compiled spark-tutorial in 0.15s
2022.02.13 11:23:12 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 11:23:12 INFO  time: compiled spark-tutorial in 93ms
2022.02.13 11:23:16 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 11:23:17 INFO  time: compiled spark-tutorial in 1.01s
2022.02.13 11:23:24 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 61h 36m 57.258s)
2022.02.13 11:23:24 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.13 11:23:24 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.13 11:23:24 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.13 11:23:28 INFO  Trying to attach to remote debuggee VM localhost:56965 .
2022.02.13 11:23:28 INFO  Attaching to debuggee VM succeeded.
2022.02.13 11:23:29 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.13 11:23:29 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.13 11:23:29 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.13 11:23:29 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.13 11:23:29 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.13 11:23:29 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.13 11:24:03 ERROR Exception in thread "main" org.apache.spark.sql.AnalysisException: cannot resolve '`newValues`['length']' due to data type mismatch: argument 2 requires integral type, however, ''length'' is of string type.;;
2022.02.13 11:24:03 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.13 11:24:03 ERROR 'Filter (newValues#176[length] > 1)
2022.02.13 11:24:03 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.13 11:24:03 ERROR +- Aggregate [tableId#33, attributeName#36, entityId#35, timestamp#34], [tableId#33, attributeName#36, entityId#35, timestamp#34, collect_list(newValue#37, 0, 0) AS newValues#176]
2022.02.13 11:24:03 ERROR    +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).tableID, true, false) AS tableID#33, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, TimestampType, fromJavaTimestamp, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).timestamp, true, false) AS timestamp#34, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).entityID AS entityID#35, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).attributeName, true, false) AS attributeName#36, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).newValue, true, false) AS newValue#37]
2022.02.13 11:24:03 ERROR       +- MapElements de.hpi.dbsII_exercises.DBSIISparkExerciseMain$$$Lambda$2376/0x000000080109c840@28dd038f, interface org.apache.spark.sql.Row, [StructField(Dataset_ID,StringType,true), StructField(Timestamp,TimestampType,true), StructField(EntityID,IntegerType,true), StructField(AttributeName,StringType,true), StructField(newValue,StringType,true)], obj#32: de.hpi.dbsII_exercises.ChangeRecord
2022.02.13 11:24:03 ERROR          +- DeserializeToObject createexternalrow(Dataset_ID#16.toString, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, ObjectType(class java.sql.Timestamp), toJavaTimestamp, Timestamp#17, true, false), EntityID#18, AttributeName#19.toString, newValue#20.toString, StructField(Dataset_ID,StringType,true), StructField(Timestamp,TimestampType,true), StructField(EntityID,IntegerType,true), StructField(AttributeName,StringType,true), StructField(newValue,StringType,true)), obj#31: org.apache.spark.sql.Row
2022.02.13 11:24:03 ERROR             +- Relation[Dataset_ID#16,Timestamp#17,EntityID#18,AttributeName#19,newValue#20] csv
2022.02.13 11:24:03 ERROR 
2022.02.13 11:24:03 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:149)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:140)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$2(TreeNode.scala:333)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:333)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$1(TreeNode.scala:330)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:399)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:237)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:397)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:350)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:330)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsUp$1(QueryPlan.scala:106)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:118)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:118)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:129)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:139)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:237)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:139)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:106)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:140)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:92)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:177)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:92)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:89)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:130)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:156)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:153)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:68)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:133)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:133)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:68)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:66)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:58)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:211)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:217)
2022.02.13 11:24:03 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.Dataset$.apply(Dataset.scala:76)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.Dataset.withTypedPlan(Dataset.scala:3649)
2022.02.13 11:24:03 ERROR 	at org.apache.spark.sql.Dataset.filter(Dataset.scala:1590)
2022.02.13 11:24:03 ERROR 	at de.hpi.dbsII_exercises.Exercise_3c.execute(Exercise_3c.scala:30)
2022.02.13 11:24:03 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:32)
2022.02.13 11:24:03 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:7)
2022.02.13 11:24:03 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.13 11:24:03 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.13 11:24:03 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.13 11:24:03 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.13 11:24:03 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.13 11:24:03 ERROR 	at scala.App.main(App.scala:80)
2022.02.13 11:24:03 ERROR 	at scala.App.main$(App.scala:78)
2022.02.13 11:24:03 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:7)
2022.02.13 11:24:03 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.13 11:24:03 INFO  Closing debug server tcp://0.0.0.0:56961
Feb. 13, 2022 11:24:03 VORM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireError
SEVERE: java.net.SocketException: Broken pipe (Write failed)
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.net.SocketException: Broken pipe (Write failed)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.debug.SocketEndpoint.consume(SocketEndpoint.scala:22)
	at scala.meta.internal.metals.debug.MessageIdAdapter.consume(MessageIdAdapter.scala:43)
	at scala.meta.internal.metals.debug.ServerAdapter.send(ServerAdapter.scala:30)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleClientMessage$1(DebugProxy.scala:138)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToClient$1(DebugProxy.scala:63)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.base/java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)
	at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:69)
	... 21 more

Feb. 13, 2022 11:24:04 VORM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireStreamClosed
INFO: Connection reset
java.net.SocketException: Connection reset
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:79)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)

2022.02.13 11:24:04 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.13 11:27:54 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 11:27:54 INFO  time: compiled spark-tutorial in 0.97s
2022.02.13 11:27:57 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 11:27:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.13 11:27:58 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.13 11:27:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.13 11:27:58 INFO  time: compiled spark-tutorial in 1.71s
2022.02.13 11:27:58 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 11:27:58 INFO  time: compiled spark-tutorial in 0.29s
2022.02.13 11:28:05 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 11:28:05 INFO  time: compiled spark-tutorial in 0.17s
2022.02.13 11:28:08 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 11:28:08 INFO  time: compiled spark-tutorial in 0.12s
2022.02.13 11:28:11 INFO  compiling spark-tutorial (1 scala source)
2022.02.13 11:28:11 INFO  time: compiled spark-tutorial in 0.13s
2022.02.13 11:28:31 INFO  compiling spark-tutorial (2 scala sources)
2022.02.13 11:28:31 INFO  time: compiled spark-tutorial in 0.2s
2022.02.13 11:28:36 INFO  compiling spark-tutorial (2 scala sources)
2022.02.13 11:28:36 INFO  time: compiled spark-tutorial in 0.17s
2022.02.13 11:28:44 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:28:44 INFO  time: compiled spark-tutorial in 0.18s
2022.02.13 11:28:45 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:28:45 INFO  time: compiled spark-tutorial in 0.21s
2022.02.13 11:28:49 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:28:49 INFO  time: compiled spark-tutorial in 0.2s
Feb. 13, 2022 11:28:56 VORM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7803
2022.02.13 11:29:16 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:29:16 INFO  time: compiled spark-tutorial in 0.23s
2022.02.13 11:29:21 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:29:21 INFO  time: compiled spark-tutorial in 0.22s
2022.02.13 11:29:23 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:29:23 INFO  time: compiled spark-tutorial in 0.23s
2022.02.13 11:29:30 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:29:30 INFO  time: compiled spark-tutorial in 0.24s
2022.02.13 11:29:32 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:29:32 INFO  time: compiled spark-tutorial in 0.44s
2022.02.13 11:29:34 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:29:34 INFO  time: compiled spark-tutorial in 0.19s
2022.02.13 11:29:38 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:29:38 INFO  time: compiled spark-tutorial in 0.2s
2022.02.13 11:29:46 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:29:46 INFO  time: compiled spark-tutorial in 0.21s
2022.02.13 11:30:06 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:30:06 INFO  time: compiled spark-tutorial in 0.21s
2022.02.13 11:30:15 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:30:15 INFO  time: compiled spark-tutorial in 0.2s
2022.02.13 11:30:55 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:30:55 INFO  time: compiled spark-tutorial in 0.18s
2022.02.13 11:31:00 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:31:00 INFO  time: compiled spark-tutorial in 0.18s
2022.02.13 11:32:43 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:32:43 INFO  time: compiled spark-tutorial in 84ms
2022.02.13 11:32:44 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:26: stale bloop error: ')' expected but string literal found.
      .where($"newValues"".length" > "1")
                         ^
2022.02.13 11:32:44 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:26: stale bloop error: ')' expected but string literal found.
      .where($"newValues"".length" > "1")
                         ^
2022.02.13 11:32:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:26: stale bloop error: ')' expected but string literal found.
      .where($"newValues"".length" > "1")
                         ^
2022.02.13 11:32:45 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:32:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:39: stale bloop error: unclosed string literal
      .where($"newValues".length" > "1")
                                      ^
2022.02.13 11:32:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:39: stale bloop error: unclosed string literal
      .where($"newValues".length" > "1")
                                      ^
2022.02.13 11:32:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:27: stale bloop error: identifier expected but string literal found.
      .where($"newValues".length" > "1")
                          ^
2022.02.13 11:32:45 INFO  time: compiled spark-tutorial in 71ms
2022.02.13 11:32:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:39: stale bloop error: unclosed string literal
      .where($"newValues".length" > "1")
                                      ^
2022.02.13 11:32:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:27: stale bloop error: identifier expected but string literal found.
      .where($"newValues".length" > "1")
                          ^
2022.02.13 11:32:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:39: stale bloop error: unclosed string literal
      .where($"newValues".length" > "1")
                                      ^
2022.02.13 11:32:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:27: stale bloop error: identifier expected but string literal found.
      .where($"newValues".length" > "1")
                          ^
2022.02.13 11:32:46 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:32:46 INFO  time: compiled spark-tutorial in 0.19s
2022.02.13 11:32:55 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:32:55 INFO  time: compiled spark-tutorial in 0.17s
2022.02.13 11:33:33 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:33:33 INFO  time: compiled spark-tutorial in 0.19s
2022.02.13 11:33:34 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:33:34 INFO  time: compiled spark-tutorial in 71ms
2022.02.13 11:33:37 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:33:37 INFO  time: compiled spark-tutorial in 0.22s
2022.02.13 11:33:41 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:33:41 INFO  time: compiled spark-tutorial in 0.19s
2022.02.13 11:33:48 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:33:48 INFO  time: compiled spark-tutorial in 0.21s
2022.02.13 11:33:50 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:33:50 INFO  time: compiled spark-tutorial in 0.19s
2022.02.13 11:34:02 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:34:02 INFO  time: compiled spark-tutorial in 0.2s
2022.02.13 11:34:04 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:34:04 INFO  time: compiled spark-tutorial in 0.17s
Feb. 13, 2022 11:36:31 VORM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8184
2022.02.13 11:38:56 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:38:56 INFO  time: compiled spark-tutorial in 0.22s
2022.02.13 11:38:59 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:38:59 INFO  time: compiled spark-tutorial in 0.21s
2022.02.13 11:39:03 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:39:03 INFO  time: compiled spark-tutorial in 0.1s
2022.02.13 11:39:07 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:39:07 INFO  time: compiled spark-tutorial in 0.24s
2022.02.13 11:39:10 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:41:5: stale bloop error: value toSeq is not a member of org.apache.spark.sql.Column
    test.toSeq().show()
    ^^^^^^^^^^
2022.02.13 11:39:10 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:41:5: stale bloop error: value toSeq is not a member of org.apache.spark.sql.Column
    test.toSeq().show()
    ^^^^^^^^^^
2022.02.13 11:39:12 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:39:12 INFO  time: compiled spark-tutorial in 0.24s
2022.02.13 11:39:16 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:39:16 INFO  time: compiled spark-tutorial in 0.18s
2022.02.13 11:39:19 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 11:39:19 INFO  time: compiled spark-tutorial in 0.16s
2022.02.13 16:24:41 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:24:41 INFO  time: compiled spark-tutorial in 0.5s
2022.02.13 16:25:05 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:25:05 INFO  time: compiled spark-tutorial in 0.11s
2022.02.13 16:25:07 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:25:07 INFO  time: compiled spark-tutorial in 0.11s
2022.02.13 16:25:10 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:25:10 INFO  time: compiled spark-tutorial in 0.12s
2022.02.13 16:25:11 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:25:11 INFO  time: compiled spark-tutorial in 0.12s
2022.02.13 16:25:14 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:25:14 INFO  time: compiled spark-tutorial in 0.12s
2022.02.13 16:25:16 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:25:16 INFO  time: compiled spark-tutorial in 0.1s
2022.02.13 16:25:21 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:25:21 INFO  time: compiled spark-tutorial in 0.12s
2022.02.13 16:25:39 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:25:39 INFO  time: compiled spark-tutorial in 0.11s
2022.02.13 16:25:42 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:13: stale bloop error: not a legal formal parameter.
Note: Tuples cannot be directly destructured in method or function parameters.
      Either create a single parameter accepting the Tuple1,
      or consider a pattern matching anonymous function: `{ case (param1, param1) => ... }
      .map(($"tableId",$"attributeName",$"entityId",_,$"newValues") => > 1)
            ^
2022.02.13 16:25:42 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:74: stale bloop error: ')' expected but integer literal found.
      .map(($"tableId",$"attributeName",$"entityId",_,$"newValues") => > 1)
                                                                         ^
2022.02.13 16:25:42 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:13: stale bloop error: not a legal formal parameter.
Note: Tuples cannot be directly destructured in method or function parameters.
      Either create a single parameter accepting the Tuple1,
      or consider a pattern matching anonymous function: `{ case (param1, param1) => ... }
      .map(($"tableId",$"attributeName",$"entityId",_,$"newValues") => > 1)
            ^
2022.02.13 16:25:42 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:74: stale bloop error: ')' expected but integer literal found.
      .map(($"tableId",$"attributeName",$"entityId",_,$"newValues") => > 1)
                                                                         ^
2022.02.13 16:25:44 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:25:44 INFO  time: compiled spark-tutorial in 93ms
2022.02.13 16:25:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:13: stale bloop error: not a legal formal parameter.
Note: Tuples cannot be directly destructured in method or function parameters.
      Either create a single parameter accepting the Tuple1,
      or consider a pattern matching anonymous function: `{ case (param1, param1) => ... }
      .map(($"tableId",$"attributeName",_,_,$"newValues") => > 1)
            ^
2022.02.13 16:25:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:64: stale bloop error: ')' expected but integer literal found.
      .map(($"tableId",$"attributeName",_,_,$"newValues") => > 1)
                                                               ^
2022.02.13 16:25:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:13: stale bloop error: not a legal formal parameter.
Note: Tuples cannot be directly destructured in method or function parameters.
      Either create a single parameter accepting the Tuple1,
      or consider a pattern matching anonymous function: `{ case (param1, param1) => ... }
      .map(($"tableId",$"attributeName",_,_,$"newValues") => > 1)
            ^
2022.02.13 16:25:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:64: stale bloop error: ')' expected but integer literal found.
      .map(($"tableId",$"attributeName",_,_,$"newValues") => > 1)
                                                               ^
2022.02.13 16:25:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:13: stale bloop error: not a legal formal parameter.
Note: Tuples cannot be directly destructured in method or function parameters.
      Either create a single parameter accepting the Tuple1,
      or consider a pattern matching anonymous function: `{ case (param1, param1) => ... }
      .map(($"tableId",$"attributeName",_,_,$"newValues") => > 1)
            ^
2022.02.13 16:25:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:64: stale bloop error: ')' expected but integer literal found.
      .map(($"tableId",$"attributeName",_,_,$"newValues") => > 1)
                                                               ^
2022.02.13 16:25:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:13: stale bloop error: not a legal formal parameter.
Note: Tuples cannot be directly destructured in method or function parameters.
      Either create a single parameter accepting the Tuple1,
      or consider a pattern matching anonymous function: `{ case (param1, param1) => ... }
      .map(($"tableId",$"attributeName",_,_,$"newValues") => > 1)
            ^
2022.02.13 16:25:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:64: stale bloop error: ')' expected but integer literal found.
      .map(($"tableId",$"attributeName",_,_,$"newValues") => > 1)
                                                               ^
2022.02.13 16:25:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:13: stale bloop error: not a legal formal parameter.
Note: Tuples cannot be directly destructured in method or function parameters.
      Either create a single parameter accepting the Tuple1,
      or consider a pattern matching anonymous function: `{ case (param1, param1) => ... }
      .map(($"tableId",$"attributeName",_,_,$"newValues") => > 1)
            ^
2022.02.13 16:25:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:64: stale bloop error: ')' expected but integer literal found.
      .map(($"tableId",$"attributeName",_,_,$"newValues") => > 1)
                                                               ^
2022.02.13 16:25:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:13: stale bloop error: not a legal formal parameter.
Note: Tuples cannot be directly destructured in method or function parameters.
      Either create a single parameter accepting the Tuple1,
      or consider a pattern matching anonymous function: `{ case (param1, param1) => ... }
      .map(($"tableId",$"attributeName",_,_,$"newValues") => > 1)
            ^
2022.02.13 16:25:45 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:64: stale bloop error: ')' expected but integer literal found.
      .map(($"tableId",$"attributeName",_,_,$"newValues") => > 1)
                                                               ^
2022.02.13 16:25:48 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:25:48 INFO  time: compiled spark-tutorial in 0.1s
2022.02.13 16:25:49 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:13: stale bloop error: not a legal formal parameter.
Note: Tuples cannot be directly destructured in method or function parameters.
      Either create a single parameter accepting the Tuple1,
      or consider a pattern matching anonymous function: `{ case (param1, param1) => ... }
      .map(($"tableId",_,_,_,$"newValues") => > 1)
            ^
2022.02.13 16:25:49 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:49: stale bloop error: ')' expected but integer literal found.
      .map(($"tableId",_,_,_,$"newValues") => > 1)
                                                ^
2022.02.13 16:25:49 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:13: stale bloop error: not a legal formal parameter.
Note: Tuples cannot be directly destructured in method or function parameters.
      Either create a single parameter accepting the Tuple1,
      or consider a pattern matching anonymous function: `{ case (param1, param1) => ... }
      .map(($"tableId",_,_,_,$"newValues") => > 1)
            ^
2022.02.13 16:25:49 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:30:49: stale bloop error: ')' expected but integer literal found.
      .map(($"tableId",_,_,_,$"newValues") => > 1)
                                                ^
2022.02.13 16:25:51 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:25:51 INFO  time: compiled spark-tutorial in 0.1s
2022.02.13 16:26:02 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:26:02 INFO  time: compiled spark-tutorial in 0.11s
2022.02.13 16:26:06 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:26:06 INFO  time: compiled spark-tutorial in 79ms
2022.02.13 16:26:08 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:26:08 INFO  time: compiled spark-tutorial in 94ms
2022.02.13 16:26:10 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:26:10 INFO  time: compiled spark-tutorial in 0.11s
2022.02.13 16:26:13 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:26:13 INFO  time: compiled spark-tutorial in 0.28s
2022.02.13 16:26:14 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:26:14 INFO  time: compiled spark-tutorial in 0.25s
2022.02.13 16:26:25 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:26:25 INFO  time: compiled spark-tutorial in 0.25s
2022.02.13 16:26:28 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:26:28 INFO  time: compiled spark-tutorial in 93ms
2022.02.13 16:26:31 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:26:31 INFO  time: compiled spark-tutorial in 0.1s
2022.02.13 16:26:34 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:26:34 INFO  time: compiled spark-tutorial in 0.27s
2022.02.13 16:26:38 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:26:38 INFO  time: compiled spark-tutorial in 0.41s
2022.02.13 16:26:40 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:26:40 INFO  time: compiled spark-tutorial in 0.23s
2022.02.13 16:26:45 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:26:45 INFO  time: compiled spark-tutorial in 0.26s
2022.02.13 16:26:51 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:26:51 INFO  time: compiled spark-tutorial in 74ms
2022.02.13 16:26:55 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:26:55 INFO  time: compiled spark-tutorial in 0.18s
2022.02.13 16:26:57 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:26:57 INFO  time: compiled spark-tutorial in 89ms
2022.02.13 16:27:01 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:27:01 INFO  time: compiled spark-tutorial in 0.3s
2022.02.13 16:27:04 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:27:04 INFO  time: compiled spark-tutorial in 65ms
2022.02.13 16:27:18 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:27:18 INFO  time: compiled spark-tutorial in 87ms
2022.02.13 16:27:21 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:27:21 INFO  time: compiled spark-tutorial in 0.12s
2022.02.13 16:27:24 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:27:24 INFO  time: compiled spark-tutorial in 74ms
2022.02.13 16:27:26 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:27:26 INFO  time: compiled spark-tutorial in 0.19s
2022.02.13 16:27:28 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:27:28 INFO  time: compiled spark-tutorial in 0.21s
2022.02.13 16:27:37 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:27:37 INFO  time: compiled spark-tutorial in 0.17s
2022.02.13 16:27:57 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:27:57 INFO  time: compiled spark-tutorial in 83ms
2022.02.13 16:28:03 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:28:03 INFO  time: compiled spark-tutorial in 0.19s
2022.02.13 16:28:08 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:28:08 INFO  time: compiled spark-tutorial in 73ms
2022.02.13 16:28:10 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:28:10 INFO  time: compiled spark-tutorial in 0.19s
2022.02.13 16:28:16 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:28:16 INFO  time: compiled spark-tutorial in 0.18s
2022.02.13 16:28:29 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:28:29 INFO  time: compiled spark-tutorial in 0.2s
2022.02.13 16:28:41 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:28:41 INFO  time: compiled spark-tutorial in 0.27s
2022.02.13 16:28:43 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:28:43 INFO  time: compiled spark-tutorial in 0.22s
2022.02.13 16:28:48 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:28:48 INFO  time: compiled spark-tutorial in 0.18s
2022.02.13 16:28:50 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:28:50 INFO  time: compiled spark-tutorial in 84ms
2022.02.13 16:28:52 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:28:52 INFO  time: compiled spark-tutorial in 0.21s
2022.02.13 16:28:54 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:28:54 INFO  time: compiled spark-tutorial in 89ms
2022.02.13 16:28:55 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:28:55 INFO  time: compiled spark-tutorial in 0.2s
2022.02.13 16:29:08 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:29:08 INFO  time: compiled spark-tutorial in 0.18s
2022.02.13 16:29:17 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:29:17 INFO  time: compiled spark-tutorial in 0.22s
2022.02.13 16:29:26 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:29:26 INFO  time: compiled spark-tutorial in 0.36s
2022.02.13 16:30:20 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:30:20 INFO  time: compiled spark-tutorial in 0.14s
2022.02.13 16:30:21 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:30:21 INFO  time: compiled spark-tutorial in 0.21s
2022.02.13 16:30:23 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:30:23 INFO  time: compiled spark-tutorial in 0.13s
2022.02.13 16:30:39 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:30:39 INFO  time: compiled spark-tutorial in 0.18s
2022.02.13 16:30:43 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:30:43 INFO  time: compiled spark-tutorial in 0.18s
2022.02.13 16:30:46 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:30:46 INFO  time: compiled spark-tutorial in 0.18s
2022.02.13 16:31:15 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:31:15 INFO  time: compiled spark-tutorial in 0.2s
2022.02.13 16:31:20 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:31:20 INFO  time: compiled spark-tutorial in 0.16s
2022.02.13 16:31:59 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:31:59 INFO  time: compiled spark-tutorial in 0.26s
2022.02.13 16:32:05 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:32:05 INFO  time: compiled spark-tutorial in 0.21s
2022.02.13 16:32:09 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:32:09 INFO  time: compiled spark-tutorial in 0.17s
2022.02.13 16:32:23 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:32:23 INFO  time: compiled spark-tutorial in 0.17s
2022.02.13 16:32:32 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:32:32 INFO  time: compiled spark-tutorial in 92ms
2022.02.13 16:32:36 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:32:36 INFO  time: compiled spark-tutorial in 0.17s
2022.02.13 16:32:39 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:32:39 INFO  time: compiled spark-tutorial in 0.17s
2022.02.13 16:32:44 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:32:44 INFO  time: compiled spark-tutorial in 81ms
2022.02.13 16:32:47 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:32:47 INFO  time: compiled spark-tutorial in 0.18s
2022.02.13 16:32:52 INFO  compiling spark-tutorial (3 scala sources)
2022.02.13 16:32:52 INFO  time: compiled spark-tutorial in 0.18s
2022.02.14 18:17:01 INFO  compiling spark-tutorial (3 scala sources)
2022.02.14 18:17:04 INFO  time: compiled spark-tutorial in 3.53s
2022.02.14 18:17:04 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:17:05 INFO  time: compiled spark-tutorial in 0.26s
2022.02.14 18:17:19 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:17:21 INFO  time: compiled spark-tutorial in 1.46s
2022.02.14 18:17:23 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:17:23 INFO  time: compiled spark-tutorial in 0.33s
2022.02.14 18:17:24 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:24 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:26 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:17:26 INFO  time: compiled spark-tutorial in 0.26s
2022.02.14 18:17:28 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:28 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:28 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:31 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:31 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:31 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:32 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:17:32 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:32 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:32 INFO  time: compiled spark-tutorial in 0.41s
2022.02.14 18:17:32 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:32 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:33 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:33 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:33 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:17:33 INFO  time: compiled spark-tutorial in 0.36s
2022.02.14 18:17:35 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:35 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:35 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:36 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:36 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:36 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:36 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:37 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:37 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:17:36 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:43 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:18:43 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:43 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:43 INFO  time: compiled spark-tutorial in 0.51s
2022.02.14 18:18:49 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:49 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:50 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:49 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:52 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:52 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:52 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:52 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:55 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:55 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:56 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:18:56 INFO  time: compiled spark-tutorial in 0.25s
2022.02.14 18:18:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:18:57 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:18:57 INFO  time: compiled spark-tutorial in 0.13s
2022.02.14 18:19:00 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:03 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:04 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:04 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:04 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:04 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:05 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:05 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:06 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:19:06 INFO  time: compiled spark-tutorial in 0.39s
2022.02.14 18:19:14 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:14 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:15 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:19:15 INFO  time: compiled spark-tutorial in 0.2s
2022.02.14 18:19:21 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:24 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:24 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:24 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:24 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:24 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:25 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:19:25 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:27 INFO  time: compiled spark-tutorial in 1.71s
2022.02.14 18:19:31 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:19:31 INFO  time: compiled spark-tutorial in 0.68s
2022.02.14 18:19:32 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:19:32 INFO  time: compiled spark-tutorial in 0.17s
2022.02.14 18:19:34 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:19:34 INFO  time: compiled spark-tutorial in 0.15s
2022.02.14 18:19:36 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:19:36 INFO  time: compiled spark-tutorial in 92ms
2022.02.14 18:19:39 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:19:39 INFO  time: compiled spark-tutorial in 0.2s
2022.02.14 18:19:44 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:19:45 INFO  time: compiled spark-tutorial in 1.19s
2022.02.14 18:19:45 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:19:45 INFO  time: compiled spark-tutorial in 0.14s
2022.02.14 18:19:46 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:48 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:48 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:48 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:48 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:19:49 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:19:50 INFO  time: compiled spark-tutorial in 1.04s
2022.02.14 18:20:07 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 92h 33m 40.914s)
2022.02.14 18:20:07 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.14 18:20:07 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.14 18:20:08 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 18:20:15 INFO  Trying to attach to remote debuggee VM localhost:55091 .
2022.02.14 18:20:15 INFO  Attaching to debuggee VM succeeded.
2022.02.14 18:20:17 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.14 18:20:17 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.14 18:20:17 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.14 18:20:17 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.14 18:20:17 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.14 18:20:17 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.14 18:20:17 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:20:19 INFO  time: compiled spark-tutorial in 1.71s
2022.02.14 18:20:22 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 92h 33m 56.069s)
2022.02.14 18:20:22 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.14 18:20:22 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.14 18:20:23 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 18:20:34 INFO  Trying to attach to remote debuggee VM localhost:55109 .
2022.02.14 18:20:34 INFO  Attaching to debuggee VM succeeded.
2022.02.14 18:20:35 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.14 18:20:35 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.14 18:20:35 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.14 18:20:35 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.14 18:20:35 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.14 18:20:35 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.14 18:20:36 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 18:20:35 INFO  Closing debug server tcp://0.0.0.0:55084
2022.02.14 18:20:35 ERROR Read data from io exception: java.net.SocketException: Socket closed
2022.02.14 18:20:40 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 18:20:40 INFO  Closing debug server tcp://0.0.0.0:55103
2022.02.14 18:20:49 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 92h 34m 22.672s)
2022.02.14 18:20:49 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.14 18:20:49 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.14 18:20:49 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 18:20:55 INFO  Trying to attach to remote debuggee VM localhost:55125 .
2022.02.14 18:20:55 INFO  Attaching to debuggee VM succeeded.
2022.02.14 18:20:56 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.14 18:20:56 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.14 18:20:56 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.14 18:20:56 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.14 18:20:56 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.14 18:20:56 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.14 18:21:32 ERROR Exception in thread "main" org.apache.spark.sql.AnalysisException: Resolved attribute(s) newValues#176 missing from attributeName#36,tableID#33,newValue#37,timestamp#34,entityID#35 in operator !Aggregate [tableId#33, attributeName#36, entityId#35, timestamp#34], [tableId#33, attributeName#36, entityId#35, timestamp#34, collect_list(newValue#37, 0, 0) AS newValues#176, count(newValues#176) AS count(newValues#176)#184L].;;
2022.02.14 18:21:32 ERROR Project [tableId#33, attributeName#36, entityId#35, timestamp#34, newValues#176]
2022.02.14 18:21:32 ERROR +- Filter (count(newValues#176)#184L > cast(1 as bigint))
2022.02.14 18:21:32 ERROR    +- !Aggregate [tableId#33, attributeName#36, entityId#35, timestamp#34], [tableId#33, attributeName#36, entityId#35, timestamp#34, collect_list(newValue#37, 0, 0) AS newValues#176, count(newValues#176) AS count(newValues#176)#184L]
2022.02.14 18:21:32 ERROR       +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).tableID, true, false) AS tableID#33, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, TimestampType, fromJavaTimestamp, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).timestamp, true, false) AS timestamp#34, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).entityID AS entityID#35, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).attributeName, true, false) AS attributeName#36, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).newValue, true, false) AS newValue#37]
2022.02.14 18:21:32 ERROR          +- MapElements de.hpi.dbsII_exercises.DBSIISparkExerciseMain$$$Lambda$2396/0x00000008010a4840@397b5b2d, interface org.apache.spark.sql.Row, [StructField(Dataset_ID,StringType,true), StructField(Timestamp,TimestampType,true), StructField(EntityID,IntegerType,true), StructField(AttributeName,StringType,true), StructField(newValue,StringType,true)], obj#32: de.hpi.dbsII_exercises.ChangeRecord
2022.02.14 18:21:32 ERROR             +- DeserializeToObject createexternalrow(Dataset_ID#16.toString, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, ObjectType(class java.sql.Timestamp), toJavaTimestamp, Timestamp#17, true, false), EntityID#18, AttributeName#19.toString, newValue#20.toString, StructField(Dataset_ID,StringType,true), StructField(Timestamp,TimestampType,true), StructField(EntityID,IntegerType,true), StructField(AttributeName,StringType,true), StructField(newValue,StringType,true)), obj#31: org.apache.spark.sql.Row
2022.02.14 18:21:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.14 18:21:32 ERROR                +- Relation[Dataset_ID#16,Timestamp#17,EntityID#18,AttributeName#19,newValue#20] csv
2022.02.14 18:21:32 ERROR 
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.failAnalysis(CheckAnalysis.scala:49)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.failAnalysis$(CheckAnalysis.scala:48)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.failAnalysis(Analyzer.scala:130)
2022.02.14 18:21:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:582)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:92)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:177)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:176)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:176)
2022.02.14 18:21:32 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:176)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:176)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:176)
2022.02.14 18:21:32 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:176)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:92)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:89)
2022.02.14 18:21:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:130)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:156)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:153)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:68)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:133)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:133)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:68)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:66)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:58)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:211)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:217)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.Dataset$.apply(Dataset.scala:76)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.Dataset.withTypedPlan(Dataset.scala:3649)
2022.02.14 18:21:32 ERROR 	at org.apache.spark.sql.Dataset.filter(Dataset.scala:1590)
2022.02.14 18:21:32 ERROR 	at de.hpi.dbsII_exercises.Exercise_3c.execute(Exercise_3c.scala:30)
2022.02.14 18:21:32 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:32)
2022.02.14 18:21:32 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:7)
2022.02.14 18:21:32 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.14 18:21:32 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.14 18:21:32 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.14 18:21:32 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.14 18:21:32 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.14 18:21:32 ERROR 	at scala.App.main(App.scala:80)
2022.02.14 18:21:32 ERROR 	at scala.App.main$(App.scala:78)
2022.02.14 18:21:32 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:7)
2022.02.14 18:21:32 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.14 18:21:32 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.14 18:21:32 INFO  Closing debug server tcp://0.0.0.0:55121
Feb. 14, 2022 6:21:34 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireStreamClosed
INFO: Connection reset
java.net.SocketException: Connection reset
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:79)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)

2022.02.14 18:21:34 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 18:22:00 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:22:00 INFO  time: compiled spark-tutorial in 0.23s
2022.02.14 18:22:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:22:02 INFO  time: compiled spark-tutorial in 78ms
2022.02.14 18:22:06 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:22:06 INFO  time: compiled spark-tutorial in 0.1s
2022.02.14 18:22:07 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:22:07 INFO  time: compiled spark-tutorial in 71ms
2022.02.14 18:22:14 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:22:14 INFO  time: compiled spark-tutorial in 0.18s
2022.02.14 18:22:32 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:22:32 INFO  time: compiled spark-tutorial in 0.16s
2022.02.14 18:22:39 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:22:39 INFO  time: compiled spark-tutorial in 0.17s
2022.02.14 18:22:41 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:22:41 INFO  time: compiled spark-tutorial in 75ms
2022.02.14 18:22:44 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:22:44 INFO  time: compiled spark-tutorial in 0.15s
2022.02.14 18:22:45 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:22:45 INFO  time: compiled spark-tutorial in 60ms
2022.02.14 18:23:01 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:23:01 INFO  time: compiled spark-tutorial in 0.18s
2022.02.14 18:24:28 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:24:28 INFO  time: compiled spark-tutorial in 0.12s
2022.02.14 18:24:30 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:24:30 INFO  time: compiled spark-tutorial in 0.11s
2022.02.14 18:24:32 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:24:32 INFO  time: compiled spark-tutorial in 0.2s
2022.02.14 18:24:38 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:24:38 INFO  time: compiled spark-tutorial in 0.2s
2022.02.14 18:24:42 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:24:42 INFO  time: compiled spark-tutorial in 0.45s
2022.02.14 18:24:58 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:24:58 INFO  time: compiled spark-tutorial in 0.18s
2022.02.14 18:25:00 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:25:00 INFO  time: compiled spark-tutorial in 0.17s
2022.02.14 18:25:12 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:25:12 INFO  time: compiled spark-tutorial in 0.18s
2022.02.14 18:25:16 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:25:16 INFO  time: compiled spark-tutorial in 96ms
2022.02.14 18:25:17 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:25:17 INFO  time: compiled spark-tutorial in 81ms
2022.02.14 18:25:21 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:25:21 INFO  time: compiled spark-tutorial in 87ms
2022.02.14 18:25:38 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:25:38 INFO  time: compiled spark-tutorial in 80ms
2022.02.14 18:25:42 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:25:42 INFO  time: compiled spark-tutorial in 82ms
2022.02.14 18:25:47 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:25:47 INFO  time: compiled spark-tutorial in 0.1s
2022.02.14 18:25:58 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 92h 39m 31.505s)
2022.02.14 18:25:58 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:25:58 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:25:58 INFO  time: compiled spark-tutorial in 0.1s
2022.02.14 18:25:58 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:25:58 INFO  time: compiled spark-tutorial in 51ms
Feb. 14, 2022 6:25:58 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
java.util.concurrent.CompletionException: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:331)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:346)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:704)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:506)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2088)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:29)
	at scala.concurrent.java8.FuturesConvertersImpl$CF.apply(FutureConvertersImpl.scala:26)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: scala.meta.internal.metals.MetalsBspException: BSP connection failed in the attempt to get: DebugSessionAddress.  Compilation not successful
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.$anonfun$applyOrElse$4(BuildServerConnection.scala:282)
	at scala.Option.getOrElse(Option.scala:189)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:280)
	at scala.meta.internal.metals.BuildServerConnection$$anonfun$1.applyOrElse(BuildServerConnection.scala:268)
	at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:417)
	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)
	... 4 more

2022.02.14 18:26:10 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:26:11 INFO  time: compiled spark-tutorial in 1.08s
2022.02.14 18:26:14 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 92h 39m 48.146s)
2022.02.14 18:26:14 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.14 18:26:14 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.14 18:26:15 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 18:26:19 INFO  Trying to attach to remote debuggee VM localhost:55406 .
2022.02.14 18:26:19 INFO  Attaching to debuggee VM succeeded.
2022.02.14 18:26:20 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.14 18:26:20 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.14 18:26:20 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.14 18:26:20 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.14 18:26:20 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.14 18:26:20 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.14 18:26:57 ERROR Exception in thread "main" org.apache.spark.sql.AnalysisException: cannot resolve '`newValues`['count']' due to data type mismatch: argument 2 requires integral type, however, ''count'' is of string type.;;
2022.02.14 18:26:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.14 18:26:57 ERROR 'Filter (newValues#176[count] > 1)
2022.02.14 18:26:57 ERROR +- Aggregate [tableId#33, attributeName#36, entityId#35, timestamp#34], [tableId#33, attributeName#36, entityId#35, timestamp#34, collect_list(newValue#37, 0, 0) AS newValues#176]
2022.02.14 18:26:57 ERROR    +- SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).tableID, true, false) AS tableID#33, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, TimestampType, fromJavaTimestamp, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).timestamp, true, false) AS timestamp#34, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).entityID AS entityID#35, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).attributeName, true, false) AS attributeName#36, staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, knownnotnull(assertnotnull(input[0, de.hpi.dbsII_exercises.ChangeRecord, true])).newValue, true, false) AS newValue#37]
2022.02.14 18:26:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.14 18:26:57 ERROR       +- MapElements de.hpi.dbsII_exercises.DBSIISparkExerciseMain$$$Lambda$2396/0x00000008010a6840@3d96b8fb, interface org.apache.spark.sql.Row, [StructField(Dataset_ID,StringType,true), StructField(Timestamp,TimestampType,true), StructField(EntityID,IntegerType,true), StructField(AttributeName,StringType,true), StructField(newValue,StringType,true)], obj#32: de.hpi.dbsII_exercises.ChangeRecord
2022.02.14 18:26:57 ERROR          +- DeserializeToObject createexternalrow(Dataset_ID#16.toString, staticinvoke(class org.apache.spark.sql.catalyst.util.DateTimeUtils$, ObjectType(class java.sql.Timestamp), toJavaTimestamp, Timestamp#17, true, false), EntityID#18, AttributeName#19.toString, newValue#20.toString, StructField(Dataset_ID,StringType,true), StructField(Timestamp,TimestampType,true), StructField(EntityID,IntegerType,true), StructField(AttributeName,StringType,true), StructField(newValue,StringType,true)), obj#31: org.apache.spark.sql.Row
2022.02.14 18:26:57 ERROR             +- Relation[Dataset_ID#16,Timestamp#17,EntityID#18,AttributeName#19,newValue#20] csv
2022.02.14 18:26:57 ERROR 
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:149)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$$nestedInanonfun$checkAnalysis$1$2.applyOrElse(CheckAnalysis.scala:140)
2022.02.14 18:26:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$2(TreeNode.scala:333)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:333)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformUp$1(TreeNode.scala:330)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$mapChildren$1(TreeNode.scala:399)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:237)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:397)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:350)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:330)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsUp$1(QueryPlan.scala:106)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:118)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:72)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:118)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:129)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:139)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:237)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:139)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:106)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:140)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1$adapted(CheckAnalysis.scala:92)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:177)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:92)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:89)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:130)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:156)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:201)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:153)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:68)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:133)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:133)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:68)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:66)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:58)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:211)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:217)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.Dataset$.apply(Dataset.scala:76)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.Dataset.withTypedPlan(Dataset.scala:3649)
2022.02.14 18:26:57 ERROR 	at org.apache.spark.sql.Dataset.filter(Dataset.scala:1590)
2022.02.14 18:26:57 ERROR 	at de.hpi.dbsII_exercises.Exercise_3c.execute(Exercise_3c.scala:30)
2022.02.14 18:26:57 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:32)
2022.02.14 18:26:57 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:7)
2022.02.14 18:26:57 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.14 18:26:57 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.14 18:26:57 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.14 18:26:57 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.14 18:26:57 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.14 18:26:57 ERROR 	at scala.App.main(App.scala:80)
2022.02.14 18:26:57 ERROR 	at scala.App.main$(App.scala:78)
2022.02.14 18:26:57 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:7)
2022.02.14 18:26:57 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.14 18:26:57 ERROR searching for `#` failed
scala.meta.internal.mtags.IndexingExceptions$InvalidSymbolException: #
	at scala.meta.internal.mtags.OnDemandSymbolIndex.definitions(OnDemandSymbolIndex.scala:57)
	at scala.meta.internal.metals.DestinationProvider.definition(DefinitionProvider.scala:313)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:351)
	at scala.meta.internal.metals.DestinationProvider.fromSymbol(DefinitionProvider.scala:371)
	at scala.meta.internal.metals.DefinitionProvider.fromSymbol(DefinitionProvider.scala:104)
	at scala.meta.internal.metals.StacktraceAnalyzer.findLocationForSymbol$1(StacktraceAnalyzer.scala:68)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$2(StacktraceAnalyzer.scala:73)
	at scala.PartialFunction$Unlifted.applyOrElse(PartialFunction.scala:237)
	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:180)
	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:167)
	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:108)
	at scala.meta.internal.metals.StacktraceAnalyzer.$anonfun$fileLocationFromLine$1(StacktraceAnalyzer.scala:73)
	at scala.Option.flatMap(Option.scala:271)
	at scala.meta.internal.metals.StacktraceAnalyzer.fileLocationFromLine(StacktraceAnalyzer.scala:71)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1(DebugProxy.scala:183)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleServerMessage$1$adapted(DebugProxy.scala:160)
	at scala.meta.internal.metals.debug.ServerAdapter.$anonfun$onReceived$1(ServerAdapter.scala:25)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.lang.Thread.run(Thread.java:834)

2022.02.14 18:26:57 INFO  Closing debug server tcp://0.0.0.0:55401
Feb. 14, 2022 6:26:58 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireError
SEVERE: java.net.SocketException: Broken pipe (Write failed)
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.net.SocketException: Broken pipe (Write failed)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.debug.SocketEndpoint.consume(SocketEndpoint.scala:22)
	at scala.meta.internal.metals.debug.MessageIdAdapter.consume(MessageIdAdapter.scala:43)
	at scala.meta.internal.metals.debug.ServerAdapter.send(ServerAdapter.scala:30)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleClientMessage$1(DebugProxy.scala:138)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToClient$1(DebugProxy.scala:63)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.base/java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)
	at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:69)
	... 21 more

Feb. 14, 2022 6:26:58 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireStreamClosed
INFO: Connection reset
java.net.SocketException: Connection reset
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:79)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)

2022.02.14 18:26:58 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 18:28:10 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:28:10 INFO  time: compiled spark-tutorial in 0.93s
2022.02.14 18:28:12 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:28:12 INFO  time: compiled spark-tutorial in 0.14s
2022.02.14 18:28:13 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:28:13 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:28:13 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:28:13 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:28:13 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:28:13 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:28:14 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:28:14 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:28:14 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:28:14 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:28:16 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:28:17 INFO  time: compiled spark-tutorial in 1.09s
2022.02.14 18:29:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:29:37 INFO  time: compiled spark-tutorial in 0.13s
2022.02.14 18:29:49 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:29:50 INFO  time: compiled spark-tutorial in 1.14s
2022.02.14 18:29:50 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:29:50 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:29:51 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:29:50 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:29:51 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:29:51 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:29:52 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:29:51 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:29:53 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:29:53 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:29:53 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:29:53 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:29:53 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:29:53 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:29:54 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:29:55 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:29:55 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:29:54 INFO  time: compiled spark-tutorial in 0.99s
2022.02.14 18:29:55 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:29:55 INFO  time: compiled spark-tutorial in 83ms
2022.02.14 18:29:56 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:29:56 INFO  time: compiled spark-tutorial in 0.16s
2022.02.14 18:29:59 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:30:00 INFO  time: compiled spark-tutorial in 1.05s
2022.02.14 18:30:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:30:02 INFO  time: compiled spark-tutorial in 0.92s
2022.02.14 18:33:34 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:33:34 INFO  time: compiled spark-tutorial in 0.27s
2022.02.14 18:33:39 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:33:39 INFO  time: compiled spark-tutorial in 0.28s
2022.02.14 18:33:41 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:33:41 INFO  time: compiled spark-tutorial in 0.13s
2022.02.14 18:33:47 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:33:47 INFO  time: compiled spark-tutorial in 0.31s
2022.02.14 18:33:48 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:33:48 INFO  time: compiled spark-tutorial in 0.12s
2022.02.14 18:33:53 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:33:53 INFO  time: compiled spark-tutorial in 0.21s
2022.02.14 18:33:54 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:33:54 INFO  time: compiled spark-tutorial in 61ms
2022.02.14 18:33:58 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:33:58 INFO  time: compiled spark-tutorial in 0.18s
2022.02.14 18:34:05 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:34:05 INFO  time: compiled spark-tutorial in 87ms
2022.02.14 18:34:08 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:34:08 INFO  time: compiled spark-tutorial in 0.24s
2022.02.14 18:34:19 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:31:15: stale bloop error: value size is not a member of org.apache.spark.sql.ColumnName
      .filter($"newValues".size("count") > 1)
              ^^^^^^^^^^^^^^^^^
2022.02.14 18:34:19 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:31:15: stale bloop error: value size is not a member of org.apache.spark.sql.ColumnName
      .filter($"newValues".size("count") > 1)
              ^^^^^^^^^^^^^^^^^
2022.02.14 18:34:20 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:34:20 INFO  time: compiled spark-tutorial in 0.17s
2022.02.14 18:34:36 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:34:36 INFO  time: compiled spark-tutorial in 0.22s
2022.02.14 18:35:18 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:35:18 INFO  time: compiled spark-tutorial in 0.2s
2022.02.14 18:35:24 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:35:26 INFO  time: compiled spark-tutorial in 1.51s
2022.02.14 18:36:33 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:36:33 INFO  time: compiled spark-tutorial in 0.12s
2022.02.14 18:36:35 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:36:35 INFO  time: compiled spark-tutorial in 0.21s
2022.02.14 18:36:38 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:36:38 INFO  time: compiled spark-tutorial in 0.2s
2022.02.14 18:37:40 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:37:40 INFO  time: compiled spark-tutorial in 0.26s
2022.02.14 18:37:43 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:37:43 INFO  time: compiled spark-tutorial in 0.17s
2022.02.14 18:37:46 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:37:46 INFO  time: compiled spark-tutorial in 0.21s
2022.02.14 18:37:47 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:37:47 INFO  time: compiled spark-tutorial in 0.14s
2022.02.14 18:38:30 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:38:30 INFO  time: compiled spark-tutorial in 0.17s
2022.02.14 18:38:48 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:38:48 INFO  time: compiled spark-tutorial in 0.15s
2022.02.14 18:39:10 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:39:10 INFO  time: compiled spark-tutorial in 0.18s
2022.02.14 18:39:11 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:39:11 INFO  time: compiled spark-tutorial in 0.15s
2022.02.14 18:39:14 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:39:14 INFO  time: compiled spark-tutorial in 0.14s
2022.02.14 18:40:06 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:40:06 INFO  time: compiled spark-tutorial in 0.3s
2022.02.14 18:40:08 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:40:08 INFO  time: compiled spark-tutorial in 86ms
2022.02.14 18:40:09 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:40:09 INFO  time: compiled spark-tutorial in 0.19s
2022.02.14 18:40:51 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:40:51 INFO  time: compiled spark-tutorial in 0.23s
2022.02.14 18:40:57 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:40:57 INFO  time: compiled spark-tutorial in 0.2s
2022.02.14 18:40:58 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:40:58 INFO  time: compiled spark-tutorial in 0.15s
2022.02.14 18:42:29 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:42:29 INFO  time: compiled spark-tutorial in 0.27s
2022.02.14 18:42:34 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:42:34 INFO  time: compiled spark-tutorial in 91ms
2022.02.14 18:42:42 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:42:42 INFO  time: compiled spark-tutorial in 0.22s
2022.02.14 18:44:07 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:44:07 INFO  time: compiled spark-tutorial in 0.28s
2022.02.14 18:44:24 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:44:24 INFO  time: compiled spark-tutorial in 0.19s
2022.02.14 18:44:29 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:44:29 INFO  time: compiled spark-tutorial in 0.15s
2022.02.14 18:44:31 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:44:31 INFO  time: compiled spark-tutorial in 0.21s
2022.02.14 18:44:43 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:44:43 INFO  time: compiled spark-tutorial in 0.25s
2022.02.14 18:44:44 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:44:44 INFO  time: compiled spark-tutorial in 0.17s
2022.02.14 18:44:53 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:44:53 INFO  time: compiled spark-tutorial in 0.16s
2022.02.14 18:45:00 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:45:00 INFO  time: compiled spark-tutorial in 87ms
2022.02.14 18:45:04 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:45:04 INFO  time: compiled spark-tutorial in 0.17s
2022.02.14 18:45:09 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:32:161: stale bloop error: overloaded method value count with alternatives:
  (columnName: String)org.apache.spark.sql.TypedColumn[Any,Long] <and>
  (e: org.apache.spark.sql.Column)org.apache.spark.sql.Column
 cannot be applied to (Seq[String])
      .map((tableId:String,attributeName:String,entityId:Int,timestamp:Timestamp,newValues:Seq[String]) => (tableId,attributeName,entityId,timestamp,newValues, org.apache.spark.sql.functions.count(newValues) as "count"))
                                                                                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2022.02.14 18:45:09 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:32:161: stale bloop error: overloaded method value count with alternatives:
  (columnName: String)org.apache.spark.sql.TypedColumn[Any,Long] <and>
  (e: org.apache.spark.sql.Column)org.apache.spark.sql.Column
 cannot be applied to (Seq[String])
      .map((tableId:String,attributeName:String,entityId:Int,timestamp:Timestamp,newValues:Seq[String]) => (tableId,attributeName,entityId,timestamp,newValues, org.apache.spark.sql.functions.count(newValues) as "count"))
                                                                                                                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2022.02.14 18:45:12 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:45:12 INFO  time: compiled spark-tutorial in 0.17s
2022.02.14 18:45:31 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:45:31 INFO  time: compiled spark-tutorial in 0.11s
2022.02.14 18:45:34 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:45:34 INFO  time: compiled spark-tutorial in 0.24s
2022.02.14 18:45:36 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:45:36 INFO  time: compiled spark-tutorial in 0.16s
2022.02.14 18:47:00 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:47:00 INFO  time: compiled spark-tutorial in 0.17s
2022.02.14 18:47:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:47:02 INFO  time: compiled spark-tutorial in 0.21s
2022.02.14 18:47:43 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:47:43 INFO  time: compiled spark-tutorial in 0.18s
2022.02.14 18:47:49 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:47:49 INFO  time: compiled spark-tutorial in 0.15s
2022.02.14 18:47:54 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:47:56 INFO  time: compiled spark-tutorial in 1.74s
2022.02.14 18:47:56 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:47:56 INFO  time: compiled spark-tutorial in 0.18s
2022.02.14 18:47:59 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:48:00 INFO  time: compiled spark-tutorial in 1.12s
2022.02.14 18:48:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:48:02 INFO  time: compiled spark-tutorial in 0.86s
2022.02.14 18:48:06 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:48:06 INFO  time: compiled spark-tutorial in 0.16s
2022.02.14 18:48:13 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:48:13 INFO  time: compiled spark-tutorial in 98ms
2022.02.14 18:48:19 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:48:19 INFO  time: compiled spark-tutorial in 0.19s
2022.02.14 18:48:21 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:48:22 INFO  time: compiled spark-tutorial in 1.16s
2022.02.14 18:48:22 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:48:22 INFO  time: compiled spark-tutorial in 72ms
2022.02.14 18:48:25 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:25 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:26 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:48:26 INFO  time: compiled spark-tutorial in 89ms
2022.02.14 18:48:31 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:32 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:48:32 INFO  time: compiled spark-tutorial in 0.15s
2022.02.14 18:48:36 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:37 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:36 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:48:37 INFO  time: compiled spark-tutorial in 89ms
2022.02.14 18:48:37 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:38 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:38 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:38 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:38 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:39 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:38 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:39 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:38 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:39 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:39 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:39 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:40 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:39 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:40 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:40 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:40 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:41 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:41 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:41 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:42 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:48:43 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:43 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:43 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:48:43 INFO  time: compiled spark-tutorial in 1.11s
2022.02.14 18:48:44 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:48:44 INFO  time: compiled spark-tutorial in 85ms
2022.02.14 18:48:46 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:48:46 INFO  time: compiled spark-tutorial in 0.2s
2022.02.14 18:48:50 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:48:50 INFO  time: compiled spark-tutorial in 0.22s
2022.02.14 18:48:54 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:48:54 INFO  time: compiled spark-tutorial in 0.15s
2022.02.14 18:48:56 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:48:56 INFO  time: compiled spark-tutorial in 0.17s
2022.02.14 18:48:57 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:48:57 INFO  time: compiled spark-tutorial in 0.11s
2022.02.14 18:49:00 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:01 INFO  time: compiled spark-tutorial in 1.14s
2022.02.14 18:49:04 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:04 INFO  time: compiled spark-tutorial in 90ms
2022.02.14 18:49:05 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:05 INFO  time: compiled spark-tutorial in 56ms
2022.02.14 18:49:13 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:13 INFO  time: compiled spark-tutorial in 85ms
2022.02.14 18:49:16 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:16 INFO  time: compiled spark-tutorial in 0.17s
2022.02.14 18:49:17 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:17 INFO  time: compiled spark-tutorial in 0.15s
2022.02.14 18:49:18 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:18 INFO  time: compiled spark-tutorial in 0.14s
2022.02.14 18:49:21 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:22 INFO  time: compiled spark-tutorial in 1.07s
2022.02.14 18:49:22 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:22 INFO  time: compiled spark-tutorial in 47ms
2022.02.14 18:49:23 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:23 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:24 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:24 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:25 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:25 INFO  time: compiled spark-tutorial in 0.15s
2022.02.14 18:49:26 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:26 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:26 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:27 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:27 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:27 INFO  time: compiled spark-tutorial in 0.14s
2022.02.14 18:49:28 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:28 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:29 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:29 INFO  time: compiled spark-tutorial in 0.15s
2022.02.14 18:49:33 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:33 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:34 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:34 INFO  time: compiled spark-tutorial in 0.14s
2022.02.14 18:49:34 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:34 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:34 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:35 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:36 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:36 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:49:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:38 INFO  time: compiled spark-tutorial in 1.25s
2022.02.14 18:49:41 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:41 INFO  time: compiled spark-tutorial in 76ms
2022.02.14 18:49:49 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:49 INFO  time: compiled spark-tutorial in 0.17s
2022.02.14 18:49:50 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:50 INFO  time: compiled spark-tutorial in 84ms
2022.02.14 18:49:54 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:55 INFO  time: compiled spark-tutorial in 1.1s
2022.02.14 18:49:57 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:49:57 INFO  time: compiled spark-tutorial in 77ms
2022.02.14 18:50:01 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:50:01 INFO  time: compiled spark-tutorial in 0.18s
2022.02.14 18:50:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:50:39 INFO  time: compiled spark-tutorial in 2.16s
2022.02.14 18:50:52 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:50:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:50:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:50:54 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:50:55 INFO  time: code lens generation in 1.44s
2022.02.14 18:50:55 INFO  time: code lens generation in 1.03s
2022.02.14 18:50:55 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:50:55 INFO  time: compiled spark-tutorial in 0.15s
2022.02.14 18:51:05 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:51:05 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:51:05 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:51:06 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:51:08 INFO  time: compiled spark-tutorial in 1.24s
2022.02.14 18:51:16 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 93h 4m 49.502s)
2022.02.14 18:51:16 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.14 18:51:16 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.14 18:51:16 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 18:51:25 INFO  Trying to attach to remote debuggee VM localhost:56383 .
2022.02.14 18:51:25 INFO  Attaching to debuggee VM succeeded.
2022.02.14 18:51:26 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.14 18:51:26 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.14 18:51:26 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.14 18:51:26 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.14 18:51:26 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.14 18:51:26 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.14 18:52:02 ERROR Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4.0 (TID 12, 192.168.178.30, executor driver): java.lang.ClassCastException: class java.lang.Integer cannot be cast to class java.lang.Long (java.lang.Integer and java.lang.Long are in module java.base of loader 'bootstrap')
2022.02.14 18:52:02 ERROR 	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.Row.getLong(Row.scala:251)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.Row.getLong$(Row.scala:251)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getLong(rows.scala:166)
2022.02.14 18:52:02 ERROR 	at de.hpi.dbsII_exercises.Exercise_3c.$anonfun$execute$1(Exercise_3c.scala:34)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:340)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:872)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:872)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.14 18:52:02 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.14 18:52:02 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.14 18:52:02 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.14 18:52:02 ERROR 
2022.02.14 18:52:02 ERROR Driver stacktrace:
2022.02.14 18:52:02 ERROR 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2023)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1972)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1971)
2022.02.14 18:52:02 ERROR 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
2022.02.14 18:52:02 ERROR 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
2022.02.14 18:52:02 ERROR 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1971)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:950)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:950)
2022.02.14 18:52:02 ERROR 	at scala.Option.foreach(Option.scala:407)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:950)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2203)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2152)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2141)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:752)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2093)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2133)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:467)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:420)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3625)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2695)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3616)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3614)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.Dataset.head(Dataset.scala:2695)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.Dataset.take(Dataset.scala:2902)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.Dataset.getRows(Dataset.scala:300)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.Dataset.showString(Dataset.scala:337)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.Dataset.show(Dataset.scala:824)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.Dataset.show(Dataset.scala:783)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.Dataset.show(Dataset.scala:792)
2022.02.14 18:52:02 ERROR 	at de.hpi.dbsII_exercises.Exercise_3c.execute(Exercise_3c.scala:34)
2022.02.14 18:52:02 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.delayedEndpoint$de$hpi$dbsII_exercises$DBSIISparkExerciseMain$1(DBSIISparkExerciseMain.scala:32)
2022.02.14 18:52:02 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$delayedInit$body.apply(DBSIISparkExerciseMain.scala:7)
2022.02.14 18:52:02 ERROR 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
2022.02.14 18:52:02 ERROR 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
2022.02.14 18:52:02 ERROR 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
2022.02.14 18:52:02 ERROR 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
2022.02.14 18:52:02 ERROR 	at scala.collection.immutable.List.foreach(List.scala:392)
2022.02.14 18:52:02 ERROR 	at scala.App.main(App.scala:80)
2022.02.14 18:52:02 ERROR 	at scala.App.main$(App.scala:78)
2022.02.14 18:52:02 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain$.main(DBSIISparkExerciseMain.scala:7)
2022.02.14 18:52:02 ERROR 	at de.hpi.dbsII_exercises.DBSIISparkExerciseMain.main(DBSIISparkExerciseMain.scala)
2022.02.14 18:52:02 ERROR Caused by: java.lang.ClassCastException: class java.lang.Integer cannot be cast to class java.lang.Long (java.lang.Integer and java.lang.Long are in module java.base of loader 'bootstrap')
2022.02.14 18:52:02 ERROR 	at scala.runtime.BoxesRunTime.unboxToLong(BoxesRunTime.java:107)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.Row.getLong(Row.scala:251)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.Row.getLong$(Row.scala:251)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.catalyst.expressions.GenericRow.getLong(rows.scala:166)
2022.02.14 18:52:02 ERROR 	at de.hpi.dbsII_exercises.Exercise_3c.$anonfun$execute$1(Exercise_3c.scala:34)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.mapelements_doConsume_0$(Unknown Source)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.deserializetoobject_doConsume_0$(Unknown Source)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:729)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:340)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:872)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:872)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:349)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:313)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.scheduler.Task.run(Task.scala:127)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:444)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
2022.02.14 18:52:02 ERROR 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:447)
2022.02.14 18:52:02 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
2022.02.14 18:52:02 ERROR 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
2022.02.14 18:52:02 ERROR 	at java.base/java.lang.Thread.run(Thread.java:834)
2022.02.14 18:52:02 INFO  Closing debug server tcp://0.0.0.0:56375
Feb. 14, 2022 6:52:04 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireError
SEVERE: java.net.SocketException: Broken pipe (Write failed)
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.net.SocketException: Broken pipe (Write failed)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.debug.SocketEndpoint.consume(SocketEndpoint.scala:22)
	at scala.meta.internal.metals.debug.MessageIdAdapter.consume(MessageIdAdapter.scala:43)
	at scala.meta.internal.metals.debug.ServerAdapter.send(ServerAdapter.scala:30)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleClientMessage$1(DebugProxy.scala:138)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToClient$1(DebugProxy.scala:63)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.base/java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)
	at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:69)
	... 21 more

Feb. 14, 2022 6:52:04 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireError
SEVERE: java.net.SocketException: Broken pipe (Write failed)
org.eclipse.lsp4j.jsonrpc.JsonRpcException: java.net.SocketException: Broken pipe (Write failed)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:72)
	at scala.meta.internal.metals.debug.SocketEndpoint.consume(SocketEndpoint.scala:22)
	at scala.meta.internal.metals.debug.MessageIdAdapter.consume(MessageIdAdapter.scala:43)
	at scala.meta.internal.metals.debug.ServerAdapter.send(ServerAdapter.scala:30)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$handleClientMessage$1(DebugProxy.scala:138)
	at scala.meta.internal.metals.debug.MessageIdAdapter.$anonfun$listen$1(MessageIdAdapter.scala:57)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToClient$1(DebugProxy.scala:63)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.base/java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.base/java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:110)
	at java.base/java.net.SocketOutputStream.write(SocketOutputStream.java:150)
	at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)
	at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageConsumer.consume(StreamMessageConsumer.java:69)
	... 21 more

Feb. 14, 2022 6:52:06 NACHM. org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer fireStreamClosed
INFO: Connection reset
java.net.SocketException: Connection reset
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:186)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:79)
	at scala.meta.internal.metals.debug.SocketEndpoint.listen(SocketEndpoint.scala:26)
	at scala.meta.internal.metals.debug.MessageIdAdapter.listen(MessageIdAdapter.scala:47)
	at scala.meta.internal.metals.debug.ServerAdapter.onReceived(ServerAdapter.scala:18)
	at scala.meta.internal.metals.debug.DebugProxy.$anonfun$listenToServer$1(DebugProxy.scala:67)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:659)
	at scala.util.Success.$anonfun$map$1(Try.scala:255)
	at scala.util.Success.map(Try.scala:213)
	at scala.concurrent.Future.$anonfun$map$1(Future.scala:292)
	at scala.concurrent.impl.Promise.liftedTree1$1(Promise.scala:33)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)

2022.02.14 18:52:06 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 18:52:35 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:52:35 INFO  time: compiled spark-tutorial in 0.15s
2022.02.14 18:52:38 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:52:39 INFO  time: compiled spark-tutorial in 1.35s
2022.02.14 18:52:41 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:52:42 INFO  time: compiled spark-tutorial in 1.05s
2022.02.14 18:53:19 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 93h 6m 52.792s)
2022.02.14 18:53:19 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.14 18:53:19 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.14 18:53:20 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 18:53:23 INFO  Trying to attach to remote debuggee VM localhost:56417 .
2022.02.14 18:53:23 INFO  Attaching to debuggee VM succeeded.
2022.02.14 18:53:24 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.14 18:53:24 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.14 18:53:24 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.14 18:53:24 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.14 18:53:24 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.14 18:53:24 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.14 18:54:01 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 18:54:01 INFO  Closing debug server tcp://0.0.0.0:56413
2022.02.14 18:54:25 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:54:27 INFO  time: compiled spark-tutorial in 2.12s
2022.02.14 18:54:39 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:54:39 INFO  time: compiled spark-tutorial in 94ms
2022.02.14 18:54:41 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:54:42 INFO  time: compiled spark-tutorial in 1.02s
2022.02.14 18:54:45 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:54:45 INFO  time: compiled spark-tutorial in 80ms
2022.02.14 18:54:46 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:54:46 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:54:47 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:54:47 INFO  time: compiled spark-tutorial in 82ms
2022.02.14 18:54:51 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:18: stale bloop error: ')' expected but integer literal found.
      .filter( > 1)
                 ^
2022.02.14 18:54:51 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:18: stale bloop error: ')' expected but integer literal found.
      .filter( > 1)
                 ^
2022.02.14 18:54:51 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:54:51 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:54:52 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:18: stale bloop error: ')' expected but integer literal found.
      .filter( > 1)
                 ^
2022.02.14 18:54:52 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:54:52 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:15: stale bloop error: illegal character '\u00a2'
      .filter(¢ > 1)
              ^
2022.02.14 18:54:52 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:15: stale bloop error: illegal character '\u00a2'
      .filter(¢ > 1)
              ^
2022.02.14 18:54:52 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:42:3: stale bloop error: ')' expected but '}' found.
  }
  ^
2022.02.14 18:54:52 INFO  time: compiled spark-tutorial in 81ms
2022.02.14 18:54:52 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:15: stale bloop error: illegal character '\u00a2'
      .filter(¢ > 1)
              ^
2022.02.14 18:54:52 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:42:3: stale bloop error: ')' expected but '}' found.
  }
  ^
2022.02.14 18:54:52 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:15: stale bloop error: illegal character '\u00a2'
      .filter(¢ > 1)
              ^
2022.02.14 18:54:52 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:42:3: stale bloop error: ')' expected but '}' found.
  }
  ^
2022.02.14 18:54:52 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:54:52 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:54:53 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:15: stale bloop error: illegal character '\u00a2'
      .filter(¢ > 1)
              ^
2022.02.14 18:54:53 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:42:3: stale bloop error: ')' expected but '}' found.
  }
  ^
2022.02.14 18:54:53 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:54:53 INFO  time: compiled spark-tutorial in 71ms
2022.02.14 18:54:55 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:18: stale bloop error: ')' expected but integer literal found.
      .filter( > 1)
                 ^
2022.02.14 18:54:55 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:18: stale bloop error: ')' expected but integer literal found.
      .filter( > 1)
                 ^
2022.02.14 18:54:56 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:54:56 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:54:56 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:18: stale bloop error: ')' expected but integer literal found.
      .filter( > 1)
                 ^
2022.02.14 18:54:56 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:54:56 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:15: stale bloop error: illegal character '\u00a2'
      .filter(¢ > 1)
              ^
2022.02.14 18:54:56 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:15: stale bloop error: illegal character '\u00a2'
      .filter(¢ > 1)
              ^
2022.02.14 18:54:56 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:42:3: stale bloop error: ')' expected but '}' found.
  }
  ^
2022.02.14 18:54:56 INFO  time: compiled spark-tutorial in 80ms
2022.02.14 18:54:57 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:15: stale bloop error: illegal character '\u00a2'
      .filter(¢ > 1)
              ^
2022.02.14 18:54:57 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:42:3: stale bloop error: ')' expected but '}' found.
  }
  ^
2022.02.14 18:54:57 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:15: stale bloop error: illegal character '\u00a2'
      .filter(¢ > 1)
              ^
2022.02.14 18:54:57 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:42:3: stale bloop error: ')' expected but '}' found.
  }
  ^
2022.02.14 18:54:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:54:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:54:57 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:15: stale bloop error: illegal character '\u00a2'
      .filter(¢ > 1)
              ^
2022.02.14 18:54:57 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:42:3: stale bloop error: ')' expected but '}' found.
  }
  ^
2022.02.14 18:54:57 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:15: stale bloop error: illegal character '\u00a2'
      .filter(¢ > 1)
              ^
2022.02.14 18:54:57 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:42:3: stale bloop error: ')' expected but '}' found.
  }
  ^
2022.02.14 18:54:58 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:54:57 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:54:58 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:54:59 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:15: stale bloop error: illegal character '\u00a2'
      .filter(¢ > 1)
              ^
2022.02.14 18:54:59 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:42:3: stale bloop error: ')' expected but '}' found.
  }
  ^
2022.02.14 18:54:58 INFO  time: compiled spark-tutorial in 0.31s
2022.02.14 18:54:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:54:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:54:59 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:55:00 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:55:01 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:55:01 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:55:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:55:02 INFO  time: compiled spark-tutorial in 0.19s
2022.02.14 18:55:03 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:55:03 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:55:04 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:55:04 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:55:05 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:55:05 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 18:55:06 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:55:07 INFO  time: compiled spark-tutorial in 1.12s
2022.02.14 18:55:10 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:55:11 INFO  time: compiled spark-tutorial in 1.07s
2022.02.14 18:55:13 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:55:13 INFO  time: compiled spark-tutorial in 89ms
2022.02.14 18:55:13 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:55:14 INFO  time: compiled spark-tutorial in 62ms
2022.02.14 18:55:15 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:55:15 INFO  time: compiled spark-tutorial in 74ms
2022.02.14 18:55:19 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:55:19 INFO  time: compiled spark-tutorial in 0.22s
2022.02.14 18:55:20 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:55:20 INFO  time: compiled spark-tutorial in 0.21s
2022.02.14 18:55:21 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:15: stale bloop error: not found: value $newVa
      .filter($newVa > 1)
              ^^^^^^
2022.02.14 18:55:21 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:15: stale bloop error: not found: value $newVa
      .filter($newVa > 1)
              ^^^^^^
2022.02.14 18:55:22 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:15: stale bloop error: not found: value $newVa
      .filter($newVa > 1)
              ^^^^^^
2022.02.14 18:55:22 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:35:15: stale bloop error: not found: value $newVa
      .filter($newVa > 1)
              ^^^^^^
2022.02.14 18:55:24 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:55:26 INFO  time: compiled spark-tutorial in 1.16s
2022.02.14 18:55:34 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 93h 9m 7.258s)
2022.02.14 18:55:34 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.14 18:55:34 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.14 18:55:34 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 18:55:38 INFO  Trying to attach to remote debuggee VM localhost:56485 .
2022.02.14 18:55:38 INFO  Attaching to debuggee VM succeeded.
2022.02.14 18:55:39 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.14 18:55:39 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.14 18:55:39 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.14 18:55:39 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.14 18:55:39 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.14 18:55:39 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.14 18:56:22 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 18:56:22 INFO  Closing debug server tcp://0.0.0.0:56481
2022.02.14 18:56:33 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:56:33 INFO  time: compiled spark-tutorial in 0.29s
2022.02.14 18:56:41 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:56:41 INFO  time: compiled spark-tutorial in 0.31s
2022.02.14 18:56:44 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:56:44 INFO  time: compiled spark-tutorial in 0.22s
2022.02.14 18:56:54 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:56:54 INFO  time: compiled spark-tutorial in 0.22s
2022.02.14 18:56:56 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:56:56 INFO  time: compiled spark-tutorial in 0.23s
2022.02.14 18:57:08 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:44:3: stale bloop error: type mismatch;
 found   : Unit
 required: Map[(String, String, Int, java.sql.Timestamp),Seq[String]]
  }
  ^
2022.02.14 18:57:08 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:44:3: stale bloop error: type mismatch;
 found   : Unit
 required: Map[(String, String, Int, java.sql.Timestamp),Seq[String]]
  }
  ^
2022.02.14 18:57:08 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:44:3: stale bloop error: type mismatch;
 found   : Unit
 required: Map[(String, String, Int, java.sql.Timestamp),Seq[String]]
  }
  ^
2022.02.14 18:57:08 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:44:3: stale bloop error: type mismatch;
 found   : Unit
 required: Map[(String, String, Int, java.sql.Timestamp),Seq[String]]
  }
  ^
2022.02.14 18:57:08 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:44:3: stale bloop error: type mismatch;
 found   : Unit
 required: Map[(String, String, Int, java.sql.Timestamp),Seq[String]]
  }
  ^
2022.02.14 18:57:08 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:44:3: stale bloop error: type mismatch;
 found   : Unit
 required: Map[(String, String, Int, java.sql.Timestamp),Seq[String]]
  }
  ^
2022.02.14 18:57:10 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:57:10 INFO  time: compiled spark-tutorial in 0.24s
2022.02.14 18:57:19 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:18: stale bloop error: value as is not a member of String
      .map(x => (x.getString(0) as , x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                 ^^^^^^^^^^^^^^^^^
2022.02.14 18:57:19 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:36:15: stale bloop error: not found: value $
      .select($)
              ^
2022.02.14 18:57:19 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:44:3: stale bloop error: type mismatch;
 found   : Unit
 required: Map[(String, String, Int, java.sql.Timestamp),Seq[String]]
  }
  ^
2022.02.14 18:57:19 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:18: stale bloop error: value as is not a member of String
      .map(x => (x.getString(0) as , x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                 ^^^^^^^^^^^^^^^^^
2022.02.14 18:57:19 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:36:15: stale bloop error: not found: value $
      .select($)
              ^
2022.02.14 18:57:19 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:44:3: stale bloop error: type mismatch;
 found   : Unit
 required: Map[(String, String, Int, java.sql.Timestamp),Seq[String]]
  }
  ^
2022.02.14 18:57:21 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:57:21 INFO  time: compiled spark-tutorial in 0.25s
2022.02.14 18:57:22 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:57:22 INFO  time: compiled spark-tutorial in 0.61s
2022.02.14 18:57:25 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:57:25 INFO  time: compiled spark-tutorial in 0.17s
2022.02.14 18:57:28 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:57:28 INFO  time: compiled spark-tutorial in 0.22s
2022.02.14 18:57:34 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:57:34 INFO  time: compiled spark-tutorial in 0.26s
2022.02.14 18:57:34 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:57:35 INFO  time: compiled spark-tutorial in 0.16s
2022.02.14 18:57:42 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:57:42 INFO  time: compiled spark-tutorial in 0.24s
2022.02.14 18:57:46 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:57:46 INFO  time: compiled spark-tutorial in 0.23s
2022.02.14 18:57:59 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:57:59 INFO  time: compiled spark-tutorial in 78ms
2022.02.14 18:58:00 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:58:00 INFO  time: compiled spark-tutorial in 78ms
2022.02.14 18:58:04 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:58:04 INFO  time: compiled spark-tutorial in 72ms
2022.02.14 18:58:08 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:58:08 INFO  time: compiled spark-tutorial in 0.23s
2022.02.14 18:58:16 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:58:16 INFO  time: compiled spark-tutorial in 87ms
2022.02.14 18:58:19 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:58:19 INFO  time: compiled spark-tutorial in 97ms
2022.02.14 18:58:21 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:58:21 INFO  time: compiled spark-tutorial in 88ms
2022.02.14 18:58:26 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:58:26 INFO  time: compiled spark-tutorial in 72ms
2022.02.14 18:58:27 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 18:58:27 INFO  time: compiled spark-tutorial in 0.29s
2022.02.14 19:00:30 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:00:30 INFO  time: compiled spark-tutorial in 0.33s
2022.02.14 19:00:33 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:00:33 INFO  time: compiled spark-tutorial in 0.17s
2022.02.14 19:00:35 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:00:35 INFO  time: compiled spark-tutorial in 0.21s
2022.02.14 19:00:44 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:00:44 INFO  time: compiled spark-tutorial in 89ms
2022.02.14 19:00:46 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:00:46 INFO  time: compiled spark-tutorial in 0.1s
2022.02.14 19:00:48 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:44: stale bloop error: illegal start of simple expression
      .map(x => (x.getString(0).as tableId,, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                           ^
2022.02.14 19:00:48 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:43:3: stale bloop error: ')' expected but '}' found.
  }
  ^
2022.02.14 19:00:48 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:44: stale bloop error: illegal start of simple expression
      .map(x => (x.getString(0).as tableId,, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                           ^
2022.02.14 19:00:48 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:43:3: stale bloop error: ')' expected but '}' found.
  }
  ^
2022.02.14 19:00:49 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:44: stale bloop error: illegal start of simple expression
      .map(x => (x.getString(0).as tableId,, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                           ^
2022.02.14 19:00:49 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:43:3: stale bloop error: ')' expected but '}' found.
  }
  ^
2022.02.14 19:00:49 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:00:49 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0).as "tableId, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:00:49 INFO  time: compiled spark-tutorial in 89ms
2022.02.14 19:00:50 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0).as "tableId, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:00:50 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0).as "tableId, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:00:51 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0).as "tableId, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:00:51 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:00:51 INFO  time: compiled spark-tutorial in 79ms
2022.02.14 19:00:53 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:00:53 INFO  time: compiled spark-tutorial in 0.1s
2022.02.14 19:00:57 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:00:57 INFO  time: compiled spark-tutorial in 0.19s
2022.02.14 19:01:03 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:01:03 INFO  time: compiled spark-tutorial in 0.19s
2022.02.14 19:01:04 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:18: stale bloop error: value a is not a member of String
      .map(x => (x.getString(0) a "tableId", x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                 ^^^^^^^^^^^^^^^^
2022.02.14 19:01:04 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:43:3: stale bloop error: type mismatch;
 found   : Unit
 required: Map[(String, String, Int, java.sql.Timestamp),Seq[String]]
  }
  ^
2022.02.14 19:01:04 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:18: stale bloop error: value a is not a member of String
      .map(x => (x.getString(0) a "tableId", x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                 ^^^^^^^^^^^^^^^^
2022.02.14 19:01:04 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:43:3: stale bloop error: type mismatch;
 found   : Unit
 required: Map[(String, String, Int, java.sql.Timestamp),Seq[String]]
  }
  ^
2022.02.14 19:01:04 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:18: stale bloop error: value a is not a member of String
      .map(x => (x.getString(0) a "tableId", x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                 ^^^^^^^^^^^^^^^^
2022.02.14 19:01:04 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:43:3: stale bloop error: type mismatch;
 found   : Unit
 required: Map[(String, String, Int, java.sql.Timestamp),Seq[String]]
  }
  ^
2022.02.14 19:01:04 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:18: stale bloop error: value a is not a member of String
      .map(x => (x.getString(0) a "tableId", x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                 ^^^^^^^^^^^^^^^^
2022.02.14 19:01:04 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:43:3: stale bloop error: type mismatch;
 found   : Unit
 required: Map[(String, String, Int, java.sql.Timestamp),Seq[String]]
  }
  ^
2022.02.14 19:01:06 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:18: stale bloop error: value a is not a member of String
      .map(x => (x.getString(0) a "tableId", x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                 ^^^^^^^^^^^^^^^^
2022.02.14 19:01:06 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:43:3: stale bloop error: type mismatch;
 found   : Unit
 required: Map[(String, String, Int, java.sql.Timestamp),Seq[String]]
  }
  ^
2022.02.14 19:01:06 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:01:06 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:06 INFO  time: compiled spark-tutorial in 0.35s
2022.02.14 19:01:07 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:07 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:07 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:07 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:07 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:07 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:07 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:08 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:08 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:08 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:08 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:09 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:01:09 INFO  time: compiled spark-tutorial in 0.11s
2022.02.14 19:01:09 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 19:01:10 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:01:10 INFO  time: compiled spark-tutorial in 0.15s
2022.02.14 19:01:14 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:18: stale bloop error: value a is not a member of String
      .map(x => (x.getString(0) a, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                 ^^^^^^^^^^^^^^^^
2022.02.14 19:01:14 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:43:3: stale bloop error: type mismatch;
 found   : Unit
 required: Map[(String, String, Int, java.sql.Timestamp),Seq[String]]
  }
  ^
2022.02.14 19:01:14 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:18: stale bloop error: value a is not a member of String
      .map(x => (x.getString(0) a, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                 ^^^^^^^^^^^^^^^^
2022.02.14 19:01:14 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:43:3: stale bloop error: type mismatch;
 found   : Unit
 required: Map[(String, String, Int, java.sql.Timestamp),Seq[String]]
  }
  ^
2022.02.14 19:01:15 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:18: stale bloop error: value a is not a member of String
      .map(x => (x.getString(0) a, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                 ^^^^^^^^^^^^^^^^
2022.02.14 19:01:15 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:43:3: stale bloop error: type mismatch;
 found   : Unit
 required: Map[(String, String, Int, java.sql.Timestamp),Seq[String]]
  }
  ^
2022.02.14 19:01:15 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:01:15 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:15 INFO  time: compiled spark-tutorial in 95ms
2022.02.14 19:01:35 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:01:35 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:35 INFO  time: compiled spark-tutorial in 0.21s
2022.02.14 19:01:41 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:41 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:42 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:42 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:01:42 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:42 INFO  time: compiled spark-tutorial in 83ms
2022.02.14 19:01:50 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:50 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:51 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:51 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:01:51 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:51 INFO  time: compiled spark-tutorial in 0.3s
2022.02.14 19:01:53 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:53 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:54 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:54 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:01:54 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:54 INFO  time: compiled spark-tutorial in 0.11s
2022.02.14 19:01:56 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:56 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:34:36: stale bloop error: unclosed string literal
      .map(x => (x.getString(0) as "tab, x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq(4).size))
                                   ^
2022.02.14 19:01:57 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:01:57 INFO  time: compiled spark-tutorial in 0.3s
2022.02.14 19:01:59 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:01:59 INFO  time: compiled spark-tutorial in 0.26s
2022.02.14 19:02:07 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:02:07 INFO  time: compiled spark-tutorial in 0.22s
2022.02.14 19:02:11 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:02:11 INFO  time: compiled spark-tutorial in 0.3s
2022.02.14 19:02:15 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:02:15 INFO  time: compiled spark-tutorial in 91ms
2022.02.14 19:02:17 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:02:17 INFO  time: compiled spark-tutorial in 0.27s
2022.02.14 19:02:22 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:02:22 INFO  time: compiled spark-tutorial in 0.24s
Feb. 14, 2022 7:02:30 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 13590
2022.02.14 19:02:32 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:02:32 INFO  time: compiled spark-tutorial in 0.32s
2022.02.14 19:03:31 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:03:32 INFO  time: compiled spark-tutorial in 1.27s
2022.02.14 19:03:33 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:03:36 INFO  time: compiled spark-tutorial in 3.22s
2022.02.14 19:07:40 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:07:43 INFO  time: compiled spark-tutorial in 3.11s
2022.02.14 19:07:47 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:07:48 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 19:07:48 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
Feb. 14, 2022 7:07:48 NACHM. scala.meta.internal.pc.CompilerAccess retryWithCleanCompiler
INFO: compiler crashed due to an error in the Scala compiler, retrying with new compiler instance.
2022.02.14 19:07:49 INFO  time: compiled spark-tutorial in 1.42s
Feb. 14, 2022 7:07:49 NACHM. scala.meta.internal.pc.CompilerAccess handleError
SEVERE: assertion failed: bad position: [2255:2176]
java.lang.AssertionError: assertion failed: bad position: [2255:2176]
	at scala.reflect.internal.util.Position$.validate(Position.scala:41)
	at scala.reflect.internal.util.Position$.range(Position.scala:58)
	at scala.reflect.internal.util.InternalPositionImpl.copyRange(Position.scala:218)
	at scala.reflect.internal.util.InternalPositionImpl.withStart(Position.scala:133)
	at scala.reflect.internal.util.InternalPositionImpl.withStart$(Position.scala:133)
	at scala.reflect.internal.util.Position.withStart(Position.scala:19)
	at scala.meta.internal.pc.CompletionProvider.editRange$lzycompute$1(CompletionProvider.scala:376)
	at scala.meta.internal.pc.CompletionProvider.editRange$2(CompletionProvider.scala:375)
	at scala.meta.internal.pc.CompletionProvider.expected$1(CompletionProvider.scala:385)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:483)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:58)

2022.02.14 19:07:50 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:07:51 INFO  time: compiled spark-tutorial in 1.49s
2022.02.14 19:07:51 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:07:52 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 19:07:52 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
Feb. 14, 2022 7:07:52 NACHM. scala.meta.internal.pc.CompilerAccess retryWithCleanCompiler
INFO: compiler crashed due to an error in the Scala compiler, retrying with new compiler instance.
2022.02.14 19:07:53 INFO  time: compiled spark-tutorial in 0.84s
Feb. 14, 2022 7:07:53 NACHM. scala.meta.internal.pc.CompilerAccess handleError
SEVERE: assertion failed: bad position: [2256:2177]
java.lang.AssertionError: assertion failed: bad position: [2256:2177]
	at scala.reflect.internal.util.Position$.validate(Position.scala:41)
	at scala.reflect.internal.util.Position$.range(Position.scala:58)
	at scala.reflect.internal.util.InternalPositionImpl.copyRange(Position.scala:218)
	at scala.reflect.internal.util.InternalPositionImpl.withStart(Position.scala:133)
	at scala.reflect.internal.util.InternalPositionImpl.withStart$(Position.scala:133)
	at scala.reflect.internal.util.Position.withStart(Position.scala:19)
	at scala.meta.internal.pc.CompletionProvider.editRange$lzycompute$1(CompletionProvider.scala:376)
	at scala.meta.internal.pc.CompletionProvider.editRange$2(CompletionProvider.scala:375)
	at scala.meta.internal.pc.CompletionProvider.expected$1(CompletionProvider.scala:385)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:483)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:58)

2022.02.14 19:07:53 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:07:54 INFO  time: compiled spark-tutorial in 0.49s
Feb. 14, 2022 7:07:58 NACHM. scala.meta.internal.pc.CompilerAccess retryWithCleanCompiler
INFO: compiler crashed due to an error in the Scala compiler, retrying with new compiler instance.
Feb. 14, 2022 7:07:59 NACHM. scala.meta.internal.pc.CompilerAccess handleError
SEVERE: assertion failed: bad position: [2246:2182]
java.lang.AssertionError: assertion failed: bad position: [2246:2182]
	at scala.reflect.internal.util.Position$.validate(Position.scala:41)
	at scala.reflect.internal.util.Position$.range(Position.scala:58)
	at scala.reflect.internal.util.InternalPositionImpl.copyRange(Position.scala:218)
	at scala.reflect.internal.util.InternalPositionImpl.withStart(Position.scala:133)
	at scala.reflect.internal.util.InternalPositionImpl.withStart$(Position.scala:133)
	at scala.reflect.internal.util.Position.withStart(Position.scala:19)
	at scala.meta.internal.pc.CompletionProvider.editRange$lzycompute$1(CompletionProvider.scala:376)
	at scala.meta.internal.pc.CompletionProvider.editRange$2(CompletionProvider.scala:375)
	at scala.meta.internal.pc.CompletionProvider.expected$1(CompletionProvider.scala:385)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:483)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:58)

2022.02.14 19:07:59 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:08:01 INFO  time: compiled spark-tutorial in 1.5s
2022.02.14 19:08:01 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:08:01 INFO  time: compiled spark-tutorial in 0.47s
Feb. 14, 2022 7:08:09 NACHM. scala.meta.internal.pc.CompilerAccess retryWithCleanCompiler
INFO: compiler crashed due to an error in the Scala compiler, retrying with new compiler instance.
Feb. 14, 2022 7:08:09 NACHM. scala.meta.internal.pc.CompilerAccess handleError
SEVERE: assertion failed: bad position: [2238:2188]
java.lang.AssertionError: assertion failed: bad position: [2238:2188]
	at scala.reflect.internal.util.Position$.validate(Position.scala:41)
	at scala.reflect.internal.util.Position$.range(Position.scala:58)
	at scala.reflect.internal.util.InternalPositionImpl.copyRange(Position.scala:218)
	at scala.reflect.internal.util.InternalPositionImpl.withStart(Position.scala:133)
	at scala.reflect.internal.util.InternalPositionImpl.withStart$(Position.scala:133)
	at scala.reflect.internal.util.Position.withStart(Position.scala:19)
	at scala.meta.internal.pc.CompletionProvider.editRange$lzycompute$1(CompletionProvider.scala:376)
	at scala.meta.internal.pc.CompletionProvider.editRange$2(CompletionProvider.scala:375)
	at scala.meta.internal.pc.CompletionProvider.expected$1(CompletionProvider.scala:385)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:483)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:58)

2022.02.14 19:08:10 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:08:11 INFO  time: compiled spark-tutorial in 1.24s
2022.02.14 19:08:15 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:08:19 INFO  time: compiled spark-tutorial in 3.22s
Feb. 14, 2022 7:08:19 NACHM. scala.meta.internal.pc.CompilerAccess retryWithCleanCompiler
INFO: compiler crashed due to an error in the Scala compiler, retrying with new compiler instance.
2022.02.14 19:08:19 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
Feb. 14, 2022 7:08:19 NACHM. scala.meta.internal.pc.CompilerAccess handleError
SEVERE: assertion failed: bad position: [2224:2194]
java.lang.AssertionError: assertion failed: bad position: [2224:2194]
	at scala.reflect.internal.util.Position$.validate(Position.scala:41)
	at scala.reflect.internal.util.Position$.range(Position.scala:58)
	at scala.reflect.internal.util.InternalPositionImpl.copyRange(Position.scala:218)
	at scala.reflect.internal.util.InternalPositionImpl.withStart(Position.scala:133)
	at scala.reflect.internal.util.InternalPositionImpl.withStart$(Position.scala:133)
	at scala.reflect.internal.util.Position.withStart(Position.scala:19)
	at scala.meta.internal.pc.CompletionProvider.editRange$lzycompute$1(CompletionProvider.scala:376)
	at scala.meta.internal.pc.CompletionProvider.editRange$2(CompletionProvider.scala:375)
	at scala.meta.internal.pc.CompletionProvider.expected$1(CompletionProvider.scala:385)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:483)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:58)

2022.02.14 19:08:19 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 19:08:21 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:08:23 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 19:08:23 INFO  time: compiled spark-tutorial in 2.4s
2022.02.14 19:08:25 INFO  compiling spark-tutorial (1 scala source)
Feb. 14, 2022 7:08:25 NACHM. scala.meta.internal.pc.CompilerAccess retryWithCleanCompiler
INFO: compiler crashed due to an error in the Scala compiler, retrying with new compiler instance.
Feb. 14, 2022 7:08:25 NACHM. scala.meta.internal.pc.CompilerAccess handleError
SEVERE: assertion failed: bad position: [2217:2200]
java.lang.AssertionError: assertion failed: bad position: [2217:2200]
	at scala.reflect.internal.util.Position$.validate(Position.scala:41)
	at scala.reflect.internal.util.Position$.range(Position.scala:58)
	at scala.reflect.internal.util.InternalPositionImpl.copyRange(Position.scala:218)
	at scala.reflect.internal.util.InternalPositionImpl.withStart(Position.scala:133)
	at scala.reflect.internal.util.InternalPositionImpl.withStart$(Position.scala:133)
	at scala.reflect.internal.util.Position.withStart(Position.scala:19)
	at scala.meta.internal.pc.CompletionProvider.editRange$lzycompute$1(CompletionProvider.scala:376)
	at scala.meta.internal.pc.CompletionProvider.editRange$2(CompletionProvider.scala:375)
	at scala.meta.internal.pc.CompletionProvider.expected$1(CompletionProvider.scala:385)
	at scala.meta.internal.pc.CompletionProvider.safeCompletionsAt(CompletionProvider.scala:483)
	at scala.meta.internal.pc.CompletionProvider.completions(CompletionProvider.scala:58)

2022.02.14 19:08:26 INFO  time: compiled spark-tutorial in 1.18s
2022.02.14 19:08:26 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 19:08:27 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:08:28 INFO  time: compiled spark-tutorial in 1.03s
2022.02.14 19:08:38 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:08:39 INFO  time: compiled spark-tutorial in 1.15s
2022.02.14 19:08:59 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:08:59 INFO  time: compiled spark-tutorial in 0.23s
2022.02.14 19:09:19 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:09:19 INFO  time: compiled spark-tutorial in 0.3s
2022.02.14 19:09:25 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:09:25 INFO  time: compiled spark-tutorial in 0.24s
2022.02.14 19:09:54 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:09:54 INFO  time: compiled spark-tutorial in 0.41s
2022.02.14 19:10:12 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:10:12 INFO  time: compiled spark-tutorial in 0.23s
2022.02.14 19:10:18 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:10:18 INFO  time: compiled spark-tutorial in 0.22s
2022.02.14 19:10:20 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:10:20 INFO  time: compiled spark-tutorial in 0.42s
2022.02.14 19:10:23 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:10:23 INFO  time: compiled spark-tutorial in 0.22s
2022.02.14 19:10:26 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:10:26 INFO  time: compiled spark-tutorial in 0.2s
2022.02.14 19:10:28 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:10:28 INFO  time: compiled spark-tutorial in 0.23s
2022.02.14 19:10:30 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:10:30 INFO  time: compiled spark-tutorial in 71ms
2022.02.14 19:10:33 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:10:33 INFO  time: compiled spark-tutorial in 0.26s
2022.02.14 19:11:50 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:11:50 INFO  time: compiled spark-tutorial in 0.28s
2022.02.14 19:11:53 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:11:53 INFO  time: compiled spark-tutorial in 0.21s
2022.02.14 19:12:11 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:12:11 INFO  time: compiled spark-tutorial in 0.11s
2022.02.14 19:12:14 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:12:14 INFO  time: compiled spark-tutorial in 0.28s
2022.02.14 19:12:28 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:12:28 INFO  time: compiled spark-tutorial in 0.2s
2022.02.14 19:12:55 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:12:55 INFO  time: compiled spark-tutorial in 0.23s
2022.02.14 19:12:56 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:12:56 INFO  time: compiled spark-tutorial in 0.24s
2022.02.14 19:13:21 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:13:21 INFO  time: compiled spark-tutorial in 0.66s
2022.02.14 19:13:24 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:13:24 INFO  time: compiled spark-tutorial in 0.23s
2022.02.14 19:13:31 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:13:31 INFO  time: compiled spark-tutorial in 0.23s
2022.02.14 19:13:34 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:13:34 INFO  time: compiled spark-tutorial in 0.38s
2022.02.14 19:13:36 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:13:36 INFO  time: compiled spark-tutorial in 0.21s
2022.02.14 19:13:38 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:13:39 INFO  time: compiled spark-tutorial in 1.15s
2022.02.14 19:13:45 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:13:46 INFO  time: compiled spark-tutorial in 1.28s
2022.02.14 19:13:57 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 93h 27m 30.623s)
2022.02.14 19:13:57 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.14 19:13:57 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.14 19:13:57 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 19:14:02 INFO  Trying to attach to remote debuggee VM localhost:57271 .
2022.02.14 19:14:02 INFO  Attaching to debuggee VM succeeded.
2022.02.14 19:14:03 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.14 19:14:03 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.14 19:14:03 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.14 19:14:03 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.14 19:14:03 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.14 19:14:03 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.14 19:14:42 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 19:14:42 INFO  Closing debug server tcp://0.0.0.0:57267
2022.02.14 19:18:22 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:18:26 INFO  time: compiled spark-tutorial in 3.21s
2022.02.14 19:18:40 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:18:42 INFO  time: compiled spark-tutorial in 1.67s
2022.02.14 19:18:47 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:18:47 INFO  time: compiled spark-tutorial in 0.41s
2022.02.14 19:23:08 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:23:08 INFO  time: compiled spark-tutorial in 0.78s
2022.02.14 19:23:11 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:23:11 INFO  time: compiled spark-tutorial in 0.82s
2022.02.14 19:23:14 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:23:14 INFO  time: compiled spark-tutorial in 0.23s
2022.02.14 19:23:16 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:23:16 INFO  time: compiled spark-tutorial in 0.76s
2022.02.14 19:23:31 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:23:31 INFO  time: compiled spark-tutorial in 0.95s
2022.02.14 19:23:35 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:23:35 INFO  time: compiled spark-tutorial in 0.16s
2022.02.14 19:23:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:23:37 INFO  time: compiled spark-tutorial in 0.72s
2022.02.14 19:23:45 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:23:45 INFO  time: compiled spark-tutorial in 0.14s
2022.02.14 19:23:56 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:23:56 INFO  time: compiled spark-tutorial in 0.61s
2022.02.14 19:24:05 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:24:05 INFO  time: compiled spark-tutorial in 0.7s
2022.02.14 19:24:20 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:24:20 INFO  time: compiled spark-tutorial in 0.53s
2022.02.14 19:24:21 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:24:21 INFO  time: compiled spark-tutorial in 0.53s
2022.02.14 19:24:46 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:24:46 INFO  time: compiled spark-tutorial in 0.1s
2022.02.14 19:24:48 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:24:48 INFO  time: compiled spark-tutorial in 78ms
2022.02.14 19:25:00 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:25:00 INFO  time: compiled spark-tutorial in 0.33s
2022.02.14 19:25:04 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:25:04 INFO  time: compiled spark-tutorial in 0.13s
2022.02.14 19:25:13 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:25:13 INFO  time: compiled spark-tutorial in 0.32s
2022.02.14 19:25:21 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:25:21 INFO  time: compiled spark-tutorial in 90ms
2022.02.14 19:25:28 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:25:28 INFO  time: compiled spark-tutorial in 86ms
2022.02.14 19:25:30 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:25:30 INFO  time: compiled spark-tutorial in 0.14s
2022.02.14 19:25:31 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:25:31 INFO  time: compiled spark-tutorial in 0.1s
2022.02.14 19:25:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:25:37 INFO  time: compiled spark-tutorial in 84ms
2022.02.14 19:25:44 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:25:44 INFO  time: compiled spark-tutorial in 81ms
2022.02.14 19:25:54 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:25:54 INFO  time: compiled spark-tutorial in 0.12s
2022.02.14 19:25:59 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:25:59 INFO  time: compiled spark-tutorial in 0.3s
2022.02.14 19:26:09 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:26:09 INFO  time: compiled spark-tutorial in 0.2s
2022.02.14 19:26:11 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:26:13 INFO  time: compiled spark-tutorial in 2s
2022.02.14 19:26:16 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:26:16 INFO  time: compiled spark-tutorial in 0.29s
2022.02.14 19:26:44 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:26:44 INFO  time: compiled spark-tutorial in 0.23s
2022.02.14 19:26:46 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:26:46 INFO  time: compiled spark-tutorial in 0.3s
2022.02.14 19:27:07 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:27:07 INFO  time: compiled spark-tutorial in 0.58s
2022.02.14 19:27:29 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:27:29 INFO  time: compiled spark-tutorial in 0.71s
2022.02.14 19:27:36 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:27:36 INFO  time: compiled spark-tutorial in 0.24s
2022.02.14 19:27:38 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:27:38 INFO  time: compiled spark-tutorial in 0.36s
2022.02.14 19:27:41 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:27:41 INFO  time: compiled spark-tutorial in 0.26s
2022.02.14 19:28:00 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:28:00 INFO  time: compiled spark-tutorial in 0.28s
2022.02.14 19:28:10 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:28:10 INFO  time: compiled spark-tutorial in 0.26s
2022.02.14 19:28:15 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:28:15 INFO  time: compiled spark-tutorial in 0.22s
2022.02.14 19:28:17 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:28:19 INFO  time: compiled spark-tutorial in 1.35s
2022.02.14 19:28:22 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:28:22 INFO  time: compiled spark-tutorial in 0.24s
2022.02.14 19:28:27 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:28:27 INFO  time: compiled spark-tutorial in 0.25s
2022.02.14 19:28:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:28:37 INFO  time: compiled spark-tutorial in 0.24s
2022.02.14 19:28:39 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:28:39 INFO  time: compiled spark-tutorial in 0.22s
2022.02.14 19:28:42 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:28:42 INFO  time: compiled spark-tutorial in 0.2s
2022.02.14 19:28:49 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:28:49 INFO  time: compiled spark-tutorial in 0.24s
2022.02.14 19:28:54 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:28:54 INFO  time: compiled spark-tutorial in 0.38s
2022.02.14 19:28:56 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:28:56 INFO  time: compiled spark-tutorial in 0.3s
2022.02.14 19:28:58 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:28:59 INFO  time: compiled spark-tutorial in 1.07s
2022.02.14 19:29:08 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:29:09 INFO  time: compiled spark-tutorial in 1.15s
2022.02.14 19:29:16 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.14 19:29:16 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.14 19:29:16 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 19:29:21 INFO  Trying to attach to remote debuggee VM localhost:57690 .
2022.02.14 19:29:21 INFO  Attaching to debuggee VM succeeded.
2022.02.14 19:29:22 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.14 19:29:22 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.14 19:29:22 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.14 19:29:22 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.14 19:29:22 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.14 19:29:22 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.14 19:30:00 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 19:30:00 INFO  Closing debug server tcp://0.0.0.0:57686
2022.02.14 19:30:20 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 19:30:20 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:30:20 INFO  time: compiled spark-tutorial in 0.28s
2022.02.14 19:30:21 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
Feb. 14, 2022 7:30:21 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 15429
Feb. 14, 2022 7:30:21 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 15430
2022.02.14 19:30:21 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 19:30:21 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 19:30:21 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 19:30:21 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 19:30:22 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala
2022.02.14 19:30:23 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:30:30 INFO  time: compiled spark-tutorial in 6.81s
2022.02.14 19:31:27 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:31:27 INFO  time: compiled spark-tutorial in 0.25s
2022.02.14 19:31:29 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:31:29 INFO  time: compiled spark-tutorial in 0.27s
2022.02.14 19:31:32 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:31:32 INFO  time: compiled spark-tutorial in 0.26s
2022.02.14 19:31:49 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:31:49 INFO  time: compiled spark-tutorial in 0.24s
2022.02.14 19:31:52 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:31:52 INFO  time: compiled spark-tutorial in 0.25s
2022.02.14 19:31:57 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:31:57 INFO  time: compiled spark-tutorial in 0.23s
2022.02.14 19:32:00 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:32:00 INFO  time: compiled spark-tutorial in 0.25s
2022.02.14 19:32:18 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:32:18 INFO  time: compiled spark-tutorial in 84ms
2022.02.14 19:32:20 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:32:20 INFO  time: compiled spark-tutorial in 0.12s
2022.02.14 19:32:22 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:32:22 INFO  time: compiled spark-tutorial in 81ms
2022.02.14 19:32:25 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:32:25 INFO  time: compiled spark-tutorial in 0.27s
2022.02.14 19:32:31 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:32:31 INFO  time: compiled spark-tutorial in 94ms
2022.02.14 19:32:32 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:32:32 INFO  time: compiled spark-tutorial in 0.25s
2022.02.14 19:32:39 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:32:39 INFO  time: compiled spark-tutorial in 0.22s
2022.02.14 19:33:00 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:33:00 INFO  time: compiled spark-tutorial in 0.25s
2022.02.14 19:33:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:33:02 INFO  time: compiled spark-tutorial in 0.22s
2022.02.14 19:34:07 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:40:5: stale bloop error: not enough arguments for method apply: (n: Int)((String, String, Int, java.sql.Timestamp), Seq[Nothing]) in trait LinearSeqOptimized.
Unspecified value parameter n.
    result.toList().show()
    ^^^^^^^^^^^^^^^
2022.02.14 19:34:07 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:40:5: stale bloop error: not enough arguments for method apply: (n: Int)((String, String, Int, java.sql.Timestamp), Seq[Nothing]) in trait LinearSeqOptimized.
Unspecified value parameter n.
    result.toList().show()
    ^^^^^^^^^^^^^^^
2022.02.14 19:34:07 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:34:07 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:29:18: stale bloop error: value show is not a member of scala.collection.immutable.Map[(String, String, Int, java.sql.Timestamp),Seq[Nothing]]
> changeRecords.groupBy($"tableId",$"attributeName",$"entityId",$"timestamp")
>       .agg(collect_list($"newValue") as "newValues")
>       //.filter($"newValues".size() > 1)
>       //tableId:String,attributeName:String,entityId:Int,timestamp:Timestamp,newValues:Seq[String])
>       //.map((tableId:String,attributeName:String,entityId:Int,timestamp:Timestamp,newValues:Seq[String]) => (tableId,attributeName,entityId,timestamp,newValues, org.apache.spark.sql.functions.count(newValues):Int))
>       .map(x => (x.getString(0), x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq[String](4).size))
>       .filter(x => x._6 > 1)
>       .map(x => ((x._1, x._2, x._3, x._4), x._5))
>       .collect()
>       .toMap.show
2022.02.14 19:34:07 INFO  time: compiled spark-tutorial in 0.56s
2022.02.14 19:34:09 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:34:09 INFO  time: compiled spark-tutorial in 0.31s
2022.02.14 19:34:09 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 19:34:10 INFO  time: compiled spark-tutorial in 0.32s
2022.02.14 19:34:59 INFO  /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/Exercise_3c.scala:29:18: stale bloop error: value show is not a member of scala.collection.immutable.Map[(String, String, Int, java.sql.Timestamp),Seq[Nothing]]
> changeRecords.groupBy($"tableId",$"attributeName",$"entityId",$"timestamp")
>       .agg(collect_list($"newValue") as "newValues")
>       //.filter($"newValues".size() > 1)
>       //tableId:String,attributeName:String,entityId:Int,timestamp:Timestamp,newValues:Seq[String])
>       //.map((tableId:String,attributeName:String,entityId:Int,timestamp:Timestamp,newValues:Seq[String]) => (tableId,attributeName,entityId,timestamp,newValues, org.apache.spark.sql.functions.count(newValues):Int))
>       .map(x => (x.getString(0), x.getString(1), x.getInt(2), x.getTimestamp(3), x.getSeq(4), x.getSeq[String](4).size))
>       .filter(x => x._6 > 1)
>       .map(x => ((x._1, x._2, x._3, x._4), x._5))
>       .collect()
>       .toMap.show
2022.02.14 20:23:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:23:02 INFO  time: compiled spark-tutorial in 0.49s
2022.02.14 20:24:18 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:24:20 INFO  time: compiled spark-tutorial in 1.25s
2022.02.14 20:24:20 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:24:21 INFO  time: compiled spark-tutorial in 0.79s
2022.02.14 20:24:37 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:24:37 INFO  time: compiled spark-tutorial in 0.58s
2022.02.14 20:24:39 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:24:40 INFO  time: compiled spark-tutorial in 1.07s
2022.02.14 20:24:42 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:24:44 INFO  time: compiled spark-tutorial in 2.48s
2022.02.14 20:24:59 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:24:59 INFO  time: compiled spark-tutorial in 0.64s
2022.02.14 20:25:02 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:25:04 INFO  time: compiled spark-tutorial in 2.33s
2022.02.14 20:25:11 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:25:13 INFO  time: compiled spark-tutorial in 2.46s
2022.02.14 20:25:14 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.14 20:25:14 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.14 20:25:15 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 20:25:22 INFO  Trying to attach to remote debuggee VM localhost:58387 .
2022.02.14 20:25:22 INFO  Attaching to debuggee VM succeeded.
2022.02.14 20:25:23 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.14 20:25:23 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.14 20:25:23 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.14 20:25:23 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.14 20:25:23 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.14 20:25:23 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Feb. 14, 2022 8:25:35 NACHM. org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 16146
2022.02.14 20:26:19 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 20:26:19 INFO  Closing debug server tcp://0.0.0.0:58382
2022.02.14 20:26:55 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:26:57 INFO  time: compiled spark-tutorial in 2.08s
2022.02.14 20:27:10 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:27:17 INFO  time: compiled spark-tutorial in 6.65s
2022.02.14 20:27:17 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:27:17 INFO  time: compiled spark-tutorial in 0.2s
2022.02.14 20:27:17 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:27:17 INFO  time: compiled spark-tutorial in 0.25s
2022.02.14 20:27:20 INFO  compiling spark-tutorial (2 scala sources)
2022.02.14 20:27:20 INFO  time: compiled spark-tutorial in 0.24s
2022.02.14 20:27:25 INFO  compiling spark-tutorial (3 scala sources)
2022.02.14 20:27:25 INFO  time: compiled spark-tutorial in 0.37s
2022.02.14 20:27:26 INFO  compiling spark-tutorial (3 scala sources)
2022.02.14 20:27:26 INFO  time: compiled spark-tutorial in 0.32s
2022.02.14 20:27:29 INFO  compiling spark-tutorial (3 scala sources)
2022.02.14 20:27:29 INFO  time: compiled spark-tutorial in 0.28s
2022.02.14 20:27:31 INFO  compiling spark-tutorial (3 scala sources)
2022.02.14 20:27:31 INFO  time: compiled spark-tutorial in 0.27s
2022.02.14 20:27:37 INFO  compiling spark-tutorial (3 scala sources)
2022.02.14 20:27:37 INFO  time: compiled spark-tutorial in 0.26s
2022.02.14 20:28:45 INFO  compiling spark-tutorial (3 scala sources)
2022.02.14 20:28:45 INFO  time: compiled spark-tutorial in 0.34s
2022.02.14 20:28:47 INFO  compiling spark-tutorial (3 scala sources)
2022.02.14 20:28:47 INFO  time: compiled spark-tutorial in 0.31s
2022.02.14 20:28:51 INFO  compiling spark-tutorial (3 scala sources)
2022.02.14 20:28:51 INFO  time: compiled spark-tutorial in 0.3s
2022.02.14 20:29:04 INFO  compiling spark-tutorial (3 scala sources)
2022.02.14 20:29:06 INFO  time: compiled spark-tutorial in 2.04s
2022.02.14 20:29:08 INFO  compiling spark-tutorial (3 scala sources)
2022.02.14 20:29:08 INFO  time: compiled spark-tutorial in 0.28s
2022.02.14 20:29:12 INFO  compiling spark-tutorial (3 scala sources)
2022.02.14 20:29:12 INFO  time: compiled spark-tutorial in 83ms
2022.02.14 20:29:14 INFO  compiling spark-tutorial (3 scala sources)
2022.02.14 20:29:14 INFO  time: compiled spark-tutorial in 0.24s
2022.02.14 20:29:16 INFO  compiling spark-tutorial (3 scala sources)
2022.02.14 20:29:16 INFO  time: compiled spark-tutorial in 0.23s
2022.02.14 20:29:18 INFO  compiling spark-tutorial (3 scala sources)
2022.02.14 20:29:18 INFO  time: compiled spark-tutorial in 0.24s
2022.02.14 20:29:27 INFO  compiling spark-tutorial (3 scala sources)
2022.02.14 20:29:27 INFO  time: compiled spark-tutorial in 0.31s
2022.02.14 20:29:50 INFO  compiling spark-tutorial (3 scala sources)
2022.02.14 20:29:50 INFO  time: compiled spark-tutorial in 0.26s
2022.02.14 20:29:54 INFO  compiling spark-tutorial (2 scala sources)
2022.02.14 20:29:54 INFO  time: compiled spark-tutorial in 0.27s
2022.02.14 20:30:04 INFO  compiling spark-tutorial (2 scala sources)
2022.02.14 20:30:05 INFO  time: compiled spark-tutorial in 1.44s
2022.02.14 20:30:05 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:30:06 INFO  time: compiled spark-tutorial in 0.47s
2022.02.14 20:30:09 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:30:10 INFO  time: compiled spark-tutorial in 1.18s
2022.02.14 20:30:12 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.14 20:30:12 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:30:12 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.14 20:30:12 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.14 20:30:13 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/DBSIISparkExerciseMain.scala
2022.02.14 20:30:13 INFO  time: compiled spark-tutorial in 1s
2022.02.14 20:30:13 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:30:13 INFO  time: compiled spark-tutorial in 0.35s
2022.02.14 20:30:16 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:30:16 INFO  time: compiled spark-tutorial in 0.98s
2022.02.14 20:30:22 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.14 20:30:22 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.14 20:30:22 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 20:30:26 INFO  Trying to attach to remote debuggee VM localhost:58522 .
2022.02.14 20:30:26 INFO  Attaching to debuggee VM succeeded.
2022.02.14 20:30:27 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.14 20:30:27 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.14 20:30:27 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.14 20:30:27 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.14 20:30:27 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.14 20:30:27 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.14 20:31:17 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 20:31:17 INFO  Closing debug server tcp://0.0.0.0:58518
2022.02.14 20:31:56 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:31:57 INFO  time: compiled spark-tutorial in 1.2s
2022.02.14 20:33:11 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:33:11 INFO  time: compiled spark-tutorial in 0.97s
2022.02.14 20:35:30 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:35:33 INFO  time: compiled spark-tutorial in 3.23s
2022.02.14 20:35:34 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.14 20:35:34 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.14 20:35:34 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.14 20:35:34 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.14 20:35:35 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.14 20:35:35 WARN  Could not load snapshot text for /Users/Johann/Documents/GitHub/spark-tutorial/src/main/scala/de/hpi/dbsII_exercises/ResultChecker.scala
2022.02.14 20:35:36 INFO  compiling spark-tutorial (1 scala source)
2022.02.14 20:35:37 INFO  time: compiled spark-tutorial in 1.59s
2022.02.14 20:35:46 INFO  Deduplicating compilation of spark-tutorial from bsp client 'Metals 0.11.1' (since 94h 49m 20.043s)
2022.02.14 20:35:46 INFO  tracing is disabled for protocol dap-server, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-server.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-server.trace.json
2022.02.14 20:35:46 INFO  tracing is disabled for protocol dap-client, to enable tracing of incoming and outgoing JSON messages create an empty file at /Users/Johann/Documents/GitHub/spark-tutorial/.metals/dap-client.trace.json or /Users/Johann/Library/Caches/org.scalameta.metals/dap-client.trace.json
2022.02.14 20:35:47 INFO  Starting debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 20:35:53 INFO  Trying to attach to remote debuggee VM localhost:58593 .
2022.02.14 20:35:53 INFO  Attaching to debuggee VM succeeded.
2022.02.14 20:35:54 ERROR Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
2022.02.14 20:35:54 ERROR WARNING: An illegal reflective access operation has occurred
2022.02.14 20:35:54 ERROR WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/Johann/Library/Caches/Coursier/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/3.0.0/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
2022.02.14 20:35:54 ERROR WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
2022.02.14 20:35:54 ERROR WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
2022.02.14 20:35:54 ERROR WARNING: All illegal access operations will be denied in a future release
2022.02.14 20:36:46 INFO  Canceling debug proxy for [de.hpi.dbsII_exercises.DBSIISparkExerciseMain]
2022.02.14 20:36:46 INFO  Closing debug server tcp://0.0.0.0:58587
